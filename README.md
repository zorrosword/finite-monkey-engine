# FiniteMonkey

<p align="center">
  <img src="image.jpeg" width="500">
</p>

<p align="center">
  <img src="https://img.shields.io/badge/license-Apache--2.0-blue.svg">
  <img src="https://img.shields.io/badge/version-1.0-green.svg">
  <img src="https://img.shields.io/badge/bounties-$60,000+-yellow.svg">
</p>

FiniteMonkey is an intelligent vulnerability mining engine based on large language models, requiring no pre-trained knowledge base or fine-tuning. Its core feature is using task-driven and prompt engineering approaches to guide models in vulnerability analysis through carefully designed prompts.

## ğŸŒŸ Core Concepts

- **Task-driven rather than problem-driven**
- **Prompt-driven rather than code-driven**
- **Focus on prompt design rather than model design**
- **Leverage "deception" and hallucination as key mechanisms**

## ğŸ† Achievements

As of May 2024, this tool has helped discover over $60,000 worth of bug bounties.

## ğŸš€ Latest Updates

**2024.11.19**: Released version 1.0 - Validated LLM-based auditing and productization feasibility

**Earlier Updates:**
- 2024.08.02: Project renamed to finite-monkey-engine
- 2024.08.01: Added Func, Tact language support
- 2024.07.23: Added Cairo, Move language support
- 2024.07.01: Updated license
- 2024.06.01: Added Python language support
- 2024.05.18: Improved false positive rate (~20%)
- 2024.05.16: Added cross-contract vulnerability confirmation
- 2024.04.29: Added basic Rust language support

## ğŸ“‹ Requirements

- PostgreSQL database
- OpenAI API access
- Python environment

## ğŸ› ï¸ Installation & Configuration

1. Place project in `src/dataset/agent-v1-c4` directory

2. Configure project in `datasets.json`:
```json
{
    "StEverVault2": {
        "path": "StEverVault",
        "files": [],
        "functions": []
    }
}
```

3. Create database using `src/db.sql`

4. Configure `.env`:
```env
# æ•°æ®åº“è¿æ¥URLï¼Œä½¿ç”¨PostgreSQLæ•°æ®åº“
# Database connection URL using PostgreSQL
DATABASE_URL=postgresql://postgres:1234@127.0.0.1:5432/postgres

# æ‰€æœ‰llmçš„åŸºç¡€URLï¼ˆllmä¸­è½¬å¹³å°ï¼‰ï¼Œç”¨äºAPIè¯·æ±‚
# Base URL for all LLM requests (LLM proxy platform) used for API requests
OPENAI_API_BASE="4.0.wokaai.com"

# ç”¨äºæ–‡æœ¬åµŒå…¥çš„æ¨¡å‹åç§°
# Model name used for text embeddings
EMBEDDING_MODEL="text-embedding-3-large"

# llmä¸­è½¬å¹³å°çš„APIå¯†é’¥
# API key for LLM proxy platform
OPENAI_API_KEY=your-api-keyï¼ˆé€šå¸¸å»ºè®®ä»openrouterå’Œwokaaiè·å–ï¼Œä¸€æ¬¡æ€§å¤šä¸ªæ¨¡å‹ï¼‰

# ç¡®è®¤æ¨¡å‹çš„é€‰æ‹©ï¼Œä½¿ç”¨DeepSeekæ¨¡å‹
# Confirmation model selection, using DeepSeek model
CONFIRMATION_MODEL="DEEPSEEK"

# OpenAIæ¨¡å‹çš„é€‰æ‹©ï¼Œä½¿ç”¨GPT-4 Turbo
# OpenAI model selection, using GPT-4 Turbo
OPENAI_MODEL=gpt-4-turbo

# Claudeæ¨¡å‹çš„é€‰æ‹©ï¼Œä½¿ç”¨Claude 3.5 Sonnetç‰ˆæœ¬
# Claude model selection, using Claude 3.5 Sonnet version
CLAUDE_MODEL=claude-3-5-sonnet-20241022

# æ‰«ææ¨¡å¼è®¾ç½®ï¼Œå½“å‰ä¸ºçº¯æ‰«ææ¨¡å¼
# Scan mode setting, currently set to pure scan mode
# å¯é€‰å€¼ï¼šSPECIFIC_PROJECT(ç‰¹å®šé¡¹ç›®CHECKLIST) / OPTIMIZE(ä»£ç å»ºè®®æ¨¡å¼) / COMMON_PROJECT(é€šç”¨é¡¹ç›®CHECKLIST) / PURE_SCAN(çº¯æ‰«æ) 
# / CHECKLIST(æ£€æŸ¥æ¸…å•è‡ªåŠ¨ç”Ÿæˆ) / CHECKLIST_PIPELINE(æ£€æŸ¥æ¸…å•è‡ªåŠ¨ç”Ÿæˆ+pipeline)
# Available options: SPECIFIC_PROJECT / OPTIMIZE / COMMON_PROJECT / PURE_SCAN 
# / CHECKLIST / CHECKLIST_PIPELINE  
SCAN_MODE=CHECKLIST_PIPELINE 

# APIæœåŠ¡æä¾›å•†é€‰æ‹©
# API service provider selection
# å¯é€‰å€¼ï¼šOPENAI / AZURE / CLAUDE / DEEPSEEK
# Available options: OPENAI / AZURE / CLAUDE / DEEPSEEK
AZURE_OR_OPENAI="OPENAI" 

# ç¡®è®¤é˜¶æ®µçš„æœ€å¤§çº¿ç¨‹æ•°
# Maximum number of threads for confirmation phase
MAX_THREADS_OF_CONFIRMATION=10

# æ‰«æé˜¶æ®µçš„æœ€å¤§çº¿ç¨‹æ•°
# Maximum number of threads for scanning phase
MAX_THREADS_OF_SCAN=20

# ä¸šåŠ¡æµç¨‹é‡å¤æ•°é‡ï¼ˆè§¦å‘å¹»è§‰çš„æ•°é‡ï¼Œæ•°å­—è¶Šå¤§å¹»è§‰è¶Šå¤šï¼Œè¾“å‡ºè¶Šå¤šï¼Œæ—¶é—´è¶Šé•¿ï¼‰
# Business flow repeat count (number of hallucinations triggered, higher number means more hallucinations, more output, longer time)
BUSINESS_FLOW_COUNT=10

# æ˜¯å¦å¯ç”¨å‡½æ•°ä»£ç æ‰«æ
# Whether to enable function code scanning
SWITCH_FUNCTION_CODE=False

# æ˜¯å¦å¯ç”¨ä¸šåŠ¡ä»£ç æ‰«æ
# Whether to enable business code scanning
SWITCH_BUSINESS_CODE=True

# æœ€å¤§ç¡®è®¤è½®æ•°
# Maximum number of confirmation rounds
MAX_CONFIRMATION_ROUNDS=2

# JSONæ¨¡å‹ID
# JSON model ID
JSON_MODEL_ID="gpt-4-turbo"

# æ˜¯å¦å¯ç”¨ç½‘ç»œæœç´¢
# Whether to enable internet search
ENABLE_INTERNET_SEARCH=False

# è®¾ç½®æ£€æŸ¥æ¸…å•ç”Ÿæˆè¿­ä»£è½®æ•°
# Set the number of iterations for checklist generation
CHECKLIST_ITERATION_ROUNDS=3

```

## ğŸŒˆ Supported Languages

- Solidity (.sol)
- Rust (.rs)
- Python (.py)
- Move (.move)
- Cairo (.cairo)
- Tact (.tact)
- Func (.fc)
- Java (.java)
- Pseudo-Solidity (.fr) - For scanning Solidity pseudocode

## ğŸ“Š Scan Results Guide

1. If interrupted due to network/API issues, resume scanning using the same project_id in main.py
3. Results include detailed annotations:
   - Focus on entries marked "yes" in result column
   - Filter "dont need In-project other contract" in category column
   - Check specific code in business_flow_code column
   - Find code location in name column

## ğŸ¯ Important Notes

- Best suited for logic vulnerability mining in real projects
- Not recommended for academic vulnerability testing
- GPT-4-turbo recommended for best results
- Average scan time for medium-sized projects: 2-3 hours
- Estimated cost for 10 iterations on medium projects: $20-30
- Current false positive rate: 30-65% (depends on project size)

## ğŸ” Technical Notes

1. claude 3.5 sonnet in scanning provides better results with acceptable time cost, GPT-3 not fully tested
2. Deceptive prompt theory adaptable to any language with minor modifications
3. ANTLR AST parsing recommended for better code slicing results
4. Currently supports Solidity, plans to expand language support
5. DeepSeek-R1 is recommended for better confirmation results
## ğŸ›¡ï¸ Scanning Features

- Excels at code understanding and logic vulnerability detection
- Weaker at control flow vulnerability detection
- Designed for real projects, not academic test cases

## ğŸ’¡ Implementation Tips

- Progress automatically saved per scan
- claude-3.5-sonnet offers best performance in scanning compared to other models
- deepseek-R1 offers best performance in confirmation compared to other models
- 10 iterations for medium projects take about 4 hours
- Results include detailed categorization

## ğŸ“ License

Apache License 2.0

## ğŸ¤ Contributing

Pull Requests welcome!

---

*Note: Project name inspired by [Large Language Monkeys paper](https://arxiv.org/abs/2407.21787v1)*

Would you like me to explain or break down the code?