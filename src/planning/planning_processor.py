import json
import random
import csv
import sys
import os
import os.path
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
from typing import List, Dict, Tuple, Optional

from dao.task_mgr import ProjectTaskMgr
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from tqdm import tqdm
from dao.entity import Project_Task
from openai_api.openai import common_ask_for_json, ask_claude
from prompt_factory.core_prompt import CorePrompt
from prompt_factory.vul_prompt_common import VulPromptCommon
from prompt_factory.assumption_prompt import AssumptionPrompt
import json
from .business_flow_utils import BusinessFlowUtils
from .config_utils import ConfigUtils

# ç›´æ¥ä½¿ç”¨tree_sitter_parsingè€Œä¸æ˜¯é€šè¿‡context
from tree_sitter_parsing import TreeSitterProjectAudit, parse_project, TreeSitterProjectFilter

# å¤æ‚åº¦åˆ†æç›¸å…³å¯¼å…¥
try:
    from tree_sitter import Language, Parser, Node
    import tree_sitter_solidity as ts_solidity
    # å°è¯•å¯¼å…¥å…¶ä»–è¯­è¨€è§£æå™¨
    try:
        import tree_sitter_rust as ts_rust
        RUST_AVAILABLE = True
    except ImportError:
        RUST_AVAILABLE = False
        
    try:
        import tree_sitter_cpp as ts_cpp
        CPP_AVAILABLE = True
    except ImportError:
        CPP_AVAILABLE = False
        
    try:
        import tree_sitter_move as ts_move
        MOVE_AVAILABLE = True
    except ImportError:
        MOVE_AVAILABLE = False
    
    COMPLEXITY_ANALYSIS_ENABLED = True
except ImportError:
    print("âš ï¸ Tree-sitteræ¨¡å—æœªå®‰è£…ï¼Œå¤æ‚åº¦è¿‡æ»¤åŠŸèƒ½å°†è¢«ç¦ç”¨")
    COMPLEXITY_ANALYSIS_ENABLED = False
    RUST_AVAILABLE = False
    CPP_AVAILABLE = False
    MOVE_AVAILABLE = False


class PlanningProcessor:
    """è§„åˆ’å¤„ç†å™¨ï¼Œè´Ÿè´£åŸºäºpublicå‡½æ•°downstreamæ·±åº¦æ‰«æçš„æ–°planningé€»è¾‘"""
    
    def __init__(self, project_audit: TreeSitterProjectAudit, taskmgr: ProjectTaskMgr):
        """
        ç›´æ¥æ¥å—é¡¹ç›®å®¡è®¡ç»“æœï¼Œè€Œä¸æ˜¯é€šè¿‡ContextFactoryé—´æ¥è·å–
        
        Args:
            project_audit: TreeSitterProjectAuditå®ä¾‹ï¼ŒåŒ…å«è§£æåçš„é¡¹ç›®æ•°æ®
            taskmgr: ä»»åŠ¡ç®¡ç†å™¨
        """
        self.project_audit = project_audit
        self.taskmgr = taskmgr
        
        # ä»project_auditè·å–æ ¸å¿ƒæ•°æ®
        self.functions = project_audit.functions
        self.functions_to_check = project_audit.functions_to_check
        self.call_trees = project_audit.call_trees
        
        # RAGåŠŸèƒ½ï¼ˆå¯é€‰ï¼Œå¦‚æœéœ€è¦çš„è¯ï¼‰
        self.rag_processor = None
    
    def initialize_rag_processor(self, lancedb_path, project_id):
        """åˆå§‹åŒ–RAGå¤„ç†å™¨ï¼ˆå¯é€‰åŠŸèƒ½ï¼‰"""
        try:
            from context.rag_processor import RAGProcessor
            # æ­£ç¡®ä¼ é€’å‚æ•°ï¼šfunctions_to_checkä½œä¸ºç¬¬ä¸€ä¸ªå‚æ•°ï¼Œå¹¶ä¼ é€’è°ƒç”¨æ ‘æ•°æ®
            call_trees = getattr(self.project_audit, 'call_trees', [])
            self.rag_processor = RAGProcessor(self.functions_to_check, lancedb_path, project_id, call_trees)
            print("âœ… RAGå¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
            print(f"ğŸ“Š åŸºäº {len(self.functions_to_check)} ä¸ªtree-sitterè§£æçš„å‡½æ•°æ„å»ºRAG")
            print(f"ğŸ”— ä½¿ç”¨ {len(call_trees)} ä¸ªè°ƒç”¨æ ‘æ„å»ºå…³ç³»å‹RAG")
        except ImportError:
            print("âš ï¸  RAGå¤„ç†å™¨ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ç®€åŒ–æœç´¢")
            self.rag_processor = None
        except Exception as e:
            print(f"âš ï¸  RAGå¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.rag_processor = None
    
    def find_public_functions_by_language(self) -> Dict[str, List[Dict]]:
        """æ ¹æ®è¯­è¨€ç±»å‹æŸ¥æ‰¾æ‰€æœ‰publicå‡½æ•°
        
        Returns:
            Dict[str, List[Dict]]: æŒ‰è¯­è¨€åˆ†ç±»çš„publicå‡½æ•°å­—å…¸
        """
        public_functions_by_lang = {
            'solidity': [],
            'rust': [],
            'cpp': [],
            'move': []
        }
        
        for func in self.functions_to_check:
            # æ£€æŸ¥å¯è§æ€§
            visibility = func.get('visibility', '').lower()
            func_name = func.get('name', '')
            
            # åˆ¤æ–­è¯­è¨€ç±»å‹å’Œpublicå¯è§æ€§
            if func_name.endswith('.sol') or 'sol' in func.get('relative_file_path', '').lower():
                if visibility in ['public', 'external']:
                    public_functions_by_lang['solidity'].append(func)
            elif func_name.endswith('.rs') or 'rs' in func.get('relative_file_path', '').lower():
                if visibility == 'pub' or visibility == 'public':
                    public_functions_by_lang['rust'].append(func)
            elif func_name.endswith('.cpp') or func_name.endswith('.c') or 'cpp' in func.get('relative_file_path', '').lower():
                if visibility == 'public' or not visibility:  # C++é»˜è®¤public
                    if "exec" in func_name:
                        public_functions_by_lang['cpp'].append(func)
            elif func_name.endswith('.move') or 'move' in func.get('relative_file_path', '').lower():
                if visibility == 'public' or visibility == 'public(friend)':
                    public_functions_by_lang['move'].append(func)
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        total_public = sum(len(funcs) for funcs in public_functions_by_lang.values())
        print(f"ğŸ” å‘ç° {total_public} ä¸ªpublicå‡½æ•°:")
        for lang, funcs in public_functions_by_lang.items():
            if funcs:
                print(f"  ğŸ“‹ {lang}: {len(funcs)} ä¸ªpublicå‡½æ•°")
        
        return public_functions_by_lang
    
    def _calculate_simple_complexity(self, function_content: str, language: str = 'solidity') -> Dict:
        """ç®€åŒ–ç‰ˆå¤æ‚åº¦è®¡ç®—ï¼Œæ”¯æŒå¤šç§è¯­è¨€
        
        Args:
            function_content: å‡½æ•°ä»£ç å†…å®¹
            language: ç¼–ç¨‹è¯­è¨€ç±»å‹ ('solidity', 'rust', 'cpp', 'move')
            
        Returns:
            Dict: åŒ…å«åœˆå¤æ‚åº¦å’Œè®¤çŸ¥å¤æ‚åº¦çš„å­—å…¸
        """
        if not COMPLEXITY_ANALYSIS_ENABLED or not function_content:
            return {'cyclomatic': 1, 'cognitive': 0, 'should_skip': False}
        
        try:
            # æ ¹æ®è¯­è¨€é€‰æ‹©ç›¸åº”çš„è§£æå™¨
            parser = Parser()
            parser_language = None
            function_node_types = []
            
            if language == 'solidity':
                parser_language = Language(ts_solidity.language())
                function_node_types = ['function_definition']
            elif language == 'rust' and RUST_AVAILABLE:
                parser_language = Language(ts_rust.language())
                function_node_types = ['function_item', 'function_signature_item']
            elif language == 'cpp' and CPP_AVAILABLE:
                parser_language = Language(ts_cpp.language())
                function_node_types = ['function_definition', 'function_declarator']
            elif language == 'move' and MOVE_AVAILABLE:
                parser_language = Language(ts_move.language())
                function_node_types = ['function_definition']
            else:
                print(f"âš ï¸ ä¸æ”¯æŒçš„è¯­è¨€æˆ–è§£æå™¨æœªå®‰è£…: {language}")
                return {'cyclomatic': 1, 'cognitive': 0, 'should_skip': False, 'should_reduce_iterations': False}
                
            if not parser_language:
                return {'cyclomatic': 1, 'cognitive': 0, 'should_skip': False, 'should_reduce_iterations': False}
                
            parser.language = parser_language
            
            # è§£æä»£ç 
            tree = parser.parse(bytes(function_content, 'utf8'))
            
            # æŸ¥æ‰¾å‡½æ•°å®šä¹‰èŠ‚ç‚¹
            function_node = None
            for node in self._walk_tree(tree.root_node):
                if node.type in function_node_types:
                    function_node = node
                    break
            
            if not function_node:
                return {'cyclomatic': 1, 'cognitive': 0, 'should_skip': False}
            
            # è®¡ç®—åœˆå¤æ‚åº¦
            cyclomatic = self._calculate_cyclomatic_complexity(function_node, language)
            
            # è®¡ç®—è®¤çŸ¥å¤æ‚åº¦
            cognitive = self._calculate_cognitive_complexity(function_node, language)
            
            # åˆ¤æ–­æ˜¯å¦åº”è¯¥è·³è¿‡ï¼ˆåŸºäºfishcakeåˆ†æçš„æœ€ä½³é˜ˆå€¼ï¼‰
            # è¿‡æ»¤æ¡ä»¶ï¼šè®¤çŸ¥å¤æ‚åº¦=0ä¸”åœˆå¤æ‚åº¦â‰¤2ï¼Œæˆ–è€…åœˆå¤æ‚åº¦=2ä¸”è®¤çŸ¥å¤æ‚åº¦=1ï¼Œæˆ–è€…åœˆå¤æ‚åº¦=3ä¸”è®¤çŸ¥å¤æ‚åº¦=2
            should_skip = (cognitive == 0 and cyclomatic <= 2) or (cyclomatic == 2 and cognitive == 1) or (cyclomatic == 3 and cognitive == 2) # å…³é”®é€»è¾‘
            
            # ğŸ¯ åˆ¤æ–­æ˜¯å¦ä¸ºä¸­ç­‰å¤æ‚åº¦å‡½æ•°ï¼ˆéœ€è¦é™ä½è¿­ä»£æ¬¡æ•°ï¼‰
            # åŸºäºtokenURIã€buyFccAmountç­‰å‡½æ•°çš„ç‰¹å¾åˆ†æ
            should_reduce_iterations = self._should_reduce_iterations(
                cognitive, cyclomatic, function_content
            )
            
            return {
                'cyclomatic': cyclomatic,
                'cognitive': cognitive, 
                'should_skip': should_skip,
                'should_reduce_iterations': should_reduce_iterations
            }
            
        except Exception as e:
            print(f"âš ï¸ å¤æ‚åº¦è®¡ç®—å¤±è´¥: {e}")
            return {'cyclomatic': 1, 'cognitive': 0, 'should_skip': False, 'should_reduce_iterations': False}
    
    def _walk_tree(self, node):
        """éå†ASTæ ‘"""
        yield node
        for child in node.children:
            yield from self._walk_tree(child)
    
    def _calculate_cyclomatic_complexity(self, function_node, language: str = 'solidity') -> int:
        """è®¡ç®—åœˆå¤æ‚åº¦ï¼Œæ”¯æŒå¤šç§è¯­è¨€"""
        complexity = 1  # åŸºç¡€è·¯å¾„
        
        # æ ¹æ®è¯­è¨€å®šä¹‰å†³ç­–ç‚¹èŠ‚ç‚¹ç±»å‹
        decision_nodes = self._get_decision_node_types(language)
        
        for node in self._walk_tree(function_node):
            # å†³ç­–ç‚¹
            if node.type in decision_nodes['control_flow']:
                complexity += 1
            elif node.type in decision_nodes['conditional']:  # ä¸‰å…ƒè¿ç®—ç¬¦
                complexity += 1
            elif node.type == 'binary_expression':
                # æ£€æŸ¥é€»è¾‘è¿ç®—ç¬¦
                operator = node.child_by_field_name('operator')
                if operator:
                    operator_text = operator.text.decode('utf8')
                    if operator_text in ['&&', '||', 'and', 'or']:
                        complexity += 1
        
        return complexity
    
    def _calculate_cognitive_complexity(self, function_node, language: str = 'solidity') -> int:
        """è®¡ç®—è®¤çŸ¥å¤æ‚åº¦ï¼ˆç®€åŒ–ç‰ˆï¼‰ï¼Œæ”¯æŒå¤šç§è¯­è¨€"""
        # æ ¹æ®è¯­è¨€å®šä¹‰å†³ç­–ç‚¹èŠ‚ç‚¹ç±»å‹
        decision_nodes = self._get_decision_node_types(language)
        
        def calculate_recursive(node, nesting_level: int = 0) -> int:
            complexity = 0
            node_type = node.type
            
            # åŸºç¡€å¢é‡ç»“æ„
            if node_type in decision_nodes['control_flow']:
                complexity += 1 + nesting_level
                # é€’å½’å¤„ç†å­èŠ‚ç‚¹ï¼Œå¢åŠ åµŒå¥—å±‚çº§
                for child in node.children:
                    complexity += calculate_recursive(child, nesting_level + 1)
            elif node_type in decision_nodes['conditional']:
                complexity += 1 + nesting_level
            elif node_type == 'binary_expression':
                operator = node.child_by_field_name('operator')
                if operator and operator.text.decode('utf8') in ['&&', '||', 'and', 'or']:
                    complexity += 1
                # ä¸å¢åŠ åµŒå¥—å±‚çº§å¤„ç†é€»è¾‘è¿ç®—ç¬¦
                for child in node.children:
                    complexity += calculate_recursive(child, nesting_level)
            else:
                # ç»§ç»­éå†å­èŠ‚ç‚¹ï¼Œä¸å¢åŠ åµŒå¥—å±‚çº§
                for child in node.children:
                    complexity += calculate_recursive(child, nesting_level)
            
            return complexity
        
        return calculate_recursive(function_node)
    
    def _get_decision_node_types(self, language: str) -> Dict[str, List[str]]:
        """è·å–ä¸åŒè¯­è¨€çš„å†³ç­–èŠ‚ç‚¹ç±»å‹"""
        node_types = {
            'solidity': {
                'control_flow': ['if_statement', 'while_statement', 'for_statement', 'try_statement'],
                'conditional': ['conditional_expression']
            },
            'rust': {
                'control_flow': ['if_expression', 'while_expression', 'for_expression', 'loop_expression', 'match_expression'],
                'conditional': ['if_let_expression']
            },
            'cpp': {
                'control_flow': ['if_statement', 'while_statement', 'for_statement', 'do_statement', 'switch_statement'],
                'conditional': ['conditional_expression']
            },
            'move': {
                'control_flow': ['if_expression', 'while_expression', 'loop_expression'],
                'conditional': ['conditional_expression']
            }
        }
        
        return node_types.get(language, node_types['solidity'])  # é»˜è®¤ä½¿ç”¨solidityçš„èŠ‚ç‚¹ç±»å‹
    
    def _should_reduce_iterations(self, cognitive: int, cyclomatic: int, function_content: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥é™ä½è¿­ä»£æ¬¡æ•°ï¼ˆåŸºäºfishcakeé¡¹ç›®åˆ†æï¼‰
        
        é€‚ç”¨äºåƒtokenURIã€buyFccAmountç­‰ä¸­ç­‰å¤æ‚åº¦çš„æ•°æ®å¤„ç†å‹å‡½æ•°
        
        Args:
            cognitive: è®¤çŸ¥å¤æ‚åº¦
            cyclomatic: åœˆå¤æ‚åº¦  
            function_content: å‡½æ•°ä»£ç å†…å®¹
            
        Returns:
            bool: Trueè¡¨ç¤ºåº”è¯¥é™ä½è¿­ä»£æ¬¡æ•°åˆ°3-4æ¬¡
        """
        # åŸºäºfishcakeé¡¹ç›®åˆ†æçš„ç‰¹å¾è¯†åˆ«
        
        # 1. ä¸­ç­‰å¤æ‚åº¦èŒƒå›´ (ä¸æ˜¯ç®€å•å‡½æ•°ï¼Œä¹Ÿä¸æ˜¯æå¤æ‚å‡½æ•°)
        if not (5 <= cognitive <= 20 and 3 <= cyclomatic <= 8):
            return False
            
        # 2. è¯†åˆ«æ•°æ®å¤„ç†å‹å‡½æ•°ç‰¹å¾
        data_processing_indicators = [
            'view' in function_content,  # viewå‡½æ•°é€šå¸¸æ˜¯æ•°æ®æŸ¥è¯¢
            'returns (' in function_content,  # æœ‰è¿”å›å€¼
            function_content.count('return') >= 3,  # å¤šä¸ªreturnè¯­å¥(å¦‚tokenURI)
            'if(' in function_content or 'if (' in function_content,  # æœ‰æ¡ä»¶åˆ†æ”¯
        ]
        
        # 3. è¯†åˆ«ç®€å•äº¤æ˜“å‹å‡½æ•°ç‰¹å¾  
        simple_transaction_indicators = [
            'transfer' in function_content.lower(),  # åŒ…å«è½¬è´¦æ“ä½œ
            'external' in function_content,  # å¤–éƒ¨å¯è°ƒç”¨
            function_content.count('require') <= 3,  # æ£€æŸ¥æ¡ä»¶ä¸å¤ªå¤š
            function_content.count('if') <= 2,  # åˆ†æ”¯ä¸å¤ªå¤æ‚
        ]
        
        # 4. æ’é™¤å¤æ‚ä¸šåŠ¡é€»è¾‘å‡½æ•°çš„ç‰¹å¾
        complex_business_indicators = [
            'for (' in function_content or 'for(' in function_content,  # åŒ…å«å¾ªç¯
            'while' in function_content,  # åŒ…å«whileå¾ªç¯
            function_content.count('if') > 5,  # åˆ†æ”¯è¿‡å¤š
            cognitive > 20,  # è®¤çŸ¥å¤æ‚åº¦è¿‡é«˜
            'nonReentrant' in function_content and cyclomatic > 6,  # å¤æ‚çš„é˜²é‡å…¥å‡½æ•°
        ]
        
        # 5. å‡½æ•°åæ¨¡å¼è¯†åˆ« (åŸºäºå®é™…æ¡ˆä¾‹)
        function_name_patterns = [
            'tokenURI' in function_content,  # ç±»ä¼¼tokenURIçš„å‡½æ•°
            'buyFcc' in function_content,  # ç±»ä¼¼buyFccçš„å‡½æ•°  
            'updateNft' in function_content,  # ç±»ä¼¼updateNftçš„å‡½æ•°
            'uri(' in function_content,  # URIç›¸å…³å‡½æ•°
        ]
        
        # åˆ¤æ–­é€»è¾‘ï¼š
        # - æ˜¯æ•°æ®å¤„ç†å‹ OR ç®€å•äº¤æ˜“å‹
        # - ä¸” æ²¡æœ‰å¤æ‚ä¸šåŠ¡é€»è¾‘ç‰¹å¾
        # - æˆ–è€… åŒ¹é…ç‰¹å®šå‡½æ•°åæ¨¡å¼
        
        is_data_processing = sum(data_processing_indicators) >= 2
        is_simple_transaction = sum(simple_transaction_indicators) >= 2  
        has_complex_business = any(complex_business_indicators)
        matches_pattern = any(function_name_patterns)
        
        # å†³ç­–é€»è¾‘
        should_reduce = (
            (is_data_processing or is_simple_transaction or matches_pattern) and
            not has_complex_business
        )
        
        return should_reduce
    
    def filter_functions_by_complexity(self, public_functions_by_lang: Dict[str, List[Dict]]) -> Dict[str, List[Dict]]:
        """åŸºäºå¤æ‚åº¦è¿‡æ»¤å‡½æ•°ï¼ˆåŸºäºfishcakeé¡¹ç›®åˆ†æä¼˜åŒ–ï¼‰
        
        è¿‡æ»¤ç­–ç•¥ï¼š
        - è®¤çŸ¥å¤æ‚åº¦ = 0 ä¸” åœˆå¤æ‚åº¦ â‰¤ 2 â†’ è·³è¿‡æ‰«æï¼ˆç®€å•å‡½æ•°ï¼‰
        - åœˆå¤æ‚åº¦ = 2 ä¸” è®¤çŸ¥å¤æ‚åº¦ = 1 â†’ è·³è¿‡æ‰«æï¼ˆç®€å•å‡½æ•°ï¼‰
        - åœˆå¤æ‚åº¦ = 3 ä¸” è®¤çŸ¥å¤æ‚åº¦ = 2 â†’ è·³è¿‡æ‰«æï¼ˆç®€å•å‡½æ•°ï¼‰
        - å…¶ä»–å‡½æ•° â†’ ä¿ç•™æ‰«æï¼ˆå¤æ‚å‡½æ•°ï¼‰
        
        Args:
            public_functions_by_lang: æŒ‰è¯­è¨€åˆ†ç±»çš„å‡½æ•°å­—å…¸
            
        Returns:
            Dict: è¿‡æ»¤åçš„å‡½æ•°å­—å…¸
        """
        if not COMPLEXITY_ANALYSIS_ENABLED:
            print("âš ï¸ å¤æ‚åº¦åˆ†æåŠŸèƒ½æœªå¯ç”¨ï¼Œè·³è¿‡è¿‡æ»¤")
            return public_functions_by_lang
        
        filtered_functions = {
            'solidity': [],
            'rust': [],
            'cpp': [],
            'move': []
        }
        
        total_original = 0
        total_filtered = 0
        skipped_functions = []
        reduced_iteration_functions = []
        
        print("\nğŸ¯ å¼€å§‹åŸºäºå¤æ‚åº¦è¿‡æ»¤å‡½æ•°...")
        print("ğŸ“‹ è¿‡æ»¤ç­–ç•¥: è®¤çŸ¥å¤æ‚åº¦=0ä¸”åœˆå¤æ‚åº¦â‰¤2ï¼Œæˆ–è€…åœˆå¤æ‚åº¦=2ä¸”è®¤çŸ¥å¤æ‚åº¦=1ï¼Œæˆ–è€…åœˆå¤æ‚åº¦=3ä¸”è®¤çŸ¥å¤æ‚åº¦=2çš„å‡½æ•°å°†è¢«è·³è¿‡")
        
        for lang, funcs in public_functions_by_lang.items():
            if not funcs:
                continue
                
            print(f"\nğŸ“„ åˆ†æ {lang} è¯­è¨€çš„ {len(funcs)} ä¸ªå‡½æ•°...")
            
            for func in funcs:
                total_original += 1
                func_name = func.get('name', 'unknown')
                func_content = func.get('content', '')
                
                # è®¡ç®—å¤æ‚åº¦
                complexity = self._calculate_simple_complexity(func_content, lang)
                
                # åˆ¤æ–­æ˜¯å¦è·³è¿‡
                if complexity['should_skip']:
                    skipped_functions.append({
                        'name': func_name,
                        'language': lang,
                        'cyclomatic': complexity['cyclomatic'],
                        'cognitive': complexity['cognitive']
                    })
                    print(f"  â­ï¸  è·³è¿‡ç®€å•å‡½æ•°: {func_name} (åœˆ:{complexity['cyclomatic']}, è®¤çŸ¥:{complexity['cognitive']})")
                else:
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦é™ä½è¿­ä»£æ¬¡æ•°
                    if complexity.get('should_reduce_iterations', False):
                        func['reduced_iterations'] = True  # æ ‡è®°éœ€è¦é™ä½è¿­ä»£æ¬¡æ•°
                        reduced_iteration_functions.append({
                            'name': func_name,
                            'language': lang,
                            'cyclomatic': complexity['cyclomatic'],
                            'cognitive': complexity['cognitive']
                        })
                        print(f"  ğŸ”„ ä¸­ç­‰å¤æ‚å‡½æ•°(é™ä½è¿­ä»£): {func_name} (åœˆ:{complexity['cyclomatic']}, è®¤çŸ¥:{complexity['cognitive']})")
                    else:
                        print(f"  âœ… ä¿ç•™å¤æ‚å‡½æ•°: {func_name} (åœˆ:{complexity['cyclomatic']}, è®¤çŸ¥:{complexity['cognitive']})")
                    
                    filtered_functions[lang].append(func)
                    total_filtered += 1
        
        # è¾“å‡ºè¿‡æ»¤ç»Ÿè®¡
        skip_ratio = (total_original - total_filtered) / total_original * 100 if total_original > 0 else 0
        
        print(f"\nğŸ“Š è¿‡æ»¤å®Œæˆç»Ÿè®¡:")
        print(f"  åŸå§‹å‡½æ•°æ•°: {total_original}")
        print(f"  è¿‡æ»¤åå‡½æ•°æ•°: {total_filtered}")
        print(f"  è·³è¿‡å‡½æ•°æ•°: {len(skipped_functions)}")
        print(f"  é™ä½è¿­ä»£å‡½æ•°æ•°: {len(reduced_iteration_functions)}")
        print(f"  èŠ‚çœæ‰«ææ—¶é—´: {skip_ratio:.1f}%")
        
        # æ˜¾ç¤ºä¿ç•™çš„å‡½æ•°åˆ†å¸ƒ
        print(f"\nğŸ¯ ä¿ç•™æ‰«æçš„å‡½æ•°åˆ†å¸ƒ:")
        for lang, funcs in filtered_functions.items():
            if funcs:
                print(f"  ğŸ“‹ {lang}: {len(funcs)} ä¸ªå‡½æ•°éœ€è¦æ‰«æ")
        
        # æ˜¾ç¤ºè·³è¿‡çš„å‡½æ•°åˆ—è¡¨ï¼ˆå¦‚æœä¸å¤šçš„è¯ï¼‰
        if len(skipped_functions) <= 10:
            print(f"\nâ­ï¸  è·³è¿‡çš„ç®€å•å‡½æ•°åˆ—è¡¨:")
            for func in skipped_functions:
                print(f"  â€¢ {func['language']}.{func['name']} (åœˆ:{func['cyclomatic']}, è®¤çŸ¥:{func['cognitive']})")
        elif skipped_functions:
            print(f"\nâ­ï¸  è·³è¿‡äº† {len(skipped_functions)} ä¸ªç®€å•å‡½æ•° (è®¤çŸ¥å¤æ‚åº¦=0ä¸”åœˆå¤æ‚åº¦â‰¤2ï¼Œæˆ–åœˆå¤æ‚åº¦=2ä¸”è®¤çŸ¥å¤æ‚åº¦=1ï¼Œæˆ–åœˆå¤æ‚åº¦=3ä¸”è®¤çŸ¥å¤æ‚åº¦=2)")
        
        # æ˜¾ç¤ºé™ä½è¿­ä»£æ¬¡æ•°çš„å‡½æ•°åˆ—è¡¨
        if reduced_iteration_functions:
            print(f"\nğŸ”„ é™ä½è¿­ä»£æ¬¡æ•°çš„ä¸­ç­‰å¤æ‚å‡½æ•°åˆ—è¡¨:")
            for func in reduced_iteration_functions:
                print(f"  â€¢ {func['language']}.{func['name']} (åœˆ:{func['cyclomatic']}, è®¤çŸ¥:{func['cognitive']}) â†’ è¿­ä»£æ¬¡æ•°é™ä½åˆ°4æ¬¡")
        
        return filtered_functions
    
    def convert_tasks_to_project_tasks_v3(self, tasks: List[Dict]) -> List[Project_Task]:
        """å°†ä»»åŠ¡æ•°æ®è½¬æ¢ä¸ºProject_Taskå®ä½“ï¼ˆV3ç‰ˆæœ¬ï¼‰"""
        project_tasks = []
        
        for task in tasks:
            root_function = task['root_function']
            rule_list = task['rule_list']
            downstream_content = task.get('downstream_content', '')
            
            # æ„å»ºbusiness_flow_code: root funcçš„å†…å®¹ + æ‰€æœ‰downstreamçš„å†…å®¹
            business_flow_code = root_function.get('content', '')
            if downstream_content:
                business_flow_code += '\n\n' + downstream_content
            
            # åˆ›å»ºProject_Taskå®ä¾‹
            # scan_recordå°†åœ¨validationä¸­èµ‹å€¼
            
            # åˆ›å»º Project_Taskå®ä¾‹ï¼ˆUUIDå°†è‡ªåŠ¨ç”Ÿæˆï¼‰
            project_task = Project_Task(
                project_id=self.taskmgr.project_id,
                name=root_function.get('name', ''),  # åˆçº¦å+å‡½æ•°åç”¨ç‚¹è¿æ¥
                content=root_function.get('content', ''),  # root functionçš„å†…å®¹
                rule=json.dumps(rule_list, ensure_ascii=False, indent=2),  # åŸå§‹çš„list
                rule_key=task.get('rule_key', ''),  # è§„åˆ™key
                start_line=str(root_function.get('start_line', '')),
                end_line=str(root_function.get('end_line', '')),
                relative_file_path=root_function.get('relative_file_path', ''),
                absolute_file_path=root_function.get('absolute_file_path', ''),
                business_flow_code=business_flow_code
            )
            
            project_tasks.append(project_task)
        
        return project_tasks
    
    def create_database_tasks_v3(self, project_tasks: List[Project_Task]):
        """å°†Project_Taskå®ä½“å­˜å‚¨åˆ°æ•°æ®åº“ï¼ˆV3ç‰ˆæœ¬ï¼‰"""
        print(f"ğŸ’¾ å¼€å§‹å­˜å‚¨ {len(project_tasks)} ä¸ªä»»åŠ¡åˆ°æ•°æ®åº“...")
        
        success_count = 0
        for project_task in project_tasks:
            try:
                self.taskmgr.save_task(project_task)
                success_count += 1
            except Exception as e:
                print(f"âš ï¸ ä¿å­˜ä»»åŠ¡å¤±è´¥: {project_task.name} - {str(e)}")
        
        print(f"âœ… æˆåŠŸå­˜å‚¨ {success_count}/{len(project_tasks)} ä¸ªä»»åŠ¡")

    def extract_downstream_to_deepest(self, func_name: str, visited: set = None, depth: int = 0, max_depth: int = 10) -> List[Dict]:
        """æ·±åº¦æå–æŸä¸ªå‡½æ•°çš„æ‰€æœ‰ä¸‹æ¸¸å‡½æ•°åˆ°æœ€æ·±å±‚
        
        Args:
            func_name: èµ·å§‹å‡½æ•°å
            visited: å·²è®¿é—®çš„å‡½æ•°é›†åˆï¼ˆé¿å…å¾ªç¯ï¼‰
            depth: å½“å‰æ·±åº¦
            max_depth: æœ€å¤§æ·±åº¦é™åˆ¶
            
        Returns:
            List[Dict]: ä¸‹æ¸¸å‡½æ•°é“¾è¡¨ï¼ŒåŒ…å«æ·±åº¦ä¿¡æ¯
        """
        if visited is None:
            visited = set()
        
        if func_name in visited or depth > max_depth:
            return []
        
        visited.add(func_name)
        downstream_chain = []
        
        # ä½¿ç”¨æ–°çš„è°ƒç”¨æ ‘æ ¼å¼æŸ¥æ‰¾å½“å‰å‡½æ•°çš„ä¸‹æ¸¸å‡½æ•°
        for call_tree in self.call_trees:
            # ä½¿ç”¨å®Œæ•´çš„å‡½æ•°ååŒ¹é…ï¼Œé€‚é…æ–°çš„ filename.function_name æ ¼å¼
            if call_tree.get('function_name') == func_name:
                relationships = call_tree.get('relationships', {})
                downstream_funcs = relationships.get('downstream', {}).get(func_name, set())
                
                for downstream_func in downstream_funcs:
                    # æ‰¾åˆ°ä¸‹æ¸¸å‡½æ•°çš„å®Œæ•´ä¿¡æ¯
                    for func in self.functions_to_check:
                        if func['name'] == downstream_func:
                            downstream_info = {
                                'function': func,
                                'depth': depth + 1,
                                'parent': func_name
                            }
                            downstream_chain.append(downstream_info)
                            
                            # é€’å½’è·å–æ›´æ·±å±‚çš„ä¸‹æ¸¸å‡½æ•°
                            deeper_downstream = self.extract_downstream_to_deepest(
                                func['name'], visited.copy(), depth + 1, max_depth
                            )
                            downstream_chain.extend(deeper_downstream)
                            break
                break
        
        return downstream_chain

    def create_public_function_tasks_v3(self, max_depth: int = 5) -> List[Dict]:
        """ä¸ºæ¯ä¸ªpublicå‡½æ•°åˆ›å»ºæ–°ç‰ˆä»»åŠ¡ï¼ˆV3ç‰ˆæœ¬ï¼‰
        ä½¿ç”¨call treeè·å–downstreamå†…å®¹ï¼Œæ ¹æ®base_iteration_countåˆ›å»ºå¤šä¸ªä»»åŠ¡
        
        æ ¹æ®scan_modeçš„ä¸åŒï¼š
        - PURE_SCAN: å¿½ç•¥checklistï¼Œä¸ºæ¯ä¸ªpublicå‡½æ•°åˆ›å»º base_iteration_count ä¸ªä»»åŠ¡
        - å…¶ä»–æ¨¡å¼: ä¸ºæ¯ä¸ªpublicå‡½æ•° + æ¯ä¸ªrule_key åˆ›å»º base_iteration_count ä¸ªä»»åŠ¡
        
        Args:
            max_depth: æœ€å¤§æ·±åº¦é™åˆ¶
            
        Returns:
            List[Dict]: ä»»åŠ¡åˆ—è¡¨ï¼Œæ¯ä¸ªä»»åŠ¡éƒ½æœ‰å”¯ä¸€çš„UUID
        """
        print("ğŸš€ å¼€å§‹åˆ›å»ºæ–°ç‰ˆä»»åŠ¡ï¼ˆV3ï¼‰...")
        
        # è·å–æ‰«æé…ç½®
        scan_config = ConfigUtils.get_scan_configuration()
        scan_mode = scan_config['scan_mode']
        base_iteration_count = scan_config['base_iteration_count']
        
        print(f"ğŸ“‹ æ‰«ææ¨¡å¼: {scan_mode}")
        print(f"ğŸ”„ åŸºç¡€è¿­ä»£æ¬¡æ•°: {base_iteration_count}")
        
        # è·å–æ‰€æœ‰publicå‡½æ•°
        public_functions_by_lang = self.find_public_functions_by_language()
        
        # ğŸ¯ åŸºäºå¤æ‚åº¦è¿‡æ»¤å‡½æ•°ï¼ˆåŸºäºfishcakeé¡¹ç›®åˆ†æä¼˜åŒ–ï¼‰
        # è¿‡æ»¤ç­–ç•¥ï¼šè®¤çŸ¥å¤æ‚åº¦=0 ä¸” åœˆå¤æ‚åº¦â‰¤2 çš„ç®€å•å‡½æ•°å°†è¢«è·³è¿‡
        if os.getenv("COMPLEXITY_ANALYSIS_ENABLED", "False").lower() == "true":
            public_functions_by_lang = self.filter_functions_by_complexity(public_functions_by_lang)
        
        tasks = []
        task_id = 0
        
        # æ ¹æ®scan_modeå†³å®šä»»åŠ¡åˆ›å»ºé€»è¾‘
        if scan_mode == 'PURE_SCAN':
            print("ğŸ¯ PURE_SCANæ¨¡å¼: å¿½ç•¥æ‰€æœ‰checklist")
            
            for lang, public_funcs in public_functions_by_lang.items():
                if not public_funcs:
                    continue
                    
                print(f"\nğŸ“‹ å¤„ç† {lang} è¯­è¨€çš„ {len(public_funcs)} ä¸ªpublicå‡½æ•°...")
                
                for public_func in public_funcs:
                    func_name = public_func['name']
                    
                    # print(f"  ğŸ” åˆ†æpublicå‡½æ•°: {func_name}")
                    
                    # ä½¿ç”¨call treeè·å–downstreamå†…å®¹
                    downstream_content = self.get_downstream_content_with_call_tree(func_name, max_depth)
                    
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦é™ä½è¿­ä»£æ¬¡æ•°
                    actual_iteration_count = base_iteration_count
                    if public_func.get('reduced_iterations', False):
                        actual_iteration_count = 4  # é™ä½åˆ°4æ¬¡
                        print(f"  ğŸ”„ æ£€æµ‹åˆ°ä¸­ç­‰å¤æ‚å‡½æ•°ï¼Œè¿­ä»£æ¬¡æ•°é™ä½åˆ°{actual_iteration_count}æ¬¡")
                    
                    # ä¸ºæ¯ä¸ªpublicå‡½æ•°åˆ›å»ºå®é™…è¿­ä»£æ¬¡æ•°ä¸ªä»»åŠ¡
                    for iteration in range(actual_iteration_count):
                        task_data = {
                            'task_id': task_id,
                            'iteration_index': iteration + 1,
                            'language': lang,
                            'root_function': public_func,
                            'rule_key': 'PURE_SCAN',
                            'rule_list': [],  # PURE_SCANæ¨¡å¼ä¸‹æ— checklist
                            'downstream_content': downstream_content,
                            'max_depth': max_depth,
                            'task_type': 'public_function_pure_scan'
                        }
                        
                        tasks.append(task_data)
                        task_id += 1
                        
                        print(f"    âœ… åˆ›å»ºä»»åŠ¡: PURE_SCAN - è¿­ä»£{iteration + 1}/{actual_iteration_count}")
        
        else:
            # éPURE_SCANæ¨¡å¼ï¼šä½¿ç”¨checklist
            print(f"ğŸ“„ æ ‡å‡†æ¨¡å¼: ä½¿ç”¨checklist")
            
            # è·å–æ‰€æœ‰æ£€æŸ¥è§„åˆ™
            all_checklists = VulPromptCommon.vul_prompt_common_new()
            
            for lang, public_funcs in public_functions_by_lang.items():
                if not public_funcs:
                    continue
                    
                print(f"\nğŸ“‹ å¤„ç† {lang} è¯­è¨€çš„ {len(public_funcs)} ä¸ªpublicå‡½æ•°...")
                
                for public_func in public_funcs:
                    func_name = public_func['name']
                    
                    # print(f"  ğŸ” åˆ†æpublicå‡½æ•°: {func_name}")
                    
                    # ä½¿ç”¨call treeè·å–downstreamå†…å®¹
                    downstream_content = self.get_downstream_content_with_call_tree(func_name, max_depth)

                    # åŠ ä¸Šroot func çš„content
                    downstream_content = public_func['content'] + '\n\n' + downstream_content
                    
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦é™ä½è¿­ä»£æ¬¡æ•°
                    actual_iteration_count = base_iteration_count
                    if public_func.get('reduced_iterations', False):
                        actual_iteration_count = 4  # é™ä½åˆ°4æ¬¡
                        print(f"  ğŸ”„ æ£€æµ‹åˆ°ä¸­ç­‰å¤æ‚å‡½æ•°ï¼Œè¿­ä»£æ¬¡æ•°é™ä½åˆ°{actual_iteration_count}æ¬¡")
                    
                    # ä¸ºæ¯ä¸ªæ£€æŸ¥ç±»å‹åˆ›å»ºå®é™…è¿­ä»£æ¬¡æ•°ä¸ªä»»åŠ¡
                    for rule_key, rule_list in all_checklists.items():
                        for iteration in range(actual_iteration_count):
                            task_data = {
                                'task_id': task_id,
                                'iteration_index': iteration + 1,
                                'language': lang,
                                'root_function': public_func,
                                'rule_key': rule_key,
                                'rule_list': rule_list,
                                'downstream_content': downstream_content,
                                'max_depth': max_depth,
                                'task_type': 'public_function_checklist_scan'
                            }
                            
                            tasks.append(task_data)
                            task_id += 1
                        
        if os.getenv("SCAN_MODE_AVA", "False").lower() == "true":
            #==========æ–°çš„æ£€æµ‹æ¨¡å¼AVA(Assumption Violation Analysis)==========
            #åœ¨è¿™ä¸ªæ¨¡å¼ä¸‹ä¼šè¿›è¡Œä»£ç å‡è®¾è¯„ä¼°ï¼Œå¹¶æ ¹æ®å‡è®¾ç”Ÿæˆchecklistï¼Œç„¶åæ”¾å…¥taskåè¿›è¡Œæ‰«æ
            print("ğŸ¯ AVAæ¨¡å¼: è¿›è¡Œä»£ç å‡è®¾è¯„ä¼°checklistç”Ÿæˆ")
            # è¾“å…¥å¾…æµ‹ä»£ç ï¼Œè¾“å‡ºchecklistï¼Œå¯¹åº”çš„rule keyå«åš assumption_violation
            # ç„¶åæ ¹æ®checklistç”Ÿæˆtaskï¼Œæ”¾å…¥task
            
            # ä½¿ç”¨å¤šçº¿ç¨‹å¤„ç†å‡½æ•°åˆ†æ
            self._process_ava_mode_with_threading(public_functions_by_lang, max_depth, tasks, task_id)


        
        print(f"\nğŸ‰ ä»»åŠ¡åˆ›å»ºå®Œæˆï¼")
        print(f"  æ€»è®¡: {len(tasks)} ä¸ªä»»åŠ¡")
        print(f"  æ‰«ææ¨¡å¼: {scan_mode}")
        print(f"  åŸºç¡€è¿­ä»£æ¬¡æ•°: {base_iteration_count}")
        print(f"  æœ€å¤§æ·±åº¦: {max_depth}")
        
        return tasks
    
    def get_downstream_content_with_call_tree(self, func_name: str, max_depth: int = 5) -> str:
        """ä½¿ç”¨call treeè·å–å‡½æ•°çš„downstreamå†…å®¹ï¼ˆä½¿ç”¨ç»Ÿä¸€çš„æå–é€»è¾‘ï¼‰
        
        Args:
            func_name: å‡½æ•°å
            max_depth: æœ€å¤§æ·±åº¦
            
        Returns:
            str: æ‹¼æ¥çš„downstreamå†…å®¹
        """
        if hasattr(self.project_audit, 'call_trees') and self.project_audit.call_trees:
            try:
                from tree_sitter_parsing.advanced_call_tree_builder import AdvancedCallTreeBuilder
                builder = AdvancedCallTreeBuilder()
                # ä½¿ç”¨ç»Ÿä¸€çš„å†…å®¹æå–æ–¹æ³•
                return builder.get_call_content_with_direction(
                    self.project_audit.call_trees, func_name, 'downstream', max_depth
                )
            except Exception as e:
                print(f"    âš ï¸ ä½¿ç”¨ç»Ÿä¸€call treeæå–å¤±è´¥: {e}ï¼Œä½¿ç”¨ç®€åŒ–æ–¹æ³•")
                contents = self._get_downstream_content_fallback(func_name, max_depth)
                return '\n\n'.join(contents)
        else:
            contents = self._get_downstream_content_fallback(func_name, max_depth)
            return '\n\n'.join(contents)
    
    def get_upstream_content_with_call_tree(self, func_name: str, max_depth: int = 5) -> str:
        """ä½¿ç”¨call treeè·å–å‡½æ•°çš„upstreamå†…å®¹ï¼ˆä½¿ç”¨ç»Ÿä¸€çš„æå–é€»è¾‘ï¼‰
        
        Args:
            func_name: å‡½æ•°å
            max_depth: æœ€å¤§æ·±åº¦
            
        Returns:
            str: æ‹¼æ¥çš„upstreamå†…å®¹
        """
        if hasattr(self.project_audit, 'call_trees') and self.project_audit.call_trees:
            try:
                from tree_sitter_parsing.advanced_call_tree_builder import AdvancedCallTreeBuilder
                builder = AdvancedCallTreeBuilder()
                # ä½¿ç”¨ç»Ÿä¸€çš„å†…å®¹æå–æ–¹æ³•
                return builder.get_call_content_with_direction(
                    self.project_audit.call_trees, func_name, 'upstream', max_depth
                )
            except Exception as e:
                print(f"    âš ï¸ ä½¿ç”¨ç»Ÿä¸€call treeæå–upstreamå¤±è´¥: {e}")
                return ""
        else:
            return ""
    
    def _extract_contents_from_tree(self, tree_node: Dict) -> List[str]:
        """ä»treeèŠ‚ç‚¹ä¸­æå–æ‰€æœ‰å‡½æ•°å†…å®¹"""
        contents = []
        
        if tree_node.get('function_data'):
            function_data = tree_node['function_data']
            if function_data.get('content'):
                contents.append(function_data['content'])
        
        # é€’å½’å¤„ç†å­èŠ‚ç‚¹
        for child in tree_node.get('children', []):
            contents.extend(self._extract_contents_from_tree(child))
        
        return contents
    
    def _get_downstream_content_fallback(self, func_name: str, max_depth: int) -> List[str]:
        """ç®€åŒ–çš„downstreamå†…å®¹è·å–æ–¹æ³•"""
        downstream_chain = self.extract_downstream_to_deepest(func_name)
        contents = []
        
        for item in downstream_chain:
            if item.get('depth', 0) <= max_depth:
                function = item.get('function')
                if function and function.get('content'):
                    contents.append(function['content'])
        
        return contents
    
    def create_public_function_tasks(self) -> List[Dict]:
        """ä¸ºæ¯ä¸ªpublicå‡½æ•°åˆ›å»ºåŸºäºdownstreamæ·±åº¦æ‰«æçš„ä»»åŠ¡ï¼ˆæ—§ç‰ˆæœ¬ï¼Œå·²åºŸå¼ƒï¼‰
        
        Returns:
            List[Dict]: ä»»åŠ¡åˆ—è¡¨
        """
        print("ğŸš€ å¼€å§‹åŸºäºpublicå‡½æ•°downstreamæ·±åº¦æ‰«æåˆ›å»ºä»»åŠ¡...")
        
        # è·å–æ‰€æœ‰publicå‡½æ•°
        public_functions_by_lang = self.find_public_functions_by_language()
        
        # ğŸ¯ åŸºäºå¤æ‚åº¦è¿‡æ»¤å‡½æ•°ï¼ˆåŸºäºfishcakeé¡¹ç›®åˆ†æä¼˜åŒ–ï¼‰
        # è¿‡æ»¤ç­–ç•¥ï¼šè®¤çŸ¥å¤æ‚åº¦=0 ä¸” åœˆå¤æ‚åº¦â‰¤2 çš„ç®€å•å‡½æ•°å°†è¢«è·³è¿‡
        public_functions_by_lang = self.filter_functions_by_complexity(public_functions_by_lang)
        
        tasks = []
        task_id = 0
        
        for lang, public_funcs in public_functions_by_lang.items():
            if not public_funcs:
                continue
                
            print(f"\nğŸ“‹ å¤„ç† {lang} è¯­è¨€çš„ {len(public_funcs)} ä¸ªpublicå‡½æ•°...")
            
            for public_func in public_funcs:
                func_name = public_func['name']
                
                # print(f"  ğŸ” åˆ†æpublicå‡½æ•°: {func_name}")
                
                # æå–è¯¥publicå‡½æ•°çš„æ‰€æœ‰downstreamå‡½æ•°
                downstream_chain = self.extract_downstream_to_deepest(func_name)
                
                if downstream_chain:
                    # æ„å»ºä»»åŠ¡æ•°æ®
                    all_functions = [public_func] + [item['function'] for item in downstream_chain]
                    
                    # æŒ‰æ·±åº¦åˆ†ç»„
                    depth_groups = {}
                    depth_groups[0] = [public_func]
                    
                    for item in downstream_chain:
                        depth = item['depth']
                        if depth not in depth_groups:
                            depth_groups[depth] = []
                        depth_groups[depth].append(item['function'])
                    
                    max_depth = max(depth_groups.keys()) if depth_groups else 0
                    
                    task_data = {
                        'task_id': task_id,
                        'language': lang,
                        'root_function': public_func,
                        'downstream_chain': downstream_chain,
                        'all_functions': all_functions,
                        'depth_groups': depth_groups,
                        'max_depth': max_depth,
                        'total_functions': len(all_functions),
                        'task_type': 'public_downstream_scan'
                    }
                    
                    tasks.append(task_data)
                    task_id += 1
                    
                    print(f"    âœ… åˆ›å»ºä»»åŠ¡: {len(all_functions)} ä¸ªå‡½æ•°, æœ€å¤§æ·±åº¦: {max_depth}")
                    for depth, funcs in depth_groups.items():
                        print(f"      æ·±åº¦ {depth}: {len(funcs)} ä¸ªå‡½æ•°")
                else:
                    # å³ä½¿æ²¡æœ‰ä¸‹æ¸¸å‡½æ•°ï¼Œä¹Ÿä¸ºå•ä¸ªpublicå‡½æ•°åˆ›å»ºä»»åŠ¡
                    task_data = {
                        'task_id': task_id,
                        'language': lang,
                        'root_function': public_func,
                        'downstream_chain': [],
                        'all_functions': [public_func],
                        'depth_groups': {0: [public_func]},
                        'max_depth': 0,
                        'total_functions': 1,
                        'task_type': 'public_single_scan'
                    }
                    
                    tasks.append(task_data)
                    task_id += 1
                    
                    print(f"    âœ… åˆ›å»ºå•å‡½æ•°ä»»åŠ¡: {func_name}")
        
        print(f"\nğŸ‰ æ€»å…±åˆ›å»ºäº† {len(tasks)} ä¸ªåŸºäºpublicå‡½æ•°downstreamçš„æ‰«æä»»åŠ¡")
        return tasks

    def create_database_tasks(self, tasks: List[Dict]) -> None:
        """å°†ä»»åŠ¡æ•°æ®å­˜å‚¨åˆ°æ•°æ®åº“
        
        Args:
            tasks: ä»»åŠ¡åˆ—è¡¨
        """
        print("ğŸ’¾ å¼€å§‹å°†ä»»åŠ¡å­˜å‚¨åˆ°æ•°æ®åº“...")
        
        for task_data in tasks:
            try:
                # æ„å»ºä»»åŠ¡æè¿°
                root_func = task_data['root_function']
                description = f"[{task_data['language'].upper()}] Publicå‡½æ•° {root_func['name']} åŠå…¶ {task_data['total_functions']-1} ä¸ªä¸‹æ¸¸å‡½æ•°çš„æ·±åº¦æ‰«æ"
                
                # æ„å»ºå‡½æ•°åˆ—è¡¨æè¿°
                functions_desc = [f"Root: {root_func['name']}"]
                for depth, funcs in task_data['depth_groups'].items():
                    if depth > 0:
                        func_names = [f['name'] for f in funcs]
                        functions_desc.append(f"æ·±åº¦{depth}: {', '.join(func_names)}")
                
                functions_detail = "; ".join(functions_desc)
                
                # åˆ›å»ºä»»åŠ¡å¯¹è±¡ - ä½¿ç”¨Project_Taskå®ä½“çš„æ­£ç¡®å‚æ•°
                task = Project_Task(
                    project_id=self.project_audit.project_id,
                    name=root_func['name'],
                    content=root_func.get('content', ''),
                    keyword='downstream_scan',
                    business_type='vulnerability_scan',
                    sub_business_type=task_data['language'],
                    function_type='public_function_downstream',
                    rule=f"Scan public function {root_func['name']} and its downstream call chain",
                    description=description,
                    start_line=str(root_func.get('start_line', '')),
                    end_line=str(root_func.get('end_line', '')),
                    relative_file_path=root_func.get('relative_file_path', ''),
                    absolute_file_path=root_func.get('absolute_file_path', ''),
                    title=f"Public Function Downstream Scan: {root_func['name']}",
                    business_flow_code=str(task_data['all_functions'])
                )
                
                # ä¿å­˜åˆ°æ•°æ®åº“
                self.taskmgr.add_task_in_one(task)
                
                print(f"  âœ… ä¿å­˜ä»»åŠ¡: {description}")
                
            except Exception as e:
                print(f"âŒ ä¿å­˜ä»»åŠ¡å¤±è´¥: {e}")
                continue
        
        print(f"ğŸ’¾ ä»»åŠ¡å­˜å‚¨å®Œæˆï¼Œæ€»å…± {len(tasks)} ä¸ªä»»åŠ¡")

    def process_for_common_project_mode(self, max_depth: int = 5) -> Dict:
        """æ–°çš„COMMON_PROJECTæ¨¡å¼å¤„ç†é€»è¾‘ - ä½¿ç”¨V3ç‰ˆæœ¬"""
        
        print("ğŸ¯ å¯åŠ¨V3ç‰ˆæœ¬çš„Planningæ¨¡å¼ï¼ˆä½¿ç”¨call treeå’Œall_checklistsï¼‰")
        print("="*60)
        
        try:
            # 0. æ£€æŸ¥project_idæ˜¯å¦å·²ç»æœ‰ä»»åŠ¡
            existing_tasks = self.taskmgr.query_task_by_project_id(self.project_audit.project_id)
            if existing_tasks and len(existing_tasks) > 0:
                print(f"âš ï¸ é¡¹ç›® {self.project_audit.project_id} å·²ç»å­˜åœ¨ {len(existing_tasks)} ä¸ªä»»åŠ¡ï¼Œè·³è¿‡ä»»åŠ¡åˆ›å»º")
                return {
                    'success': True,
                    'message': f'é¡¹ç›® {self.project_audit.project_id} å·²å­˜åœ¨ä»»åŠ¡ï¼Œè·³è¿‡åˆ›å»º',
                    'tasks_created': 0,
                    'project_tasks_created': len(existing_tasks),
                    'tasks_by_language': {},
                    'max_depth_used': max_depth,
                    'skipped': True
                }
            
            # 1. ä½¿ç”¨V3æ–¹æ³•åˆ›å»ºä»»åŠ¡
            tasks = self.create_public_function_tasks_v3(max_depth)
            
            if not tasks:
                print("âš ï¸ æœªåˆ›å»ºä»»ä½•ä»»åŠ¡ï¼Œå¯èƒ½æ²¡æœ‰æ‰¾åˆ°publicå‡½æ•°")
                return {
                    'success': False,
                    'message': 'æœªæ‰¾åˆ°publicå‡½æ•°',
                    'tasks_created': 0
                }
            
            # 2. è½¬æ¢å¹¶å­˜å‚¨ä»»åŠ¡åˆ°æ•°æ®åº“
            project_tasks = self.convert_tasks_to_project_tasks_v3(tasks)
            self.create_database_tasks_v3(project_tasks)
            
            # 3. è¿”å›å¤„ç†ç»“æœ
            result = {
                'success': True,
                'message': 'Planningä»»åŠ¡åˆ›å»ºæˆåŠŸ',
                'tasks_created': len(tasks),
                'project_tasks_created': len(project_tasks),
                'tasks_by_language': {},
                'max_depth_used': max_depth
            }
            
            # ç»Ÿè®¡å„è¯­è¨€ä»»åŠ¡æ•°
            for task in tasks:
                lang = task['language']
                if lang not in result['tasks_by_language']:
                    result['tasks_by_language'][lang] = 0
                result['tasks_by_language'][lang] += 1
            
            print(f"\nğŸ‰ V3 Planningå¤„ç†å®Œæˆ:")
            print(f"  ğŸ“Š åˆ›å»ºä»»åŠ¡: {result['tasks_created']} ä¸ª")
            print(f"  ğŸ’¾ å­˜å‚¨åˆ°æ•°æ®åº“: {result['project_tasks_created']} ä¸ª")
            print(f"  ğŸ“ ä½¿ç”¨æœ€å¤§æ·±åº¦: {result['max_depth_used']}")
            print(f"  ğŸŒ è¯­è¨€åˆ†å¸ƒ: {result['tasks_by_language']}")
            print(f"  ğŸ” ä½¿ç”¨call treeè·å–downstreamå†…å®¹")
            print(f"  ğŸ“‹ ä½¿ç”¨all_checklistsç”Ÿæˆæ£€æŸ¥è§„åˆ™")
            
            return result
            
        except Exception as e:
            print(f"âŒ Planningå¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            
            return {
                'success': False,
                'message': f'Planningå¤„ç†å¤±è´¥: {str(e)}',
                'tasks_created': 0
            }

    def search_functions_by_name(self, name_query, k=5):
        """æŒ‰åç§°æœç´¢å‡½æ•°ï¼ˆä½¿ç”¨RAGæˆ–ç®€åŒ–æœç´¢ï¼‰"""
        if self.rag_processor:
            return self.rag_processor.search_functions_by_name(name_query, k)
        else:
            # ç®€åŒ–çš„åç§°æœç´¢
            results = []
            for func in self.functions_to_check:
                if name_query.lower() in func.get('name', '').lower():
                    results.append({
                        'function': func,
                        'score': 0.8,  # ç®€åŒ–è¯„åˆ†
                        'reason': f"åç§°åŒ¹é…: {name_query}"
                    })
                    if len(results) >= k:
                        break
            return results

    def search_functions_by_content(self, content_query, k=5):
        """æŒ‰å†…å®¹æœç´¢å‡½æ•°ï¼ˆä½¿ç”¨RAGæˆ–ç®€åŒ–æœç´¢ï¼‰"""
        if self.rag_processor:
            return self.rag_processor.search_functions_by_content(content_query, k)
        else:
            # ç®€åŒ–çš„å†…å®¹æœç´¢
            results = []
            for func in self.functions_to_check:
                if content_query.lower() in func.get('content', '').lower():
                    results.append({
                        'function': func,
                        'score': 0.7,  # ç®€åŒ–è¯„åˆ†
                        'reason': f"å†…å®¹åŒ¹é…: {content_query}"
                    })
                    if len(results) >= k:
                        break
            return results

    def get_available_rag_types(self) -> Dict[str, str]:
        """è·å–å¯ç”¨çš„RAGç±»å‹åˆ—è¡¨
        
        Returns:
            Dict[str, str]: RAGç±»å‹åç§°å’Œæè¿°çš„å­—å…¸
        """
        if not self.rag_processor:
            return {}
        
        return {
            # åŸºç¡€RAGç±»å‹
            'name': 'åå­—æ£€ç´¢ - åŸºäºå‡½æ•°åç§°çš„ç²¾ç¡®åŒ¹é…',
            'content': 'å†…å®¹æ£€ç´¢ - åŸºäºå‡½æ•°æºä»£ç å†…å®¹çš„è¯­ä¹‰ç›¸ä¼¼æ€§',
            'natural': 'è‡ªç„¶è¯­è¨€æ£€ç´¢ - åŸºäºAIç”Ÿæˆçš„åŠŸèƒ½æè¿°çš„è¯­ä¹‰ç†è§£',
            
            # å…³ç³»å‹RAGç±»å‹
            'upstream': 'ä¸Šæ¸¸å‡½æ•°æ£€ç´¢ - åŸºäºè°ƒç”¨æ­¤å‡½æ•°çš„ä¸Šæ¸¸å‡½æ•°å†…å®¹',
            'downstream': 'ä¸‹æ¸¸å‡½æ•°æ£€ç´¢ - åŸºäºæ­¤å‡½æ•°è°ƒç”¨çš„ä¸‹æ¸¸å‡½æ•°å†…å®¹',
            
            # ä¸“é—¨çš„å…³ç³»è¡¨RAGç±»å‹
            'upstream_natural': 'ä¸Šæ¸¸è‡ªç„¶è¯­è¨€å…³ç³»æ£€ç´¢ - åŸºäºä¸Šæ¸¸å‡½æ•°çš„è‡ªç„¶è¯­è¨€æè¿°',
            'downstream_natural': 'ä¸‹æ¸¸è‡ªç„¶è¯­è¨€å…³ç³»æ£€ç´¢ - åŸºäºä¸‹æ¸¸å‡½æ•°çš„è‡ªç„¶è¯­è¨€æè¿°',
            'upstream_content': 'ä¸Šæ¸¸å†…å®¹å…³ç³»æ£€ç´¢ - åŸºäºä¸Šæ¸¸å‡½æ•°çš„ä»£ç å†…å®¹',
            'downstream_content': 'ä¸‹æ¸¸å†…å®¹å…³ç³»æ£€ç´¢ - åŸºäºä¸‹æ¸¸å‡½æ•°çš„ä»£ç å†…å®¹',
            
            # æ–‡ä»¶çº§RAGç±»å‹
            'file_content': 'æ–‡ä»¶å†…å®¹æ£€ç´¢ - åŸºäºæ•´ä¸ªæ–‡ä»¶çš„å†…å®¹',
            'file_natural': 'æ–‡ä»¶è‡ªç„¶è¯­è¨€æ£€ç´¢ - åŸºäºæ–‡ä»¶çš„è‡ªç„¶è¯­è¨€æè¿°'
        }
    
    def analyze_code_assumptions(self, downstream_content: str) -> str:
        """ä½¿ç”¨Claudeåˆ†æä»£ç ä¸­çš„ä¸šåŠ¡é€»è¾‘å‡è®¾
        
        Args:
            downstream_content: ä¸‹æ¸¸ä»£ç å†…å®¹
            
        Returns:
            str: Claudeåˆ†æçš„åŸå§‹ç»“æœ
        """
        assumption_prompt = AssumptionPrompt.get_assumption_analysis_prompt(downstream_content)
        
        try:
            print("ğŸ¤– æ­£åœ¨ä½¿ç”¨Claudeåˆ†æä»£ç å‡è®¾...")
            result = ask_claude(assumption_prompt)
            print("âœ… Claudeåˆ†æå®Œæˆ")
            return result
        except Exception as e:
            print(f"âŒ Claudeåˆ†æå¤±è´¥: {e}")
            return ""
    
    def parse_assumptions_from_text(self, raw_assumptions: str) -> List[str]:
        """ä»Claudeçš„åŸå§‹è¾“å‡ºä¸­è§£æassumptionåˆ—è¡¨
        
        Args:
            raw_assumptions: Claudeåˆ†æçš„åŸå§‹ç»“æœï¼ˆä½¿ç”¨<|ASSUMPTION_SPLIT|>åˆ†å‰²ï¼‰
            
        Returns:
            List[str]: è§£æåçš„assumptionåˆ—è¡¨
        """
        if not raw_assumptions:
            return []
            
        try:
            print("ğŸ§¹ æ­£åœ¨è§£æassumptionç»“æœ...")
            
            # ä½¿ç”¨<|ASSUMPTION_SPLIT|>åˆ†å‰²å­—ç¬¦ä¸²
            assumptions_raw = raw_assumptions.strip().split("<|ASSUMPTION_SPLIT|>")
            
            # æ¸…ç†æ¯ä¸ªassumptionï¼Œå»é™¤å‰åç©ºç™½å’Œç©ºè¡Œ
            assumptions_list = []
            for assumption in assumptions_raw:
                cleaned_assumption = assumption.strip()
                if cleaned_assumption:  # è¿‡æ»¤ç©ºå­—ç¬¦ä¸²
                    assumptions_list.append(cleaned_assumption)
            
            print(f"âœ… è§£æå®Œæˆï¼Œæå–åˆ° {len(assumptions_list)} ä¸ªå‡è®¾")
            return assumptions_list
            
        except Exception as e:
            print(f"âŒ è§£æå¤±è´¥: {e}")
            return []

    def do_planning(self):
        """æ‰§è¡Œè§„åˆ’å¤„ç† - è°ƒç”¨process_for_common_project_modeæ–¹æ³•"""
        return self.process_for_common_project_mode()
    
    def _process_ava_mode_with_threading(self, public_functions_by_lang: Dict, max_depth: int, tasks: List, task_id: int):
        """ä½¿ç”¨å¤šçº¿ç¨‹å¤„ç†AVAæ¨¡å¼çš„å‡½æ•°åˆ†æ
        
        Args:
            public_functions_by_lang: æŒ‰è¯­è¨€åˆ†ç»„çš„publicå‡½æ•°
            max_depth: æœ€å¤§æ·±åº¦
            tasks: ä»»åŠ¡åˆ—è¡¨ï¼ˆå¼•ç”¨ä¼ é€’ï¼‰
            task_id: å½“å‰ä»»åŠ¡ID
        """
        # è·å–çº¿ç¨‹æ•°é…ç½®ï¼Œé»˜è®¤ä¸º4
        max_workers = int(os.getenv("AVA_THREAD_COUNT", "4"))
        print(f"ğŸš€ ä½¿ç”¨ {max_workers} ä¸ªçº¿ç¨‹è¿›è¡Œå¹¶å‘å¤„ç†")
        
        # ä¸ºäº†çº¿ç¨‹å®‰å…¨ï¼Œä½¿ç”¨é”ä¿æŠ¤å…±äº«èµ„æº
        tasks_lock = threading.Lock()
        task_id_lock = threading.Lock()
        task_id_counter = [task_id]  # ä½¿ç”¨åˆ—è¡¨æ¥å®ç°å¼•ç”¨ä¼ é€’
        
        # æ”¶é›†æ‰€æœ‰éœ€è¦å¤„ç†çš„å‡½æ•°
        all_functions = []
        for lang, public_funcs in public_functions_by_lang.items():
            if public_funcs:
                for public_func in public_funcs:
                    all_functions.append((lang, public_func))
        
        print(f"ğŸ“‹ æ€»è®¡éœ€è¦å¤„ç† {len(all_functions)} ä¸ªå‡½æ•°")
        
        def process_single_function(lang_func_pair):
            """å¤„ç†å•ä¸ªå‡½æ•°çš„å‡è®¾åˆ†æ"""
            lang, public_func = lang_func_pair
            func_name = public_func['name']
            
            try:
                # ä½¿ç”¨call treeè·å–downstreamå†…å®¹
                downstream_content = self.get_downstream_content_with_call_tree(func_name, max_depth)
                
                # åŠ ä¸Šroot funcçš„content
                downstream_content = public_func['content'] + '\n\n' + downstream_content
                
                print(f"  ğŸ” æ­£åœ¨ä¸ºå‡½æ•° {func_name} ç”Ÿæˆå‡è®¾è¯„ä¼°æ¸…å•...")
                
                # ä½¿ç”¨Claudeåˆ†æä»£ç å‡è®¾
                raw_assumptions = self.analyze_code_assumptions(downstream_content)
                
                # è§£æåˆ†å‰²æ ¼å¼çš„ç»“æœ
                assumption_violation_checklist = self.parse_assumptions_from_text(raw_assumptions)
                
                if not assumption_violation_checklist:
                    print(f"  âš ï¸ å‡½æ•° {func_name} æœªèƒ½ç”Ÿæˆæœ‰æ•ˆçš„å‡è®¾æ¸…å•ï¼Œè·³è¿‡...")
                    return []
                
                actual_iteration_count = 2
                function_tasks = []
                
                # ä¸ºæ¯ä¸ªassumption statementåˆ›å»ºå•ç‹¬çš„ä»»åŠ¡
                for assumption_statement in assumption_violation_checklist:
                    for iteration in range(actual_iteration_count):
                        # çº¿ç¨‹å®‰å…¨åœ°è·å–task_id
                        with task_id_lock:
                            current_task_id = task_id_counter[0]
                            task_id_counter[0] += 1
                        
                        task_data = {
                            'task_id': current_task_id,
                            'iteration_index': iteration + 1,
                            'language': lang,
                            'root_function': public_func,
                            'rule_key': "assumption_violation",
                            'rule_list': assumption_statement,  # æ¯ä¸ªä»»åŠ¡åªå¤„ç†ä¸€ä¸ªassumption
                            'downstream_content': downstream_content,
                            'max_depth': max_depth,
                            'task_type': 'public_function_checklist_scan'
                        }
                        
                        function_tasks.append(task_data)
                
                total_tasks_created = len(assumption_violation_checklist) * actual_iteration_count
                print(f"  âœ… ä¸ºå‡½æ•° {func_name} åˆ›å»ºäº† {total_tasks_created} ä¸ªä»»åŠ¡ ({len(assumption_violation_checklist)} ä¸ªå‡è®¾ Ã— {actual_iteration_count} æ¬¡è¿­ä»£)")
                
                return function_tasks
                
            except Exception as e:
                print(f"  âŒ å¤„ç†å‡½æ•° {func_name} æ—¶å‡ºé”™: {e}")
                return []
        
        # ä½¿ç”¨ThreadPoolExecutorè¿›è¡Œå¹¶å‘å¤„ç†
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_function = {
                executor.submit(process_single_function, lang_func_pair): lang_func_pair
                for lang_func_pair in all_functions
            }
            
            # ä½¿ç”¨è¿›åº¦æ¡æ˜¾ç¤ºå¤„ç†è¿›åº¦
            with tqdm(total=len(all_functions), desc="å¤„ç†å‡½æ•°å‡è®¾åˆ†æ") as pbar:
                for future in as_completed(future_to_function):
                    lang_func_pair = future_to_function[future]
                    lang, public_func = lang_func_pair
                    
                    try:
                        function_tasks = future.result()
                        
                        # çº¿ç¨‹å®‰å…¨åœ°æ·»åŠ ä»»åŠ¡åˆ°ä¸»åˆ—è¡¨
                        if function_tasks:
                            with tasks_lock:
                                tasks.extend(function_tasks)
                        
                    except Exception as e:
                        func_name = public_func['name']
                        print(f"âŒ å‡½æ•° {func_name} å¤„ç†å¤±è´¥: {e}")
                    
                    pbar.update(1)
        
        print(f"ğŸ‰ å¤šçº¿ç¨‹å¤„ç†å®Œæˆï¼å…±åˆ›å»ºäº† {len([t for t in tasks if t.get('rule_key') == 'assumption_violation'])} ä¸ªAVAä»»åŠ¡") 