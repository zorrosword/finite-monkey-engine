"""
å‡è®¾éªŒè¯æ¨¡å— (Assumption Validation Analysis - AVA)

æä¾›ä»£ç å‡è®¾éªŒè¯ç›¸å…³çš„åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
- ä½¿ç”¨Claudeåˆ†æä»£ç å‡è®¾
- è§£æå‡è®¾åˆ†æç»“æœ
- å¤šçº¿ç¨‹å¤„ç†AVAæ¨¡å¼çš„å‡½æ•°åˆ†æ
- ç”Ÿæˆå‡è®¾éªŒè¯ä»»åŠ¡
"""

import os
import uuid
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict
from tqdm import tqdm

from openai_api.openai import analyze_code_assumptions
from prompt_factory.assumption_prompt import AssumptionPrompt


class AssumptionValidator:
    """å‡è®¾éªŒè¯å™¨ç±»"""
    
    def __init__(self, call_tree_utils):
        """
        åˆå§‹åŒ–å‡è®¾éªŒè¯å™¨
        
        Args:
            call_tree_utils: CallTreeUtilså®ä¾‹ï¼Œç”¨äºè·å–è°ƒç”¨æ ‘å†…å®¹
        """
        self.call_tree_utils = call_tree_utils
    
    def analyze_code_assumptions(self, downstream_content: str) -> str:
        """ä½¿ç”¨Claudeåˆ†æä»£ç ä¸­çš„ä¸šåŠ¡é€»è¾‘å‡è®¾
        
        Args:
            downstream_content: ä¸‹æ¸¸ä»£ç å†…å®¹
            
        Returns:
            str: Claudeåˆ†æçš„åŸå§‹ç»“æœ
        """
        assumption_prompt = AssumptionPrompt.get_assumption_analysis_prompt(downstream_content)
        
        try:
            print("ğŸ¤– æ­£åœ¨ä½¿ç”¨Claudeåˆ†æä»£ç å‡è®¾...")
            result = analyze_code_assumptions(assumption_prompt)
            print("âœ… Claudeåˆ†æå®Œæˆ")
            return result
        except Exception as e:
            print(f"âŒ Claudeåˆ†æå¤±è´¥: {e}")
            return ""
    
    def parse_assumptions_from_text(self, raw_assumptions: str) -> List[str]:
        """ä»Claudeçš„åŸå§‹è¾“å‡ºä¸­è§£æassumptionåˆ—è¡¨
        
        Args:
            raw_assumptions: Claudeåˆ†æçš„åŸå§‹ç»“æœï¼ˆä½¿ç”¨<|ASSUMPTION_SPLIT|>åˆ†å‰²ï¼‰
            
        Returns:
            List[str]: è§£æåçš„assumptionåˆ—è¡¨
        """
        if not raw_assumptions:
            return []
            
        try:
            print("ğŸ§¹ æ­£åœ¨è§£æassumptionç»“æœ...")
            
            # ä½¿ç”¨<|ASSUMPTION_SPLIT|>åˆ†å‰²å­—ç¬¦ä¸²
            assumptions_raw = raw_assumptions.strip().split("<|ASSUMPTION_SPLIT|>")
            
            # æ¸…ç†æ¯ä¸ªassumptionï¼Œå»é™¤å‰åç©ºç™½å’Œç©ºè¡Œ
            assumptions_list = []
            for assumption in assumptions_raw:
                cleaned_assumption = assumption.strip()
                if cleaned_assumption:  # è¿‡æ»¤ç©ºå­—ç¬¦ä¸²
                    assumptions_list.append(cleaned_assumption)
            
            print(f"âœ… è§£æå®Œæˆï¼Œæå–åˆ° {len(assumptions_list)} ä¸ªå‡è®¾")
            return assumptions_list
            
        except Exception as e:
            print(f"âŒ è§£æå¤±è´¥: {e}")
            return []

    def process_ava_mode_with_threading(self, public_functions_by_lang: Dict, max_depth: int, tasks: List, task_id: int):
        """ä½¿ç”¨å¤šçº¿ç¨‹å¤„ç†AVAæ¨¡å¼çš„å‡½æ•°åˆ†æ
        
        Args:
            public_functions_by_lang: æŒ‰è¯­è¨€åˆ†ç»„çš„publicå‡½æ•°
            max_depth: æœ€å¤§æ·±åº¦
            tasks: ä»»åŠ¡åˆ—è¡¨ï¼ˆå¼•ç”¨ä¼ é€’ï¼‰
            task_id: å½“å‰ä»»åŠ¡ID
        """
        # è·å–çº¿ç¨‹æ•°é…ç½®ï¼Œé»˜è®¤ä¸º4
        max_workers = int(os.getenv("AVA_THREAD_COUNT", "4"))
        print(f"ğŸš€ ä½¿ç”¨ {max_workers} ä¸ªçº¿ç¨‹è¿›è¡Œå¹¶å‘å¤„ç†")
        
        # ä¸ºäº†çº¿ç¨‹å®‰å…¨ï¼Œä½¿ç”¨é”ä¿æŠ¤å…±äº«èµ„æº
        tasks_lock = threading.Lock()
        task_id_lock = threading.Lock()
        task_id_counter = [task_id]  # ä½¿ç”¨åˆ—è¡¨æ¥å®ç°å¼•ç”¨ä¼ é€’
        
        # æ”¶é›†æ‰€æœ‰éœ€è¦å¤„ç†çš„å‡½æ•°
        all_functions = []
        for lang, public_funcs in public_functions_by_lang.items():
            if public_funcs:
                for public_func in public_funcs:
                    all_functions.append((lang, public_func))
        
        print(f"ğŸ“‹ æ€»è®¡éœ€è¦å¤„ç† {len(all_functions)} ä¸ªå‡½æ•°")
        
        def process_single_function(lang_func_pair):
            """å¤„ç†å•ä¸ªå‡½æ•°çš„å‡è®¾åˆ†æ"""
            lang, public_func = lang_func_pair
            func_name = public_func['name']
            
            try:
                # ä½¿ç”¨call treeè·å–downstreamå†…å®¹
                downstream_content = self.call_tree_utils.get_downstream_content_with_call_tree(func_name, max_depth)
                
                # åŠ ä¸Šroot funcçš„content
                downstream_content = public_func['content'] + '\n\n' + downstream_content
                
                print(f"  ğŸ” æ­£åœ¨ä¸ºå‡½æ•° {func_name} ç”Ÿæˆå‡è®¾è¯„ä¼°æ¸…å•...")
                
                # ä½¿ç”¨Claudeåˆ†æä»£ç å‡è®¾
                raw_assumptions = self.analyze_code_assumptions(downstream_content)
                
                # è§£æåˆ†å‰²æ ¼å¼çš„ç»“æœ
                assumption_violation_checklist = self.parse_assumptions_from_text(raw_assumptions)
                
                if not assumption_violation_checklist:
                    print(f"  âš ï¸ å‡½æ•° {func_name} æœªèƒ½ç”Ÿæˆæœ‰æ•ˆçš„å‡è®¾æ¸…å•ï¼Œè·³è¿‡...")
                    return []
                
                actual_iteration_count = 2
                function_tasks = []
                
                # ä¸ºæ¯ä¸ªassumption statementåˆ›å»ºå•ç‹¬çš„ä»»åŠ¡
                for assumption_statement in assumption_violation_checklist:
                    # ä¸ºæ¯ä¸ªassumption statementåˆ†é…ä¸€ä¸ªgroup UUID
                    group_uuid = str(uuid.uuid4())
                    
                    for iteration in range(actual_iteration_count):
                        # çº¿ç¨‹å®‰å…¨åœ°è·å–task_id
                        with task_id_lock:
                            current_task_id = task_id_counter[0]
                            task_id_counter[0] += 1
                        
                        task_data = {
                            'task_id': current_task_id,
                            'iteration_index': iteration + 1,
                            'language': lang,
                            'root_function': public_func,
                            'rule_key': "assumption_violation",
                            'rule_list': assumption_statement,  # æ¯ä¸ªä»»åŠ¡åªå¤„ç†ä¸€ä¸ªassumption
                            'downstream_content': downstream_content,
                            'max_depth': max_depth,
                            'task_type': 'public_function_checklist_scan',
                            'group': group_uuid  # ä¸ºæ¯ä¸ªassumption statementåˆ†é…ä¸€ä¸ªgroup UUID
                        }
                        
                        function_tasks.append(task_data)
                
                total_tasks_created = len(assumption_violation_checklist) * actual_iteration_count
                print(f"  âœ… ä¸ºå‡½æ•° {func_name} åˆ›å»ºäº† {total_tasks_created} ä¸ªä»»åŠ¡ ({len(assumption_violation_checklist)} ä¸ªå‡è®¾ Ã— {actual_iteration_count} æ¬¡è¿­ä»£)")
                
                return function_tasks
                
            except Exception as e:
                print(f"  âŒ å¤„ç†å‡½æ•° {func_name} æ—¶å‡ºé”™: {e}")
                return []
        
        # ä½¿ç”¨ThreadPoolExecutorè¿›è¡Œå¹¶å‘å¤„ç†
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_function = {
                executor.submit(process_single_function, lang_func_pair): lang_func_pair
                for lang_func_pair in all_functions
            }
            
            # ä½¿ç”¨è¿›åº¦æ¡æ˜¾ç¤ºå¤„ç†è¿›åº¦
            with tqdm(total=len(all_functions), desc="å¤„ç†å‡½æ•°å‡è®¾åˆ†æ") as pbar:
                for future in as_completed(future_to_function):
                    lang_func_pair = future_to_function[future]
                    lang, public_func = lang_func_pair
                    
                    try:
                        function_tasks = future.result()
                        
                        # çº¿ç¨‹å®‰å…¨åœ°æ·»åŠ ä»»åŠ¡åˆ°ä¸»åˆ—è¡¨
                        if function_tasks:
                            with tasks_lock:
                                tasks.extend(function_tasks)
                        
                    except Exception as e:
                        func_name = public_func['name']
                        print(f"âŒ å‡½æ•° {func_name} å¤„ç†å¤±è´¥: {e}")
                    
                    pbar.update(1)
        
        print(f"ğŸ‰ å¤šçº¿ç¨‹å¤„ç†å®Œæˆï¼å…±åˆ›å»ºäº† {len([t for t in tasks if t.get('rule_key') == 'assumption_violation'])} ä¸ªAVAä»»åŠ¡")


# ä¾¿æ·å‡½æ•°ï¼Œç”¨äºåˆ›å»ºAssumptionValidatorå®ä¾‹
def create_assumption_validator(call_tree_utils) -> AssumptionValidator:
    """åˆ›å»ºAssumptionValidatorå®ä¾‹çš„ä¾¿æ·å‡½æ•°"""
    return AssumptionValidator(call_tree_utils)


# ä¾¿æ·å‡½æ•°ï¼Œç”¨äºç›´æ¥è°ƒç”¨åŠŸèƒ½
def analyze_code_assumptions_standalone(downstream_content: str) -> str:
    """åˆ†æä»£ç å‡è®¾çš„ä¾¿æ·å‡½æ•°ï¼ˆç‹¬ç«‹ç‰ˆæœ¬ï¼Œä¸éœ€è¦å®ä¾‹ï¼‰"""
    assumption_prompt = AssumptionPrompt.get_assumption_analysis_prompt(downstream_content)
    
    try:
        print("ğŸ¤– æ­£åœ¨ä½¿ç”¨Claudeåˆ†æä»£ç å‡è®¾...")
        result = analyze_code_assumptions(assumption_prompt)
        print("âœ… Claudeåˆ†æå®Œæˆ")
        return result
    except Exception as e:
        print(f"âŒ Claudeåˆ†æå¤±è´¥: {e}")
        return ""


def parse_assumptions_from_text_standalone(raw_assumptions: str) -> List[str]:
    """è§£æå‡è®¾æ–‡æœ¬çš„ä¾¿æ·å‡½æ•°ï¼ˆç‹¬ç«‹ç‰ˆæœ¬ï¼Œä¸éœ€è¦å®ä¾‹ï¼‰"""
    if not raw_assumptions:
        return []
        
    try:
        print("ğŸ§¹ æ­£åœ¨è§£æassumptionç»“æœ...")
        
        # ä½¿ç”¨<|ASSUMPTION_SPLIT|>åˆ†å‰²å­—ç¬¦ä¸²
        assumptions_raw = raw_assumptions.strip().split("<|ASSUMPTION_SPLIT|>")
        
        # æ¸…ç†æ¯ä¸ªassumptionï¼Œå»é™¤å‰åç©ºç™½å’Œç©ºè¡Œ
        assumptions_list = []
        for assumption in assumptions_raw:
            cleaned_assumption = assumption.strip()
            if cleaned_assumption:  # è¿‡æ»¤ç©ºå­—ç¬¦ä¸²
                assumptions_list.append(cleaned_assumption)
        
        print(f"âœ… è§£æå®Œæˆï¼Œæå–åˆ° {len(assumptions_list)} ä¸ªå‡è®¾")
        return assumptions_list
        
    except Exception as e:
        print(f"âŒ è§£æå¤±è´¥: {e}")
        return []
