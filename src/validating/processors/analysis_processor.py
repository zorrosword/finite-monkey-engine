import os
import time
import json
from datetime import datetime
from typing import List, Tuple, Dict, Any

from dao.entity import Project_Task

from ..utils.check_utils import CheckUtils
from prompt_factory.prompt_assembler import PromptAssembler
from openai_api.openai import ask_claude, common_ask_confirmation, common_ask_for_json


class AnalysisProcessor:
    """Analysis processor responsible for executing specific vulnerability analysis logic (æ”¯æŒRAGé€‰æ‹©)"""
    
    def __init__(self, context_data: Dict[str, Any]):
        """
        åˆå§‹åŒ–åˆ†æå¤„ç†å™¨
        
        Args:
            context_data: åŒ…å«é¡¹ç›®æ•°æ®çš„å­—å…¸ï¼ŒåŒ…æ‹¬functions, functions_to_checkç­‰
        """
        self.context_data = context_data
        self.functions = context_data.get('functions', [])
        self.functions_to_check = context_data.get('functions_to_check', [])
        self.call_trees = context_data.get('call_trees', [])
        self.project_id = context_data.get('project_id', '')
        self.project_path = context_data.get('project_path', '')
        
        # åˆå§‹åŒ–RAGå¤„ç†å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        self.rag_processor = None
        self._initialize_rag_processor()
    
    def _initialize_rag_processor(self):
        """åˆå§‹åŒ–RAGå¤„ç†å™¨"""
        try:
            from context.rag_processor import RAGProcessor
            # å°è¯•åˆå§‹åŒ–RAGå¤„ç†å™¨
            self.rag_processor = RAGProcessor(
                self.functions_to_check, 
                "./src/codebaseQA/lancedb", 
                self.project_id
            )
            print("âœ… Validatingæ¨¡å—: RAGå¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            print(f"âš ï¸ Validatingæ¨¡å—: RAGå¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.rag_processor = None

    def get_available_rag_types(self) -> Dict[str, str]:
        """è·å–å¯ç”¨çš„RAGç±»å‹åˆ—è¡¨åŠå…¶æè¿°"""
        if not self.rag_processor:
            return {}
        
        return {
            # åŸºç¡€RAGç±»å‹
            'name': 'åå­—æ£€ç´¢ - åŸºäºå‡½æ•°åç§°çš„ç²¾ç¡®åŒ¹é…ï¼Œé€‚åˆæŸ¥æ‰¾ç‰¹å®šå‡½æ•°',
            'content': 'å†…å®¹æ£€ç´¢ - åŸºäºå‡½æ•°æºä»£ç å†…å®¹çš„è¯­ä¹‰ç›¸ä¼¼æ€§ï¼Œé€‚åˆæŸ¥æ‰¾ç›¸ä¼¼åŠŸèƒ½çš„ä»£ç ',
            'natural': 'è‡ªç„¶è¯­è¨€æ£€ç´¢ - åŸºäºAIç”Ÿæˆçš„åŠŸèƒ½æè¿°çš„è¯­ä¹‰ç†è§£ï¼Œé€‚åˆæè¿°æ€§æŸ¥è¯¢',
            
            # å…³ç³»å‹RAGç±»å‹
            'upstream': 'ä¸Šæ¸¸å‡½æ•°æ£€ç´¢ - åŸºäºè°ƒç”¨æ­¤å‡½æ•°çš„ä¸Šæ¸¸å‡½æ•°å†…å®¹ï¼Œé€‚åˆæŸ¥æ‰¾è°ƒç”¨é“¾ä¸Šæ¸¸',
            'downstream': 'ä¸‹æ¸¸å‡½æ•°æ£€ç´¢ - åŸºäºæ­¤å‡½æ•°è°ƒç”¨çš„ä¸‹æ¸¸å‡½æ•°å†…å®¹ï¼Œé€‚åˆæŸ¥æ‰¾è°ƒç”¨é“¾ä¸‹æ¸¸',
            
            # ä¸“é—¨çš„å…³ç³»è¡¨RAGç±»å‹
            'upstream_natural': 'ä¸Šæ¸¸è‡ªç„¶è¯­è¨€å…³ç³»æ£€ç´¢ - åŸºäºä¸Šæ¸¸å‡½æ•°çš„è‡ªç„¶è¯­è¨€æè¿°ï¼Œé€‚åˆç†è§£ä¸Šæ¸¸é€»è¾‘',
            'downstream_natural': 'ä¸‹æ¸¸è‡ªç„¶è¯­è¨€å…³ç³»æ£€ç´¢ - åŸºäºä¸‹æ¸¸å‡½æ•°çš„è‡ªç„¶è¯­è¨€æè¿°ï¼Œé€‚åˆç†è§£ä¸‹æ¸¸å½±å“',
            'upstream_content': 'ä¸Šæ¸¸å†…å®¹å…³ç³»æ£€ç´¢ - åŸºäºä¸Šæ¸¸å‡½æ•°çš„ä»£ç å†…å®¹ï¼Œé€‚åˆä»£ç å±‚é¢çš„ä¸Šæ¸¸åˆ†æ',
            'downstream_content': 'ä¸‹æ¸¸å†…å®¹å…³ç³»æ£€ç´¢ - åŸºäºä¸‹æ¸¸å‡½æ•°çš„ä»£ç å†…å®¹ï¼Œé€‚åˆä»£ç å±‚é¢çš„ä¸‹æ¸¸åˆ†æ',
            
            # æ–‡ä»¶çº§RAGç±»å‹
            'file_content': 'æ–‡ä»¶å†…å®¹æ£€ç´¢ - åŸºäºæ•´ä¸ªæ–‡ä»¶çš„å†…å®¹ï¼Œé€‚åˆæ–‡ä»¶çº§åˆ«çš„åˆ†æ',
            'file_natural': 'æ–‡ä»¶è‡ªç„¶è¯­è¨€æ£€ç´¢ - åŸºäºæ–‡ä»¶çš„è‡ªç„¶è¯­è¨€æè¿°ï¼Œé€‚åˆæ–‡ä»¶åŠŸèƒ½ç†è§£'
        }

    def ask_llm_to_choose_rag_for_validation(self, vulnerability_report: str, validation_question: str, context_info: str = "") -> Dict[str, Any]:
        """è®©å¤§æ¨¡å‹é€‰æ‹©RAGç±»å‹è¿›è¡Œæ¼æ´éªŒè¯
        
        Args:
            vulnerability_report: æ¼æ´æŠ¥å‘Šå†…å®¹
            validation_question: éªŒè¯é—®é¢˜
            context_info: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            DictåŒ…å«é€‰æ‹©çš„RAGç±»å‹ã€æŸ¥è¯¢å†…å®¹å’ŒRAGç»“æœ
        """
        if not self.rag_processor:
            return {
                'rag_chosen': None,
                'query_used': None,
                'rag_results': [],
                'reason': 'RAGå¤„ç†å™¨ä¸å¯ç”¨'
            }
        
        # è·å–å¯ç”¨çš„RAGç±»å‹
        rag_types = self.get_available_rag_types()
        
        # æ„å»ºæç¤ºï¼Œè®©å¤§æ¨¡å‹é€‰æ‹©RAGç±»å‹
        rag_selection_prompt = f"""ä½ æ­£åœ¨è¿›è¡Œæ™ºèƒ½åˆçº¦æ¼æ´éªŒè¯ã€‚éœ€è¦æ ¹æ®æ¼æ´æŠ¥å‘Šå’ŒéªŒè¯é—®é¢˜ï¼Œé€‰æ‹©æœ€åˆé€‚çš„RAGæ£€ç´¢ç±»å‹æ¥è·å–ç›¸å…³ä¿¡æ¯è¿›è¡ŒéªŒè¯ã€‚

**æ¼æ´æŠ¥å‘Š**ï¼š
{vulnerability_report}

**éªŒè¯é—®é¢˜**ï¼š
{validation_question}

**å½“å‰ä¸Šä¸‹æ–‡**ï¼š
{context_info}

**å¯ç”¨çš„RAGæ£€ç´¢ç±»å‹**ï¼š
{chr(10).join([f'- {k}: {v}' for k, v in rag_types.items()])}

**è¯·åˆ†æï¼š**
1. è¦éªŒè¯è¿™ä¸ªæ¼æ´ï¼Œæœ€éœ€è¦ä»€ä¹ˆç±»å‹çš„ç›¸å…³ä¿¡æ¯ï¼Ÿ
2. åº”è¯¥é€‰æ‹©å“ªç§RAGç±»å‹æ¥è·å–è¿™äº›ä¿¡æ¯ï¼Ÿ
3. åº”è¯¥ä½¿ç”¨ä»€ä¹ˆæŸ¥è¯¢å†…å®¹è¿›è¡Œæ£€ç´¢ï¼Ÿ

**é€‰æ‹©å»ºè®®**ï¼š
- å¦‚æœéœ€è¦éªŒè¯å‡½æ•°è°ƒç”¨å…³ç³»ï¼Œé€‰æ‹©upstream/downstreamç›¸å…³çš„RAG
- å¦‚æœéœ€è¦æŸ¥æ‰¾ç›¸ä¼¼çš„æ¼æ´æ¨¡å¼ï¼Œé€‰æ‹©contentæˆ–natural RAG
- å¦‚æœéœ€è¦ç†è§£ä¸šåŠ¡é€»è¾‘ï¼Œé€‰æ‹©naturalç›¸å…³çš„RAG
- å¦‚æœéœ€è¦éªŒè¯ç‰¹å®šå‡½æ•°è¡Œä¸ºï¼Œé€‰æ‹©nameæˆ–content RAG

è¯·ç”¨JSONæ ¼å¼å›ç­”ï¼š
{{
    "rag_type": "é€‰æ‹©çš„RAGç±»å‹åç§°",
    "query_content": "ç”¨äºæ£€ç´¢çš„å…·ä½“æŸ¥è¯¢å†…å®¹",
    "reason": "é€‰æ‹©æ­¤RAGç±»å‹çš„è¯¦ç»†åŸå› ",
    "validation_focus": "éªŒè¯çš„é‡ç‚¹æ˜¯ä»€ä¹ˆ",
    "backup_rag_type": "å¤‡é€‰RAGç±»å‹ï¼ˆå¯é€‰ï¼‰",
    "backup_query": "å¤‡é€‰æŸ¥è¯¢å†…å®¹ï¼ˆå¯é€‰ï¼‰"
}}

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚"""

        try:
            # è¯¢é—®å¤§æ¨¡å‹é€‰æ‹©RAGç±»å‹
            response = common_ask_for_json(rag_selection_prompt)
            
            if not response:
                return {
                    'rag_chosen': None,
                    'query_used': None,
                    'rag_results': [],
                    'reason': 'å¤§æ¨¡å‹æœªè¿”å›RAGé€‰æ‹©'
                }
            
            rag_choice = json.loads(response) if isinstance(response, str) else response
            
            chosen_rag = rag_choice.get('rag_type', 'content')  # é»˜è®¤ä½¿ç”¨content
            query_content = rag_choice.get('query_content', validation_question)
            reason = rag_choice.get('reason', 'é»˜è®¤é€‰æ‹©')
            validation_focus = rag_choice.get('validation_focus', 'å¸¸è§„éªŒè¯')
            
            print(f"ğŸ¤– éªŒè¯é˜¶æ®µå¤§æ¨¡å‹é€‰æ‹©çš„RAGç±»å‹: {chosen_rag}")
            print(f"ğŸ” éªŒè¯æŸ¥è¯¢å†…å®¹: {query_content}")
            print(f"ğŸ¯ éªŒè¯é‡ç‚¹: {validation_focus}")
            print(f"ğŸ’­ é€‰æ‹©åŸå› : {reason}")
            
            # æ ¹æ®é€‰æ‹©æ‰§è¡Œç›¸åº”çš„RAGæŸ¥è¯¢
            rag_results = self._execute_rag_query(chosen_rag, query_content)
            
            # å¦‚æœä¸»è¦RAGæ²¡æœ‰ç»“æœï¼Œå°è¯•å¤‡é€‰æ–¹æ¡ˆ
            if not rag_results and rag_choice.get('backup_rag_type'):
                backup_rag = rag_choice.get('backup_rag_type')
                backup_query = rag_choice.get('backup_query', query_content)
                print(f"ğŸ”„ éªŒè¯é˜¶æ®µå°è¯•å¤‡é€‰RAG: {backup_rag}")
                rag_results = self._execute_rag_query(backup_rag, backup_query)
                chosen_rag = backup_rag
                query_content = backup_query
            
            return {
                'rag_chosen': chosen_rag,
                'query_used': query_content,
                'rag_results': rag_results,
                'reason': reason,
                'validation_focus': validation_focus,
                'llm_choice': rag_choice
            }
            
        except Exception as e:
            print(f"âŒ éªŒè¯RAGé€‰æ‹©è¿‡ç¨‹å¤±è´¥: {e}")
            # å›é€€åˆ°ç®€å•çš„contentæœç´¢
            rag_results = self._execute_rag_query('content', validation_question)
            return {
                'rag_chosen': 'content',
                'query_used': validation_question,
                'rag_results': rag_results,
                'reason': f'RAGé€‰æ‹©å¤±è´¥ï¼Œå›é€€åˆ°é»˜è®¤: {str(e)}'
            }

    def _execute_rag_query(self, rag_type: str, query: str, k: int = 5) -> List[Dict]:
        """æ‰§è¡ŒæŒ‡å®šç±»å‹çš„RAGæŸ¥è¯¢
        
        Args:
            rag_type: RAGç±»å‹
            query: æŸ¥è¯¢å†…å®¹
            k: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            List[Dict]: RAGæŸ¥è¯¢ç»“æœ
        """
        if not self.rag_processor:
            return []
        
        try:
            # æ ¹æ®RAGç±»å‹è°ƒç”¨ç›¸åº”çš„æœç´¢æ–¹æ³•
            if rag_type == 'name':
                return self.rag_processor.search_functions_by_name(query, k)
            elif rag_type == 'content':
                return self.rag_processor.search_functions_by_content(query, k)
            elif rag_type == 'natural':
                return self.rag_processor.search_functions_by_natural_language(query, k)
            elif rag_type == 'upstream':
                return self.rag_processor.search_functions_by_upstream(query, k)
            elif rag_type == 'downstream':
                return self.rag_processor.search_functions_by_downstream(query, k)
            elif rag_type == 'upstream_natural':
                return self.rag_processor.search_relationships_by_upstream_natural(query, k)
            elif rag_type == 'downstream_natural':
                return self.rag_processor.search_relationships_by_downstream_natural(query, k)
            elif rag_type == 'upstream_content':
                return self.rag_processor.search_relationships_by_upstream_content(query, k)
            elif rag_type == 'downstream_content':
                return self.rag_processor.search_relationships_by_downstream_content(query, k)
            elif rag_type == 'file_content':
                return self.rag_processor.search_files_by_content(query, k)
            elif rag_type == 'file_natural':
                return self.rag_processor.search_files_by_natural_language(query, k)
            else:
                print(f"âš ï¸ æœªçŸ¥çš„RAGç±»å‹: {rag_type}ï¼Œä½¿ç”¨é»˜è®¤contentæœç´¢")
                return self.rag_processor.search_functions_by_content(query, k)
                
        except Exception as e:
            print(f"âŒ RAGæŸ¥è¯¢å¤±è´¥ ({rag_type}): {e}")
            return []

    def extract_required_info(self, response_text: str) -> List[str]:
        """æå–éœ€è¦è¿›ä¸€æ­¥åˆ†æçš„ä¿¡æ¯ï¼ˆå¢å¼ºRAGæ”¯æŒï¼‰"""
        # é¦–å…ˆå°è¯•ä½¿ç”¨å¤§æ¨¡å‹æå–å…³é”®ä¿¡æ¯
        try:
            extract_prompt = f"""ä»ä»¥ä¸‹æ¼æ´åˆ†ææŠ¥å‘Šä¸­æå–éœ€è¦è¿›ä¸€æ­¥éªŒè¯æˆ–åˆ†æçš„å…³é”®ä¿¡æ¯ç‚¹ï¼š

{response_text}

è¯·æå–ï¼š
1. éœ€è¦éªŒè¯çš„å‡½æ•°è°ƒç”¨å…³ç³»
2. éœ€è¦ç¡®è®¤çš„ä»£ç é€»è¾‘
3. éœ€è¦æŸ¥æ‰¾çš„ç›¸å…³å‡½æ•°æˆ–åˆçº¦
4. éœ€è¦åˆ†æçš„ä¸šåŠ¡æµç¨‹
5. å…¶ä»–éœ€è¦è¿›ä¸€æ­¥åˆ†æçš„è¦ç‚¹

è¯·ç”¨JSONæ ¼å¼è¿”å›ï¼š
{{
    "required_info": [
        "ä¿¡æ¯ç‚¹1çš„å…·ä½“æè¿°",
        "ä¿¡æ¯ç‚¹2çš„å…·ä½“æè¿°"
    ],
    "analysis_type": "éœ€è¦çš„åˆ†æç±»å‹ï¼ˆå¦‚å‡½æ•°å…³ç³»åˆ†æã€é€»è¾‘éªŒè¯ç­‰ï¼‰",
    "priority": "high/medium/low"
}}

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚"""

            response = common_ask_for_json(extract_prompt)
            if response:
                extracted = json.loads(response) if isinstance(response, str) else response
                return extracted.get('required_info', [])
        except Exception as e:
            print(f"âš ï¸ AIä¿¡æ¯æå–å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–æ–¹æ³•: {e}")
        
        # å›é€€åˆ°ç®€åŒ–çš„å®ç°
        required_info = []
        keywords = ['éœ€è¦è¿›ä¸€æ­¥', 'æ›´å¤šä¿¡æ¯', 'éœ€è¦æŸ¥çœ‹', 'éœ€è¦ç¡®è®¤', 'ç¼ºå°‘ä¿¡æ¯', 'éªŒè¯', 'åˆ†æ']
        
        for keyword in keywords:
            if keyword in response_text:
                sentences = response_text.split('ã€‚')
                for sentence in sentences:
                    if keyword in sentence:
                        required_info.append(sentence.strip())
                        break
        
        return required_info

    def get_additional_context_with_rag(self, required_info: List[str], original_report: str = "") -> str:
        """ä½¿ç”¨RAGè·å–é¢å¤–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
        
        Args:
            required_info: éœ€è¦çš„ä¿¡æ¯åˆ—è¡¨
            original_report: åŸå§‹æŠ¥å‘Šå†…å®¹
            
        Returns:
            str: å¢å¼ºçš„ä¸Šä¸‹æ–‡ä¿¡æ¯
        """
        if not required_info:
            return "æœªæ‰¾åˆ°éœ€è¦è¿›ä¸€æ­¥åˆ†æçš„ä¿¡æ¯"
        
        enhanced_context_parts = []
        
        for i, info in enumerate(required_info, 1):
            try:
                print(f"ğŸ” å¤„ç†ä¿¡æ¯ç‚¹ {i}: {info[:50]}...")
                
                # ä¸ºæ¯ä¸ªä¿¡æ¯ç‚¹è®©å¤§æ¨¡å‹é€‰æ‹©RAGç±»å‹
                validation_question = f"éœ€è¦éªŒè¯æˆ–åˆ†æï¼š{info}"
                rag_result = self.ask_llm_to_choose_rag_for_validation(original_report, validation_question, info)
                
                enhanced_context_parts.append(f"\n=== ä¿¡æ¯ç‚¹ {i} ===")
                enhanced_context_parts.append(f"éœ€è¦åˆ†æ: {info}")
                
                if rag_result.get('rag_chosen'):
                    enhanced_context_parts.append(f"ä½¿ç”¨RAGç±»å‹: {rag_result['rag_chosen']}")
                    enhanced_context_parts.append(f"éªŒè¯é‡ç‚¹: {rag_result.get('validation_focus', 'å¸¸è§„éªŒè¯')}")
                    
                    if rag_result.get('rag_results'):
                        enhanced_context_parts.append(f"æ‰¾åˆ° {len(rag_result['rag_results'])} ä¸ªç›¸å…³ç»“æœ:")
                        for j, result in enumerate(rag_result['rag_results'][:2], 1):  # åªæ˜¾ç¤ºå‰2ä¸ª
                            if isinstance(result, dict):
                                func_name = result.get('name', result.get('function_name', 'Unknown'))
                                content_preview = result.get('content', '')[:100] if result.get('content') else ''
                                enhanced_context_parts.append(f"  {j}. {func_name}: {content_preview}...")
                    else:
                        enhanced_context_parts.append("  æœªæ‰¾åˆ°ç›´æ¥ç›¸å…³çš„ä»£ç ")
                else:
                    enhanced_context_parts.append("  RAGæŸ¥è¯¢ä¸å¯ç”¨ï¼Œä½¿ç”¨ä¼ ç»Ÿåˆ†æ")
                    # ä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•æŸ¥æ‰¾ç›¸å…³å‡½æ•°
                    traditional_context = self._get_traditional_context(info)
                    if traditional_context:
                        enhanced_context_parts.append(f"  ä¼ ç»Ÿåˆ†æç»“æœ: {traditional_context}")
                
            except Exception as e:
                print(f"âŒ å¤„ç†ä¿¡æ¯ç‚¹ {i} å¤±è´¥: {e}")
                enhanced_context_parts.append(f"  å¤„ç†å¤±è´¥: {str(e)}")
        
        return '\n'.join(enhanced_context_parts)

    def _get_traditional_context(self, info: str) -> str:
        """ä¼ ç»Ÿæ–¹æ³•è·å–ä¸Šä¸‹æ–‡ï¼ˆä½œä¸ºRAGçš„å¤‡é€‰ï¼‰"""
        context_parts = []
        info_lower = info.lower()
        
        # åœ¨functionsä¸­æŸ¥æ‰¾ç›¸å…³ä¿¡æ¯
        for func in self.functions_to_check:
            func_content = func.get('content', '').lower()
            func_name = func.get('name', '')
            
            # ç®€å•çš„å…³é”®è¯åŒ¹é…
            if any(keyword in func_content for keyword in info_lower.split()):
                context_parts.append(f"ç›¸å…³å‡½æ•°: {func_name}")
                if len(context_parts) >= 3:  # é™åˆ¶ç»“æœæ•°é‡
                    break
        
        return '; '.join(context_parts) if context_parts else "æœªæ‰¾åˆ°ç›¸å…³å‡½æ•°"

    def get_additional_internet_info(self, required_info: List[str]) -> str:
        """è·å–ç½‘ç»œä¿¡æ¯ï¼ˆç®€åŒ–å®ç°ï¼‰"""
        if required_info:
            return f"ç½‘ç»œæœç´¢ç»“æœï¼šæ‰¾åˆ°{len(required_info)}ä¸ªç›¸å…³ä¿¡æ¯ç‚¹ï¼ˆç®€åŒ–å®ç°ï¼‰"
        return ""

    def get_additional_context(self, required_info: List[str]) -> str:
        """è·å–é¢å¤–ä¸Šä¸‹æ–‡ï¼ˆå‘åå…¼å®¹æ–¹æ³•ï¼‰"""
        return self.get_additional_context_with_rag(required_info)

    def process_task_analysis(self, task:Project_Task,task_manager):
        """AgentåŒ–çš„ä¸‰è½®æ¼æ´æ£€æµ‹æµç¨‹"""
        import json
        from datetime import datetime
        
        start_time = time.time()
        logs = []
        
        print(f"\nğŸš€ å¯åŠ¨AgentåŒ–æ¼æ´æ£€æµ‹æµç¨‹ - ä»»åŠ¡: {task.name}")
        logs.append(f"å¼€å§‹æ—¶é—´: {datetime.utcnow().isoformat()}")
        
        # è·å–è§„åˆ™å’Œä¸šåŠ¡æµä»£ç 
        vulnerability_result = task.result
        business_flow_code = task.business_flow_code or task.content
        
        logs.append(f"è§„åˆ™ç±»å‹: {task.rule_key}")
        logs.append(f"ä»£ç é•¿åº¦: {len(business_flow_code)} å­—ç¬¦")
        
        # æ‰§è¡Œä¸‰è½®ç‹¬ç«‹æ£€æµ‹
        round_results = []
        
        for round_num in range(1, 4):  # ä¸‰è½®æ£€æµ‹
            print(f"\n--- ç¬¬ {round_num} è½®ç‹¬ç«‹æ£€æµ‹ ---")
            logs.append(f"å¼€å§‹ç¬¬ {round_num} è½®æ£€æµ‹")
            
            try:
                round_result = self._execute_single_detection_round(
                    vulnerability_result, business_flow_code, task, round_num, logs
                )
                round_results.append(round_result)
                logs.append(f"ç¬¬ {round_num} è½®ç»“æœ: {round_result}")
                
            except Exception as e:
                print(f"âŒ ç¬¬ {round_num} è½®æ£€æµ‹å¤±è´¥: {e}")
                logs.append(f"ç¬¬ {round_num} è½®å¤±è´¥: {str(e)}")
                round_results.append("not_sure")
        
        # æ±‡æ€»ä¸‰è½®ç»“æœ
        final_short_result, final_detailed_result = self._aggregate_round_results(round_results, logs)
        
        # è®¡ç®—å¤„ç†æ—¶é—´
        end_time = time.time()
        process_time = round(end_time - start_time, 2)
        
        logs.append(f"æœ€ç»ˆç®€çŸ­ç»“æœ: {final_short_result}")
        logs.append(f"å¤„ç†è€—æ—¶: {process_time}ç§’")
        logs.append(f"ç»“æŸæ—¶é—´: {datetime.utcnow().isoformat()}")
        
        print(f"\nğŸ¯ æœ€ç»ˆç»“æœ: {final_short_result}")
        print(f"â±ï¸ æ€»è€—æ—¶: {process_time}ç§’")
        
        # ä¿å­˜ç»“æœ
        task.set_result(final_detailed_result)
        task.set_short_result(final_short_result)
        
        # ä¿å­˜å®Œæ•´æ—¥å¿—åˆ°scan_record
        scan_data = {
            'logs': logs,
            'round_results': round_results,
            'process_time': process_time,
            'timestamp': datetime.utcnow().isoformat(),
            'rounds_count': 3
        }
        task.scan_record = json.dumps(scan_data, ensure_ascii=False)
        
        # æ›´æ–°æ•°æ®åº“
        task_manager.save_task(task)
        
        return final_short_result

    def _build_confirmation_prompt(self, task, comprehensive_analysis: str, round_num: int, max_rounds: int) -> str:
        """æ„å»ºç¡®è®¤æç¤ºï¼ˆåŒ…å«RAGå¢å¼ºä¿¡æ¯ï¼‰"""
        base_prompt = PromptAssembler.confirmation_analysis_prompt(
            task.content, comprehensive_analysis
        )
        
        # Add round-specific instructions
        round_instruction = f"""
è¿™æ˜¯ç¬¬ {round_num}/{max_rounds} è½®ç¡®è®¤åˆ†æã€‚

ä¸Šè¿°åˆ†æä¸­åŒ…å«äº†åŸºäºRAGæ£€ç´¢çš„å¢å¼ºä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œè¯·ç‰¹åˆ«æ³¨æ„ï¼š
1. RAGæ£€ç´¢åˆ°çš„ç›¸å…³å‡½æ•°å’Œä»£ç ç‰‡æ®µ
2. ä¸Šæ¸¸/ä¸‹æ¸¸å‡½æ•°è°ƒç”¨å…³ç³»ä¿¡æ¯
3. ç›¸ä¼¼åŠŸèƒ½æˆ–æ¼æ´æ¨¡å¼çš„ä»£ç 

è¯·åŸºäºè¿™äº›å¢å¼ºä¿¡æ¯è¿›è¡Œæ›´å‡†ç¡®çš„æ¼æ´ç¡®è®¤ã€‚
"""
        
        return base_prompt + round_instruction
    
    def _perform_initial_analysis(self, code_to_be_tested: str, result: str, analysis_collection: List) -> Tuple:
        """Execute initial analysis"""
        print("\n=== First Round Analysis Start ===")
        print("ğŸ“ Analyzing potential vulnerabilities...")
        prompt = PromptAssembler.assemble_vul_check_prompt(code_to_be_tested, result)
        
        initial_response = common_ask_confirmation(prompt)
        if not initial_response or initial_response == "":
            print(f"âŒ Error: Empty response received")
            return "not sure", "Empty response"
        
        print("\nğŸ“Š Initial Analysis Result Length:")
        print("-" * 80)
        print(len(initial_response))
        print("-" * 80)

        # Collect initial analysis results
        analysis_collection.extend([
            "=== Initial Analysis Results ===",
            initial_response
        ])

        # Process initial response
        initial_result_status = CheckUtils.process_round_response(initial_response)
        analysis_collection.extend([
            "=== Initial Analysis Status ===",
            initial_result_status
        ])

        # Extract required information
        required_info = self.context_data.get("extract_required_info")(initial_response)
        if required_info:
            analysis_collection.append("=== Information Requiring Further Analysis ===")
            analysis_collection.extend(required_info)

        if CheckUtils.should_skip_early(initial_result_status):
            print("\nğŸ›‘ Initial analysis shows clear 'no vulnerability' - stopping further analysis")
            return "no", "Analysis stopped after initial round due to clear 'no vulnerability' result"
        
        return None, None  # Continue with multi-round confirmation
    


    def _execute_single_detection_round(self, vulnerability_result, business_flow_code, task, round_num, logs):
        """æ‰§è¡Œå•è½®æ£€æµ‹æµç¨‹"""
        from openai_api.openai import (ask_agent_initial_analysis, ask_agent_json_extraction, 
                                       ask_agent_info_query, ask_agent_info_extraction,
                                       ask_agent_final_analysis, ask_agent_final_extraction)
        from prompt_factory.vul_check_prompt import VulCheckPrompt
        
        logs.append(f"ç¬¬ {round_num} è½®: å¼€å§‹åˆæ­¥ç¡®è®¤")
        
        # ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨prompt factoryç”Ÿæˆå®Œæ•´çš„åˆæ­¥åˆ†æprompt
        initial_prompt = VulCheckPrompt.vul_check_prompt_agent_initial_complete(
            vulnerability_result, business_flow_code
        )

        try:
            # ä½¿ç”¨ä¸“é—¨çš„åˆå§‹åˆ†ææ¨¡å‹è·å–è‡ªç„¶è¯­è¨€å“åº”
            natural_response = ask_agent_initial_analysis(initial_prompt)
            if not natural_response:
                logs.append(f"ç¬¬ {round_num} è½®: åˆå§‹åˆ†ææ¨¡å‹æ— å“åº”")
                return "not_sure"
            
            logs.append(f"ç¬¬ {round_num} è½®: åˆå§‹åˆ†æè‡ªç„¶è¯­è¨€å“åº”é•¿åº¦={len(natural_response)}")
            
            # ä½¿ç”¨prompt factoryç”ŸæˆJSONæå–prompt
            json_extraction_prompt = VulCheckPrompt.vul_check_prompt_agent_json_extraction(
                natural_response
            )

            initial_response = ask_agent_json_extraction(json_extraction_prompt)
            if not initial_response:
                logs.append(f"ç¬¬ {round_num} è½®: JSONæå–å¤±è´¥")
                return "not_sure"
            
            initial_result = json.loads(initial_response) if isinstance(initial_response, str) else initial_response
            assessment = initial_result.get('initial_assessment', 'not_sure')
            additional_info = initial_result.get('additional_info_needed', '')
            
            logs.append(f"ç¬¬ {round_num} è½®: åˆæ­¥è¯„ä¼°={assessment}")
            logs.append(f"ç¬¬ {round_num} è½®: è‡ªç„¶è¯­è¨€åˆ†æ={natural_response[:200]}...")
            
            print(f"  ğŸ“Š åˆæ­¥è¯„ä¼°: {assessment}")
            
            # å¦‚æœæ˜¯æ˜ç¡®çš„yesæˆ–noï¼Œç›´æ¥è¿”å›
            if assessment in ['yes', 'no']:
                logs.append(f"ç¬¬ {round_num} è½®: æ˜ç¡®ç»“æœï¼Œç›´æ¥è¿”å›")
                return assessment
            
            # å¦‚æœéœ€è¦æ›´å¤šä¿¡æ¯ï¼Œç›´æ¥è·å–æ‰€æœ‰ç±»å‹çš„ä¿¡æ¯
            if assessment == 'need_more_info' and additional_info:
                print(f"  ğŸ” éœ€è¦æ›´å¤šä¿¡æ¯: {additional_info}")
                logs.append(f"ç¬¬ {round_num} è½®: éœ€è¦æ›´å¤šä¿¡æ¯: {additional_info}")
                
                try:
                    # ç›´æ¥è·å–æ‰€æœ‰ç±»å‹çš„RAGä¿¡æ¯
                    print(f"  ğŸ” åŒæ—¶è·å–æ‰€æœ‰ç±»å‹çš„RAGä¿¡æ¯...")
                    all_additional_info = self._get_all_additional_info(
                        additional_info, task, logs, round_num
                    )
                    
                    # æ ¼å¼åŒ–ä¸ºå­—ç¬¦ä¸²
                    additional_context = self._format_all_additional_info(all_additional_info)
                    
                    logs.append(f"ç¬¬ {round_num} è½®: è·å–æ‰€æœ‰RAGä¿¡æ¯å®Œæˆ")
                    print(f"  âœ… è·å–ä¿¡æ¯å®Œæˆ: Functions={len(all_additional_info['function_info'])}, Upstream/Downstream={len(all_additional_info['upstream_downstream_info'])}, Chunks={len(all_additional_info['chunk_info'])}")
                    # Files={len(all_additional_info['file_info'])}, - å·²æ³¨é‡Š
                        
                    # ä½¿ç”¨prompt factoryç”Ÿæˆæœ€ç»ˆåˆ†æprompt
                    final_analysis_prompt = VulCheckPrompt.vul_check_prompt_agent_final_analysis(
                        vulnerability_result, business_flow_code, assessment, additional_info, additional_context
                    )
                    
                    # ä½¿ç”¨ä¸“é—¨çš„æœ€ç»ˆåˆ†ææ¨¡å‹è¿›è¡Œæœ€ç»ˆåˆ†æ
                    final_natural_response = ask_agent_final_analysis(final_analysis_prompt)
                    if final_natural_response:
                        # ä½¿ç”¨prompt factoryç”Ÿæˆæœ€ç»ˆç»“æœæå–prompt
                        final_extraction_prompt = VulCheckPrompt.vul_check_prompt_agent_final_extraction(
                            final_natural_response
                        )

                        final_response = ask_agent_final_extraction(final_extraction_prompt)
                        if final_response:
                            final_result = json.loads(final_response) if isinstance(final_response, str) else final_response
                            final_assessment = final_result.get('final_result', 'not_sure')
                            
                            logs.append(f"ç¬¬ {round_num} è½®: æœ€ç»ˆç»“æœ={final_assessment}")
                            logs.append(f"ç¬¬ {round_num} è½®: æœ€ç»ˆåˆ†æ={final_natural_response[:200]}...")
                            
                            print(f"  ğŸ¯ æœ€ç»ˆåˆ¤æ–­: {final_assessment}")
                            return final_assessment
                        
                except Exception as e:
                    logs.append(f"ç¬¬ {round_num} è½®: ä¿¡æ¯è·å–é˜¶æ®µå¤±è´¥: {str(e)}")
                    print(f"  âŒ ä¿¡æ¯è·å–å¤±è´¥: {e}")
            
            # å¦‚æœä»¥ä¸Šéƒ½å¤±è´¥ï¼Œè¿”å›åˆæ­¥è¯„ä¼°ç»“æœ
            return assessment if assessment in ['yes', 'no'] else 'not_sure'
            
        except Exception as e:
            logs.append(f"ç¬¬ {round_num} è½®: æ£€æµ‹å¤±è´¥: {str(e)}")
            print(f"  âŒ æ£€æµ‹å¤±è´¥: {e}")
            return "not_sure"

    def _get_additional_info_by_type(self, info_type, specific_query, task, logs, round_num):
        """æ ¹æ®ä¿¡æ¯ç±»å‹è·å–é¢å¤–ä¿¡æ¯"""
        try:
            if info_type == 'function':
                # ä½¿ç”¨RAGæœç´¢å‡½æ•°ä¿¡æ¯
                if self.rag_processor:
                    # å…ˆå°è¯•æŒ‰åç§°æœç´¢
                    name_results = self.rag_processor.search_functions_by_name(specific_query, 3)
                    # å†å°è¯•æŒ‰å†…å®¹æœç´¢
                    content_results = self.rag_processor.search_functions_by_content(specific_query, 3)
                    
                    context_parts = []
                    if name_results:
                        context_parts.append("=== æŒ‰åç§°æœç´¢çš„å‡½æ•° ===")
                        for result in name_results[:2]:
                            func_name = result.get('name', 'Unknown')
                            func_content = result.get('content', '')[:200]
                            context_parts.append(f"å‡½æ•°: {func_name}\nä»£ç : {func_content}...\n")
                    
                    if content_results:
                        context_parts.append("=== æŒ‰å†…å®¹æœç´¢çš„ç›¸ä¼¼å‡½æ•° ===")
                        for result in content_results[:2]:
                            func_name = result.get('name', 'Unknown')
                            func_content = result.get('content', '')[:200]
                            context_parts.append(f"å‡½æ•°: {func_name}\nä»£ç : {func_content}...\n")
                    
                    logs.append(f"ç¬¬ {round_num} è½®: å‡½æ•°æœç´¢æ‰¾åˆ° {len(name_results)} + {len(content_results)} ä¸ªç»“æœ")
                    return '\n'.join(context_parts) if context_parts else "æœªæ‰¾åˆ°ç›¸å…³å‡½æ•°"
                else:
                    logs.append(f"ç¬¬ {round_num} è½®: RAGä¸å¯ç”¨ï¼Œä½¿ç”¨ä¼ ç»Ÿå‡½æ•°æœç´¢")
                    return self._get_traditional_context(specific_query)
            
            elif info_type == 'file':
                # æ–‡ä»¶ä¿¡æ¯ - ä»ä»»åŠ¡ä¸­è·å–æ–‡ä»¶ç›¸å…³ä¿¡æ¯
                file_info = []
                if hasattr(task, 'absolute_file_path') and task.absolute_file_path:
                    file_info.append(f"æ–‡ä»¶è·¯å¾„: {task.absolute_file_path}")
                if hasattr(task, 'contract_code') and task.contract_code:
                    file_info.append(f"åˆçº¦ä»£ç : {task.contract_code[:300]}...")
                
                logs.append(f"ç¬¬ {round_num} è½®: è·å–æ–‡ä»¶ä¿¡æ¯ï¼Œ{len(file_info)} é¡¹")
                return '\n'.join(file_info) if file_info else "æœªæ‰¾åˆ°æ–‡ä»¶ä¿¡æ¯"
            
            elif info_type == 'upstream_downstream':
                # ä¸Šä¸‹æ¸¸ä¿¡æ¯ - ä½¿ç”¨get_call_tree_with_depth_limitè·å–å®é™…ä»£ç å†…å®¹
                upstream_downstream = []
                max_depth = 3  # è®¾ç½®æ·±åº¦é™åˆ¶
                
                # è·å–project_auditå®ä¾‹
                project_audit = getattr(self, 'project_audit', None) or self.context_data.get('project_audit')
                if project_audit and hasattr(project_audit, 'call_tree_builder'):
                    builder = project_audit.call_tree_builder
                    if hasattr(builder, 'get_call_tree_with_depth_limit'):
                        try:
                            # è·å–upstreamä»£ç å†…å®¹ï¼ˆä½¿ç”¨æ·±åº¦é™åˆ¶ï¼‰
                            limited_upstream = builder.get_call_tree_with_depth_limit(
                                self.call_trees, task.name, 'upstream', max_depth
                            )
                            if limited_upstream and limited_upstream.get('tree'):
                                upstream_content = self._extract_function_content_from_tree(limited_upstream['tree'])
                                if upstream_content:
                                    upstream_downstream.append(f"=== ä¸Šæ¸¸å‡½æ•°ä»£ç  (æ·±åº¦{max_depth}) ===")
                                    upstream_downstream.append(upstream_content[:1000] + "..." if len(upstream_content) > 1000 else upstream_content)
                                    logs.append(f"ç¬¬ {round_num} è½®: è·å–upstreamä»£ç å†…å®¹ï¼Œ{len(upstream_content)} å­—ç¬¦")
                            
                            # è·å–downstreamä»£ç å†…å®¹ï¼ˆä½¿ç”¨æ·±åº¦é™åˆ¶ï¼‰
                            limited_downstream = builder.get_call_tree_with_depth_limit(
                                self.call_trees, task.name, 'downstream', max_depth
                            )
                            if limited_downstream and limited_downstream.get('tree'):
                                downstream_content = self._extract_function_content_from_tree(limited_downstream['tree'])
                                if downstream_content:
                                    upstream_downstream.append(f"=== ä¸‹æ¸¸å‡½æ•°ä»£ç  (æ·±åº¦{max_depth}) ===")
                                    upstream_downstream.append(downstream_content[:1000] + "..." if len(downstream_content) > 1000 else downstream_content)
                                    logs.append(f"ç¬¬ {round_num} è½®: è·å–downstreamä»£ç å†…å®¹ï¼Œ{len(downstream_content)} å­—ç¬¦")
                            
                            # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
                            upstream_count = limited_upstream.get('total_count', 0) if limited_upstream else 0
                            downstream_count = limited_downstream.get('total_count', 0) if limited_downstream else 0
                            upstream_downstream.append(f"è°ƒç”¨å…³ç³»ç»Ÿè®¡: ä¸Šæ¸¸{upstream_count}ä¸ª, ä¸‹æ¸¸{downstream_count}ä¸ª")
                            
                        except Exception as e:
                            logs.append(f"ç¬¬ {round_num} è½®: ä½¿ç”¨get_call_tree_with_depth_limitè·å–å¤±è´¥: {str(e)}")
                            # å¤‡é€‰æ–¹æ¡ˆï¼šä»…è·å–å‡½æ•°å
                            if self.call_trees:
                                for call_tree in self.call_trees:
                                    if call_tree.get('function_name') == task.name:
                                        upstream_info = call_tree.get('upstream', {})
                                        downstream_info = call_tree.get('downstream', {})
                                        if upstream_info:
                                            upstream_functions = list(upstream_info.keys())[:3]
                                            upstream_downstream.append(f"ä¸Šæ¸¸å‡½æ•°: {', '.join(upstream_functions)}")
                                        if downstream_info:
                                            downstream_functions = list(downstream_info.keys())[:3]
                                            upstream_downstream.append(f"ä¸‹æ¸¸å‡½æ•°: {', '.join(downstream_functions)}")
                                        break
                else:
                    logs.append(f"ç¬¬ {round_num} è½®: call_tree_builderä¸å¯ç”¨ï¼Œä½¿ç”¨å¤‡é€‰æ–¹æ¡ˆ")
                    # å¤‡é€‰æ–¹æ¡ˆï¼šç›´æ¥ä»call_treesè·å–å‡½æ•°å
                    if self.call_trees:
                        for call_tree in self.call_trees:
                            if call_tree.get('function_name') == task.name:
                                upstream_info = call_tree.get('upstream', {})
                                downstream_info = call_tree.get('downstream', {})
                                if upstream_info:
                                    upstream_functions = list(upstream_info.keys())[:3]
                                    upstream_downstream.append(f"ä¸Šæ¸¸å‡½æ•°: {', '.join(upstream_functions)}")
                                if downstream_info:
                                    downstream_functions = list(downstream_info.keys())[:3]
                                    upstream_downstream.append(f"ä¸‹æ¸¸å‡½æ•°: {', '.join(downstream_functions)}")
                                upstream_count = call_tree.get('upstream_count', 0)
                                downstream_count = call_tree.get('downstream_count', 0)
                                upstream_downstream.append(f"è°ƒç”¨å…³ç³»ç»Ÿè®¡: ä¸Šæ¸¸{upstream_count}ä¸ª, ä¸‹æ¸¸{downstream_count}ä¸ª")
                                break
                
                logs.append(f"ç¬¬ {round_num} è½®: è·å–ä¸Šä¸‹æ¸¸ä¿¡æ¯ï¼Œ{len(upstream_downstream)} é¡¹")
                return '\n'.join(upstream_downstream) if upstream_downstream else "æœªæ‰¾åˆ°è°ƒç”¨å…³ç³»ä¿¡æ¯"
            
            else:
                logs.append(f"ç¬¬ {round_num} è½®: æœªçŸ¥ä¿¡æ¯ç±»å‹: {info_type}")
                return f"æœªçŸ¥ä¿¡æ¯ç±»å‹: {info_type}"
                
        except Exception as e:
            logs.append(f"ç¬¬ {round_num} è½®: è·å– {info_type} ä¿¡æ¯å¤±è´¥: {str(e)}")
            return f"è·å– {info_type} ä¿¡æ¯å¤±è´¥: {str(e)}"
    
    def _get_all_additional_info(self, specific_query, task, logs, round_num):
        """åŒæ—¶è·å–æ‰€æœ‰ç±»å‹çš„RAGä¿¡æ¯"""
        all_info = {
            'function_info': [],
            'file_info': [],
            'upstream_downstream_info': [],
            'chunk_info': []
        }
        
        try:
            # 1. Function RAGæœç´¢ (topk=5) - åŒ…æ‹¬ä¸‰ç§æœç´¢ç±»å‹
            if self.rag_processor:
                # æŒ‰åç§°æœç´¢
                name_results = self.rag_processor.search_functions_by_name(specific_query, 2)
                # æŒ‰å†…å®¹æœç´¢
                content_results = self.rag_processor.search_functions_by_content(specific_query, 2)
                # æŒ‰è‡ªç„¶è¯­è¨€æè¿°æœç´¢
                natural_results = self.rag_processor.search_functions_by_natural_language(specific_query, 2)
                
                # åˆå¹¶å’Œå»é‡ï¼Œå–å‰5ä¸ª
                function_results = self._merge_and_deduplicate_functions(
                    name_results, content_results, natural_results, 5
                )
                
                for result in function_results:
                    func_name = result.get('name', 'Unknown')
                    func_content = result.get('content', '')[:300]  # é™åˆ¶é•¿åº¦
                    all_info['function_info'].append({
                        'name': func_name,
                        'content': func_content,
                        'type': 'function'
                    })
                
                logs.append(f"ç¬¬ {round_num} è½®: Functionæœç´¢æ‰¾åˆ° {len(function_results)} ä¸ªç»“æœ")
            
            # 2. File RAGæœç´¢ (topk=2) - å·²æ³¨é‡Š
            # if self.rag_processor:
            #     file_results = self.rag_processor.search_files_by_content(specific_query, 2)
            #     
            #     for result in file_results:
            #         file_path = result.get('file_path', 'Unknown')
            #         file_content = result.get('content', '')[:300]
            #         all_info['file_info'].append({
            #             'path': file_path,
            #             'content': file_content,
            #             'type': 'file'
            #         })
            #     
            #     logs.append(f"ç¬¬ {round_num} è½®: Fileæœç´¢æ‰¾åˆ° {len(file_results)} ä¸ªç»“æœ")
            
            # 3. Upstream/Downstreamæœç´¢ (level=3/4)
            upstream_downstream_results = self._get_upstream_downstream_with_levels(task, 3, 4, logs, round_num)
            all_info['upstream_downstream_info'] = upstream_downstream_results
            
            # 4. Chunk RAGæœç´¢ (topk=3)
            if self.rag_processor:
                chunk_results = self.rag_processor.search_chunks_by_content(specific_query, 3)
                
                for result in chunk_results:
                    chunk_text = result.get('chunk_text', '')[:300]
                    original_file = result.get('original_file', 'Unknown')
                    all_info['chunk_info'].append({
                        'text': chunk_text,
                        'file': original_file,
                        'type': 'chunk'
                    })
                
                logs.append(f"ç¬¬ {round_num} è½®: Chunkæœç´¢æ‰¾åˆ° {len(chunk_results)} ä¸ªç»“æœ")
            
            # 5. å»é‡é€»è¾‘ï¼šä»upstream/downstreamä¸­å»é™¤ä¸functionç›¸åŒçš„
            all_info = self._remove_function_duplicates_from_upstream_downstream(all_info)
            
            return all_info
            
        except Exception as e:
            logs.append(f"ç¬¬ {round_num} è½®: è·å–æ‰€æœ‰é¢å¤–ä¿¡æ¯å¤±è´¥: {str(e)}")
            return all_info
    
    def _merge_and_deduplicate_functions(self, name_results, content_results, natural_results, max_count):
        """åˆå¹¶å’Œå»é‡å‡½æ•°æœç´¢ç»“æœï¼ˆä¸‰ç§ç±»å‹ï¼‰"""
        seen_names = set()
        merged_results = []
        
        # å…ˆåŠ å…¥æŒ‰åç§°æœç´¢çš„ç»“æœ
        for result in name_results:
            func_name = result.get('name', '')
            if func_name and func_name not in seen_names:
                seen_names.add(func_name)
                merged_results.append(result)
                if len(merged_results) >= max_count:
                    break
        
        # å†åŠ å…¥æŒ‰å†…å®¹æœç´¢çš„ç»“æœï¼ˆå»é‡ï¼‰
        for result in content_results:
            func_name = result.get('name', '')
            if func_name and func_name not in seen_names:
                seen_names.add(func_name)
                merged_results.append(result)
                if len(merged_results) >= max_count:
                    break
        
        # æœ€ååŠ å…¥æŒ‰è‡ªç„¶è¯­è¨€æœç´¢çš„ç»“æœï¼ˆå»é‡ï¼‰
        for result in natural_results:
            func_name = result.get('name', '')
            if func_name and func_name not in seen_names:
                seen_names.add(func_name)
                merged_results.append(result)
                if len(merged_results) >= max_count:
                    break
        
        return merged_results[:max_count]
    
    def _get_upstream_downstream_with_levels(self, task, upstream_level, downstream_level, logs, round_num):
        """è·å–ä¸Šä¸‹æ¸¸ä¿¡æ¯ï¼ˆå¤ç”¨planningä¸­çš„å®ç°ï¼‰"""
        upstream_downstream = []
        
        # è·å–project_auditå®ä¾‹
        project_audit = getattr(self, 'project_audit', None) or self.context_data.get('project_audit')
        if not project_audit:
            return upstream_downstream
        
        try:
            # å¤ç”¨planningä¸­çš„æ–¹æ³•è·å–downstreamå†…å®¹
            from planning.planning_processor import PlanningProcessor
            planning_processor = PlanningProcessor(None, project_audit)  # task_managerå¯ä»¥ä¼ None
            
            # è·å–downstreamå†…å®¹ï¼ˆä½¿ç”¨planningä¸­çš„æ–¹æ³•ï¼‰
            downstream_content = planning_processor.get_downstream_content_with_call_tree(
                task.name, downstream_level
            )
            if downstream_content:
                upstream_downstream.append({
                    'content': downstream_content[:800],
                    'type': 'downstream',
                    'level': downstream_level,
                    'count': downstream_content.count('\n\n') + 1  # ç®€å•ä¼°ç®—å‡½æ•°æ•°é‡
                })
                logs.append(f"ç¬¬ {round_num} è½®: è·å–downstreamä»£ç å†…å®¹ï¼Œæ·±åº¦{downstream_level}ï¼Œ{len(downstream_content)} å­—ç¬¦")
            
            # è·å–upstreamå†…å®¹ï¼ˆå¤ç”¨planningçš„é€»è¾‘ï¼Œä½†ä¿®æ”¹ä¸ºupstreamï¼‰
            upstream_content = self._get_upstream_content_with_call_tree(
                task.name, upstream_level, planning_processor
            )
            if upstream_content:
                upstream_downstream.append({
                    'content': upstream_content[:800],
                    'type': 'upstream',
                    'level': upstream_level,
                    'count': upstream_content.count('\n\n') + 1  # ç®€å•ä¼°ç®—å‡½æ•°æ•°é‡
                })
                logs.append(f"ç¬¬ {round_num} è½®: è·å–upstreamä»£ç å†…å®¹ï¼Œæ·±åº¦{upstream_level}ï¼Œ{len(upstream_content)} å­—ç¬¦")
            
        except Exception as e:
            logs.append(f"ç¬¬ {round_num} è½®: å¤ç”¨planningæ–¹æ³•è·å–ä¸Šä¸‹æ¸¸å†…å®¹å¤±è´¥: {str(e)}")
        
        return upstream_downstream
    
    def _get_upstream_content_with_call_tree(self, func_name: str, max_depth: int, planning_processor) -> str:
        """è·å–upstreamå†…å®¹ï¼ˆå‚è€ƒplanningä¸­çš„downstreamå®ç°ï¼‰"""
        contents = []
        
        # æŸ¥æ‰¾å¯¹åº”çš„call tree
        if hasattr(planning_processor.project_audit, 'call_trees') and planning_processor.project_audit.call_trees:
            try:
                from tree_sitter_parsing.advanced_call_tree_builder import AdvancedCallTreeBuilder
                builder = AdvancedCallTreeBuilder()
                upstream_tree = builder.get_call_tree_with_depth_limit(
                    planning_processor.project_audit.call_trees, func_name, 'upstream', max_depth
                )
                
                if upstream_tree and upstream_tree.get('tree'):
                    contents = planning_processor._extract_contents_from_tree(upstream_tree['tree'])
            except Exception as e:
                print(f"    âš ï¸ ä½¿ç”¨é«˜çº§call treeè·å–upstreamå¤±è´¥: {e}")
                # è¿™é‡Œå¯ä»¥åŠ å…¥åå¤‡æ–¹æ¡ˆï¼Œä½†planningä¸­æ²¡æœ‰upstreamçš„fallback
        
        return '\n\n'.join(contents)
    
    def _remove_function_duplicates_from_upstream_downstream(self, all_info):
        """ä»upstream/downstreamä¸­å»é™¤ä¸functionç›¸åŒçš„ç»“æœ"""
        # è·å–æ‰€æœ‰functionåç§°
        function_names = set()
        for func_info in all_info['function_info']:
            function_names.add(func_info.get('name', ''))
        
        # ä»upstream/downstreamå†…å®¹ä¸­ç§»é™¤åŒ…å«ç›¸åŒfunctionsçš„éƒ¨åˆ†
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œä¸»è¦æ˜¯é¿å…å†…å®¹é‡å¤
        # å®é™…ä¸Šï¼Œupstream/downstreamå’Œfunctionçš„å†…å®¹æ˜¯ä¸åŒçš„è§’åº¦ï¼Œå¯ä»¥ä¿ç•™
        
        return all_info
    
    def _format_all_additional_info(self, all_info):
        """æ ¼å¼åŒ–æ‰€æœ‰é¢å¤–ä¿¡æ¯ä¸ºå­—ç¬¦ä¸²"""
        context_parts = []
        
        # Functionä¿¡æ¯
        if all_info['function_info']:
            context_parts.append("=== ç›¸å…³å‡½æ•° (Top 5) ===")
            for i, func in enumerate(all_info['function_info'], 1):
                context_parts.append(f"{i}. å‡½æ•°: {func.get('name', 'Unknown')}")
                context_parts.append(f"   ä»£ç : {func.get('content', '')[:200]}...\n")
        
        # Fileä¿¡æ¯ - å·²æ³¨é‡Š
        # if all_info['file_info']:
        #     context_parts.append("=== ç›¸å…³æ–‡ä»¶ (Top 2) ===")
        #     for i, file in enumerate(all_info['file_info'], 1):
        #         context_parts.append(f"{i}. æ–‡ä»¶: {file.get('path', 'Unknown')}")
        #         context_parts.append(f"   å†…å®¹: {file.get('content', '')[:200]}...\n")
        
        # Upstream/Downstreamä¿¡æ¯
        if all_info['upstream_downstream_info']:
            context_parts.append("=== ä¸Šä¸‹æ¸¸å…³ç³»ä¿¡æ¯ ===")
            for info in all_info['upstream_downstream_info']:
                level = info.get('level', 0)
                info_type = info.get('type', 'unknown')
                count = info.get('count', 0)
                context_parts.append(f"{info_type.title()}å‡½æ•° (æ·±åº¦{level}, å…±{count}ä¸ª):")
                context_parts.append(f"{info.get('content', '')[:400]}...\n")
        
        # Chunkä¿¡æ¯
        if all_info['chunk_info']:
            context_parts.append("=== ç›¸å…³æ–‡æ¡£å— (Top 3) ===")
            for i, chunk in enumerate(all_info['chunk_info'], 1):
                context_parts.append(f"{i}. æ–‡ä»¶: {chunk.get('file', 'Unknown')}")
                context_parts.append(f"   å†…å®¹: {chunk.get('text', '')[:200]}...\n")
        
        return '\n'.join(context_parts) if context_parts else "æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯"

    def _aggregate_round_results(self, round_results, logs):
        """æ±‡æ€»ä¸‰è½®ç»“æœï¼Œç”Ÿæˆæœ€ç»ˆåˆ¤æ–­"""
        logs.append("å¼€å§‹æ±‡æ€»ä¸‰è½®ç»“æœ")
        
        # ç»Ÿè®¡å„ç§ç»“æœ
        yes_count = sum(1 for result in round_results if result == 'yes')
        no_count = sum(1 for result in round_results if result == 'no')
        not_sure_count = sum(1 for result in round_results if result == 'not_sure')
        
        logs.append(f"ç»“æœç»Ÿè®¡: yes={yes_count}, no={no_count}, not_sure={not_sure_count}")
        
        # å†³ç­–é€»è¾‘
        if yes_count >= 2:  # è‡³å°‘2è½®è¯´yes
            final_short_result = "yes"
            decision_reason = f"3è½®æ£€æµ‹ä¸­{yes_count}è½®ç¡®è®¤å­˜åœ¨æ¼æ´"
        elif no_count >= 2:  # è‡³å°‘2è½®è¯´no
            final_short_result = "no"
            decision_reason = f"3è½®æ£€æµ‹ä¸­{no_count}è½®ç¡®è®¤ä¸å­˜åœ¨æ¼æ´"
        else:  # ç»“æœä¸ä¸€è‡´æˆ–éƒ½æ˜¯not_sure
            if yes_count > no_count:
                final_short_result = "yes"
                decision_reason = f"3è½®æ£€æµ‹ç»“æœä¸ä¸€è‡´ï¼Œä½†{yes_count}è½®å€¾å‘äºå­˜åœ¨æ¼æ´"
            elif no_count > yes_count:
                final_short_result = "no"
                decision_reason = f"3è½®æ£€æµ‹ç»“æœä¸ä¸€è‡´ï¼Œä½†{no_count}è½®å€¾å‘äºä¸å­˜åœ¨æ¼æ´"
            else:
                final_short_result = "not_sure"
                decision_reason = f"3è½®æ£€æµ‹ç»“æœæ— æ³•ç¡®å®šï¼Œéœ€äººå·¥å¤æ ¸"
        
        # ç”Ÿæˆè¯¦ç»†ç»“æœ
        detailed_result = f"""AgentåŒ–ä¸‰è½®æ£€æµ‹ç»“æœ:
è½®æ¬¡ç»“æœ: {round_results}
ç»Ÿè®¡: yes={yes_count}, no={no_count}, not_sure={not_sure_count}
æœ€ç»ˆåˆ¤æ–­: {final_short_result}
å†³ç­–ä¾æ®: {decision_reason}
"""
        
        logs.append(f"æœ€ç»ˆæ±‡æ€»: {final_short_result} - {decision_reason}")
        
        return final_short_result, detailed_result

    def _extract_function_names_from_tree(self, tree_data):
        """ä»è°ƒç”¨æ ‘æ•°æ®ä¸­æå–å‡½æ•°ååˆ—è¡¨"""
        function_names = []
        
        try:
            if isinstance(tree_data, dict):
                for key, value in tree_data.items():
                    if isinstance(key, str) and '.' in key:  # å‡è®¾å‡½æ•°åæ ¼å¼ä¸º ContractName.functionName
                        function_names.append(key)
                    elif isinstance(value, dict):
                        # é€’å½’å¤„ç†åµŒå¥—ç»“æ„
                        nested_names = self._extract_function_names_from_tree(value)
                        function_names.extend(nested_names)
            elif isinstance(tree_data, list):
                for item in tree_data:
                    if isinstance(item, str) and '.' in item:
                        function_names.append(item)
                    elif isinstance(item, dict):
                        nested_names = self._extract_function_names_from_tree(item)
                        function_names.extend(nested_names)
        except Exception as e:
            print(f"âš ï¸ æå–å‡½æ•°åå¤±è´¥: {e}")
        
        return list(set(function_names))  # å»é‡

    def _extract_function_content_from_tree(self, tree_data):
        """ä»è°ƒç”¨æ ‘æ•°æ®ä¸­æå–å‡½æ•°çš„å®é™…ä»£ç å†…å®¹"""
        function_contents = []
        
        try:
            if isinstance(tree_data, dict):
                for key, value in tree_data.items():
                    if isinstance(key, str) and '.' in key:  # å‡½æ•°åæ ¼å¼ä¸º ContractName.functionName
                        # ä»self.functionsä¸­æŸ¥æ‰¾å¯¹åº”çš„å‡½æ•°å†…å®¹
                        function_content = self._get_function_content_by_name(key)
                        if function_content:
                            function_contents.append(f"// {key}\n{function_content}")
                    
                    # é€’å½’å¤„ç†åµŒå¥—ç»“æ„
                    if isinstance(value, dict):
                        nested_content = self._extract_function_content_from_tree(value)
                        if nested_content:
                            function_contents.append(nested_content)
            elif isinstance(tree_data, list):
                for item in tree_data:
                    if isinstance(item, str) and '.' in item:
                        function_content = self._get_function_content_by_name(item)
                        if function_content:
                            function_contents.append(f"// {item}\n{function_content}")
                    elif isinstance(item, dict):
                        nested_content = self._extract_function_content_from_tree(item)
                        if nested_content:
                            function_contents.append(nested_content)
        except Exception as e:
            print(f"âš ï¸ æå–å‡½æ•°å†…å®¹å¤±è´¥: {e}")
        
        return '\n\n'.join(function_contents) if function_contents else ""

    def _get_function_content_by_name(self, function_name):
        """æ ¹æ®å‡½æ•°åä»self.functionsä¸­è·å–å‡½æ•°å†…å®¹"""
        try:
            for func in self.functions:
                if isinstance(func, dict) and func.get('name') == function_name:
                    return func.get('content', '')
            return ""
        except Exception as e:
            print(f"âš ï¸ æ ¹æ®å‡½æ•°åè·å–å†…å®¹å¤±è´¥: {e}")
            return "" 