import os
import time
import json
from datetime import datetime
from typing import List, Tuple, Dict, Any
import tiktoken

from dao.entity import Project_Task

from ..utils.check_utils import CheckUtils
from prompt_factory.prompt_assembler import PromptAssembler
from openai_api.openai import analyze_code_assumptions, extract_structured_json


class AnalysisProcessor:
    """Analysis processor responsible for executing specific vulnerability analysis logic (æ”¯æŒRAGé€‰æ‹©)"""
    
    def __init__(self, context_data: Dict[str, Any]):
        """
        åˆå§‹åŒ–åˆ†æå¤„ç†å™¨
        
        Args:
            context_data: åŒ…å«é¡¹ç›®æ•°æ®çš„å­—å…¸ï¼ŒåŒ…æ‹¬functions, functions_to_checkç­‰
        """
        self.context_data = context_data
        self.functions = context_data.get('functions', [])
        self.functions_to_check = context_data.get('functions_to_check', [])
        self.call_trees = context_data.get('call_trees', [])
        self.project_id = context_data.get('project_id', '')
        self.project_path = context_data.get('project_path', '')
        
        # åˆå§‹åŒ–RAGå¤„ç†å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        self.rag_processor = None
        self._initialize_rag_processor()
    
    def _initialize_rag_processor(self):
        """åˆå§‹åŒ–RAGå¤„ç†å™¨"""
        try:
            from context.rag_processor import RAGProcessor
            # è·å–project_auditå¯¹è±¡
            project_audit = self.context_data.get('project_audit')
            if not project_audit:
                self.rag_processor = None
                return
            
            # ä½¿ç”¨æ­£ç¡®çš„å‚æ•°åˆå§‹åŒ–RAGå¤„ç†å™¨ 
            self.rag_processor = RAGProcessor(
                project_audit,  # ğŸ”§ ä½¿ç”¨å®Œæ•´çš„project_auditå¯¹è±¡ï¼Œè€Œä¸æ˜¯functions_to_check
                "./src/codebaseQA/lancedb", 
                self.project_id
            )
        except Exception as e:
            import traceback
            self.rag_processor = None

    def _count_tokens(self, text: str, model: str = "gpt-4") -> int:
        """è®¡ç®—æ–‡æœ¬çš„tokenæ•°é‡
        
        Args:
            text: è¦è®¡ç®—çš„æ–‡æœ¬
            model: æ¨¡å‹åç§°ï¼Œé»˜è®¤gpt-4
            
        Returns:
            tokenæ•°é‡
        """
        try:
            encoding = tiktoken.encoding_for_model(model)
            return len(encoding.encode(text))
        except Exception:
            # å¦‚æœå¤±è´¥ï¼Œä½¿ç”¨ç®€å•ä¼°ç®—ï¼šå¤§çº¦4å­—ç¬¦=1token
            return len(text) // 4

    def get_available_rag_types(self) -> Dict[str, str]:
        """è·å–å¯ç”¨çš„RAGç±»å‹åˆ—è¡¨åŠå…¶æè¿°"""
        if not self.rag_processor:
            return {}
        
        return {
            # åŸºç¡€RAGç±»å‹
            'name': 'åå­—æ£€ç´¢ - åŸºäºå‡½æ•°åç§°çš„ç²¾ç¡®åŒ¹é…ï¼Œé€‚åˆæŸ¥æ‰¾ç‰¹å®šå‡½æ•°',
            'content': 'å†…å®¹æ£€ç´¢ - åŸºäºå‡½æ•°æºä»£ç å†…å®¹çš„è¯­ä¹‰ç›¸ä¼¼æ€§ï¼Œé€‚åˆæŸ¥æ‰¾ç›¸ä¼¼åŠŸèƒ½çš„ä»£ç ',
            'natural': 'è‡ªç„¶è¯­è¨€æ£€ç´¢ - åŸºäºAIç”Ÿæˆçš„åŠŸèƒ½æè¿°çš„è¯­ä¹‰ç†è§£ï¼Œé€‚åˆæè¿°æ€§æŸ¥è¯¢',
            
            # å…³ç³»å‹RAGç±»å‹
            'upstream': 'ä¸Šæ¸¸å‡½æ•°æ£€ç´¢ - åŸºäºè°ƒç”¨æ­¤å‡½æ•°çš„ä¸Šæ¸¸å‡½æ•°å†…å®¹ï¼Œé€‚åˆæŸ¥æ‰¾è°ƒç”¨é“¾ä¸Šæ¸¸',
            'downstream': 'ä¸‹æ¸¸å‡½æ•°æ£€ç´¢ - åŸºäºæ­¤å‡½æ•°è°ƒç”¨çš„ä¸‹æ¸¸å‡½æ•°å†…å®¹ï¼Œé€‚åˆæŸ¥æ‰¾è°ƒç”¨é“¾ä¸‹æ¸¸',
            
            # ä¸“é—¨çš„å…³ç³»è¡¨RAGç±»å‹
            'upstream_natural': 'ä¸Šæ¸¸è‡ªç„¶è¯­è¨€å…³ç³»æ£€ç´¢ - åŸºäºä¸Šæ¸¸å‡½æ•°çš„è‡ªç„¶è¯­è¨€æè¿°ï¼Œé€‚åˆç†è§£ä¸Šæ¸¸é€»è¾‘',
            'downstream_natural': 'ä¸‹æ¸¸è‡ªç„¶è¯­è¨€å…³ç³»æ£€ç´¢ - åŸºäºä¸‹æ¸¸å‡½æ•°çš„è‡ªç„¶è¯­è¨€æè¿°ï¼Œé€‚åˆç†è§£ä¸‹æ¸¸å½±å“',
            'upstream_content': 'ä¸Šæ¸¸å†…å®¹å…³ç³»æ£€ç´¢ - åŸºäºä¸Šæ¸¸å‡½æ•°çš„ä»£ç å†…å®¹ï¼Œé€‚åˆä»£ç å±‚é¢çš„ä¸Šæ¸¸åˆ†æ',
            'downstream_content': 'ä¸‹æ¸¸å†…å®¹å…³ç³»æ£€ç´¢ - åŸºäºä¸‹æ¸¸å‡½æ•°çš„ä»£ç å†…å®¹ï¼Œé€‚åˆä»£ç å±‚é¢çš„ä¸‹æ¸¸åˆ†æ',
            
            # æ–‡ä»¶çº§RAGç±»å‹
            'file_content': 'æ–‡ä»¶å†…å®¹æ£€ç´¢ - åŸºäºæ•´ä¸ªæ–‡ä»¶çš„å†…å®¹ï¼Œé€‚åˆæ–‡ä»¶çº§åˆ«çš„åˆ†æ',
            'file_natural': 'æ–‡ä»¶è‡ªç„¶è¯­è¨€æ£€ç´¢ - åŸºäºæ–‡ä»¶çš„è‡ªç„¶è¯­è¨€æè¿°ï¼Œé€‚åˆæ–‡ä»¶åŠŸèƒ½ç†è§£'
        }

    def ask_llm_to_choose_rag_for_validation(self, vulnerability_report: str, validation_question: str, context_info: str = "") -> Dict[str, Any]:
        """è®©å¤§æ¨¡å‹é€‰æ‹©RAGç±»å‹è¿›è¡Œæ¼æ´éªŒè¯
        
        Args:
            vulnerability_report: æ¼æ´æŠ¥å‘Šå†…å®¹
            validation_question: éªŒè¯é—®é¢˜
            context_info: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            DictåŒ…å«é€‰æ‹©çš„RAGç±»å‹ã€æŸ¥è¯¢å†…å®¹å’ŒRAGç»“æœ
        """
        if not self.rag_processor:
            return {
                'rag_chosen': None,
                'query_used': None,
                'rag_results': [],
                'reason': 'RAGå¤„ç†å™¨ä¸å¯ç”¨'
            }
        
        # è·å–å¯ç”¨çš„RAGç±»å‹
        rag_types = self.get_available_rag_types()
        
        # æ„å»ºæç¤ºï¼Œè®©å¤§æ¨¡å‹é€‰æ‹©RAGç±»å‹
        rag_selection_prompt = f"""ä½ æ­£åœ¨è¿›è¡Œæ™ºèƒ½åˆçº¦æ¼æ´éªŒè¯ã€‚éœ€è¦æ ¹æ®æ¼æ´æŠ¥å‘Šå’ŒéªŒè¯é—®é¢˜ï¼Œé€‰æ‹©æœ€åˆé€‚çš„RAGæ£€ç´¢ç±»å‹æ¥è·å–ç›¸å…³ä¿¡æ¯è¿›è¡ŒéªŒè¯ã€‚

**æ¼æ´æŠ¥å‘Š**ï¼š
{vulnerability_report}

**éªŒè¯é—®é¢˜**ï¼š
{validation_question}

**å½“å‰ä¸Šä¸‹æ–‡**ï¼š
{context_info}

**å¯ç”¨çš„RAGæ£€ç´¢ç±»å‹**ï¼š
{chr(10).join([f'- {k}: {v}' for k, v in rag_types.items()])}

**è¯·åˆ†æï¼š**
1. è¦éªŒè¯è¿™ä¸ªæ¼æ´ï¼Œæœ€éœ€è¦ä»€ä¹ˆç±»å‹çš„ç›¸å…³ä¿¡æ¯ï¼Ÿ
2. åº”è¯¥é€‰æ‹©å“ªç§RAGç±»å‹æ¥è·å–è¿™äº›ä¿¡æ¯ï¼Ÿ
3. åº”è¯¥ä½¿ç”¨ä»€ä¹ˆæŸ¥è¯¢å†…å®¹è¿›è¡Œæ£€ç´¢ï¼Ÿ

**é€‰æ‹©å»ºè®®**ï¼š
- å¦‚æœéœ€è¦éªŒè¯å‡½æ•°è°ƒç”¨å…³ç³»ï¼Œé€‰æ‹©upstream/downstreamç›¸å…³çš„RAG
- å¦‚æœéœ€è¦æŸ¥æ‰¾ç›¸ä¼¼çš„æ¼æ´æ¨¡å¼ï¼Œé€‰æ‹©contentæˆ–natural RAG
- å¦‚æœéœ€è¦ç†è§£ä¸šåŠ¡é€»è¾‘ï¼Œé€‰æ‹©naturalç›¸å…³çš„RAG
- å¦‚æœéœ€è¦éªŒè¯ç‰¹å®šå‡½æ•°è¡Œä¸ºï¼Œé€‰æ‹©nameæˆ–content RAG

è¯·ç”¨JSONæ ¼å¼å›ç­”ï¼š
{{
    "rag_type": "é€‰æ‹©çš„RAGç±»å‹åç§°",
    "query_content": "ç”¨äºæ£€ç´¢çš„å…·ä½“æŸ¥è¯¢å†…å®¹",
    "reason": "é€‰æ‹©æ­¤RAGç±»å‹çš„è¯¦ç»†åŸå› ",
    "validation_focus": "éªŒè¯çš„é‡ç‚¹æ˜¯ä»€ä¹ˆ",
    "backup_rag_type": "å¤‡é€‰RAGç±»å‹ï¼ˆå¯é€‰ï¼‰",
    "backup_query": "å¤‡é€‰æŸ¥è¯¢å†…å®¹ï¼ˆå¯é€‰ï¼‰"
}}

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚"""

        try:
            # è¯¢é—®å¤§æ¨¡å‹é€‰æ‹©RAGç±»å‹
            response = extract_structured_json(rag_selection_prompt)
            
            if not response:
                return {
                    'rag_chosen': None,
                    'query_used': None,
                    'rag_results': [],
                    'reason': 'å¤§æ¨¡å‹æœªè¿”å›RAGé€‰æ‹©'
                }
            
            rag_choice = json.loads(response) if isinstance(response, str) else response
            
            chosen_rag = rag_choice.get('rag_type', 'content')  # é»˜è®¤ä½¿ç”¨content
            query_content = rag_choice.get('query_content', validation_question)
            reason = rag_choice.get('reason', 'é»˜è®¤é€‰æ‹©')
            validation_focus = rag_choice.get('validation_focus', 'å¸¸è§„éªŒè¯')
            

            
            # æ ¹æ®é€‰æ‹©æ‰§è¡Œç›¸åº”çš„RAGæŸ¥è¯¢
            rag_results = self._execute_rag_query(chosen_rag, query_content)
            
            # å¦‚æœä¸»è¦RAGæ²¡æœ‰ç»“æœï¼Œå°è¯•å¤‡é€‰æ–¹æ¡ˆ
            if not rag_results and rag_choice.get('backup_rag_type'):
                backup_rag = rag_choice.get('backup_rag_type')
                backup_query = rag_choice.get('backup_query', query_content)
                rag_results = self._execute_rag_query(backup_rag, backup_query)
                chosen_rag = backup_rag
                query_content = backup_query
            
            return {
                'rag_chosen': chosen_rag,
                'query_used': query_content,
                'rag_results': rag_results,
                'reason': reason,
                'validation_focus': validation_focus,
                'llm_choice': rag_choice
            }
            
        except Exception as e:
            # å›é€€åˆ°ç®€å•çš„contentæœç´¢
            rag_results = self._execute_rag_query('content', validation_question)
            return {
                'rag_chosen': 'content',
                'query_used': validation_question,
                'rag_results': rag_results,
                'reason': f'RAGé€‰æ‹©å¤±è´¥ï¼Œå›é€€åˆ°é»˜è®¤: {str(e)}'
            }

    def _execute_rag_query(self, rag_type: str, query: str, k: int = 5) -> List[Dict]:
        """æ‰§è¡ŒæŒ‡å®šç±»å‹çš„RAGæŸ¥è¯¢
        
        Args:
            rag_type: RAGç±»å‹
            query: æŸ¥è¯¢å†…å®¹
            k: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            List[Dict]: RAGæŸ¥è¯¢ç»“æœ
        """
        if not self.rag_processor:
            return []
        
        try:
            # æ ¹æ®RAGç±»å‹è°ƒç”¨ç›¸åº”çš„æœç´¢æ–¹æ³•
            if rag_type == 'name':
                return self.rag_processor.search_functions_by_name(query, k)
            elif rag_type == 'content':
                return self.rag_processor.search_functions_by_content(query, k)
            elif rag_type == 'natural':
                return self.rag_processor.search_functions_by_natural_language(query, k)
            elif rag_type == 'upstream':
                return self.rag_processor.search_functions_by_upstream(query, k)
            elif rag_type == 'downstream':
                return self.rag_processor.search_functions_by_downstream(query, k)
            elif rag_type == 'upstream_natural':
                return self.rag_processor.search_relationships_by_upstream_natural(query, k)
            elif rag_type == 'downstream_natural':
                return self.rag_processor.search_relationships_by_downstream_natural(query, k)
            elif rag_type == 'upstream_content':
                return self.rag_processor.search_relationships_by_upstream_content(query, k)
            elif rag_type == 'downstream_content':
                return self.rag_processor.search_relationships_by_downstream_content(query, k)
            elif rag_type == 'file_content':
                return self.rag_processor.search_files_by_content(query, k)
            elif rag_type == 'file_natural':
                return self.rag_processor.search_files_by_natural_language(query, k)
            else:
                return self.rag_processor.search_functions_by_content(query, k)
                
        except Exception as e:
            return []

    def extract_required_info(self, response_text: str) -> List[str]:
        """æå–éœ€è¦è¿›ä¸€æ­¥åˆ†æçš„ä¿¡æ¯ï¼ˆå¢å¼ºRAGæ”¯æŒï¼‰"""
        # é¦–å…ˆå°è¯•ä½¿ç”¨å¤§æ¨¡å‹æå–å…³é”®ä¿¡æ¯
        try:
            extract_prompt = f"""ä»ä»¥ä¸‹æ¼æ´åˆ†ææŠ¥å‘Šä¸­æå–éœ€è¦è¿›ä¸€æ­¥éªŒè¯æˆ–åˆ†æçš„å…³é”®ä¿¡æ¯ç‚¹ï¼š

{response_text}

è¯·æå–ï¼š
1. éœ€è¦éªŒè¯çš„å‡½æ•°è°ƒç”¨å…³ç³»
2. éœ€è¦ç¡®è®¤çš„ä»£ç é€»è¾‘
3. éœ€è¦æŸ¥æ‰¾çš„ç›¸å…³å‡½æ•°æˆ–åˆçº¦
4. éœ€è¦åˆ†æçš„ä¸šåŠ¡æµç¨‹
5. å…¶ä»–éœ€è¦è¿›ä¸€æ­¥åˆ†æçš„è¦ç‚¹

è¯·ç”¨JSONæ ¼å¼è¿”å›ï¼š
{{
    "required_info": [
        "ä¿¡æ¯ç‚¹1çš„å…·ä½“æè¿°",
        "ä¿¡æ¯ç‚¹2çš„å…·ä½“æè¿°"
    ],
    "analysis_type": "éœ€è¦çš„åˆ†æç±»å‹ï¼ˆå¦‚å‡½æ•°å…³ç³»åˆ†æã€é€»è¾‘éªŒè¯ç­‰ï¼‰",
    "priority": "high/medium/low"
}}

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚"""

            response = extract_structured_json(extract_prompt)
            if response:
                extracted = json.loads(response) if isinstance(response, str) else response
                return extracted.get('required_info', [])
        except Exception as e:
            pass
        
        # å›é€€åˆ°ç®€åŒ–çš„å®ç°
        required_info = []
        keywords = ['éœ€è¦è¿›ä¸€æ­¥', 'æ›´å¤šä¿¡æ¯', 'éœ€è¦æŸ¥çœ‹', 'éœ€è¦ç¡®è®¤', 'ç¼ºå°‘ä¿¡æ¯', 'éªŒè¯', 'åˆ†æ']
        
        for keyword in keywords:
            if keyword in response_text:
                sentences = response_text.split('ã€‚')
                for sentence in sentences:
                    if keyword in sentence:
                        required_info.append(sentence.strip())
                        break
        
        return required_info

    def get_additional_context_with_rag(self, required_info: List[str], original_report: str = "") -> str:
        """ä½¿ç”¨RAGè·å–é¢å¤–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
        
        Args:
            required_info: éœ€è¦çš„ä¿¡æ¯åˆ—è¡¨
            original_report: åŸå§‹æŠ¥å‘Šå†…å®¹
            
        Returns:
            str: å¢å¼ºçš„ä¸Šä¸‹æ–‡ä¿¡æ¯
        """
        if not required_info:
            return "æœªæ‰¾åˆ°éœ€è¦è¿›ä¸€æ­¥åˆ†æçš„ä¿¡æ¯"
        
        enhanced_context_parts = []
        
        for i, info in enumerate(required_info, 1):
            try:
                
                # ä¸ºæ¯ä¸ªä¿¡æ¯ç‚¹è®©å¤§æ¨¡å‹é€‰æ‹©RAGç±»å‹
                validation_question = f"éœ€è¦éªŒè¯æˆ–åˆ†æï¼š{info}"
                rag_result = self.ask_llm_to_choose_rag_for_validation(original_report, validation_question, info)
                
                enhanced_context_parts.append(f"\n=== ä¿¡æ¯ç‚¹ {i} ===")
                enhanced_context_parts.append(f"éœ€è¦åˆ†æ: {info}")
                
                if rag_result.get('rag_chosen'):
                    enhanced_context_parts.append(f"ä½¿ç”¨RAGç±»å‹: {rag_result['rag_chosen']}")
                    enhanced_context_parts.append(f"éªŒè¯é‡ç‚¹: {rag_result.get('validation_focus', 'å¸¸è§„éªŒè¯')}")
                    
                    if rag_result.get('rag_results'):
                        enhanced_context_parts.append(f"æ‰¾åˆ° {len(rag_result['rag_results'])} ä¸ªç›¸å…³ç»“æœ:")
                        for j, result in enumerate(rag_result['rag_results'][:2], 1):  # åªæ˜¾ç¤ºå‰2ä¸ª
                            if isinstance(result, dict):
                                func_name = result.get('name', result.get('function_name', 'Unknown'))
                                content_preview = result.get('content', '')[:100] if result.get('content') else ''
                                enhanced_context_parts.append(f"  {j}. {func_name}: {content_preview}...")
                    else:
                        enhanced_context_parts.append("  æœªæ‰¾åˆ°ç›´æ¥ç›¸å…³çš„ä»£ç ")
                else:
                    enhanced_context_parts.append("  RAGæŸ¥è¯¢ä¸å¯ç”¨ï¼Œä½¿ç”¨ä¼ ç»Ÿåˆ†æ")
                    # ä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•æŸ¥æ‰¾ç›¸å…³å‡½æ•°
                    traditional_context = self._get_traditional_context(info)
                    if traditional_context:
                        enhanced_context_parts.append(f"  ä¼ ç»Ÿåˆ†æç»“æœ: {traditional_context}")
                
            except Exception as e:
                enhanced_context_parts.append(f"  å¤„ç†å¤±è´¥: {str(e)}")
        
        return '\n'.join(enhanced_context_parts)

    def _get_traditional_context(self, info: str) -> str:
        """ä¼ ç»Ÿæ–¹æ³•è·å–ä¸Šä¸‹æ–‡ï¼ˆä½œä¸ºRAGçš„å¤‡é€‰ï¼‰"""
        context_parts = []
        info_lower = info.lower()
        
        # åœ¨functionsä¸­æŸ¥æ‰¾ç›¸å…³ä¿¡æ¯
        for func in self.functions_to_check:
            func_content = func.get('content', '').lower()
            func_name = func.get('name', '')
            
            # ç®€å•çš„å…³é”®è¯åŒ¹é…
            if any(keyword in func_content for keyword in info_lower.split()):
                context_parts.append(f"ç›¸å…³å‡½æ•°: {func_name}")
                if len(context_parts) >= 3:  # é™åˆ¶ç»“æœæ•°é‡
                    break
        
        return '; '.join(context_parts) if context_parts else "æœªæ‰¾åˆ°ç›¸å…³å‡½æ•°"

    def get_additional_internet_info(self, required_info: List[str]) -> str:
        """è·å–ç½‘ç»œä¿¡æ¯ï¼ˆç®€åŒ–å®ç°ï¼‰"""
        if required_info:
            return f"ç½‘ç»œæœç´¢ç»“æœï¼šæ‰¾åˆ°{len(required_info)}ä¸ªç›¸å…³ä¿¡æ¯ç‚¹ï¼ˆç®€åŒ–å®ç°ï¼‰"
        return ""

    def get_additional_context(self, required_info: List[str]) -> str:
        """è·å–é¢å¤–ä¸Šä¸‹æ–‡ï¼ˆå‘åå…¼å®¹æ–¹æ³•ï¼‰"""
        return self.get_additional_context_with_rag(required_info)


    
    def process_task_analysis(self, task:Project_Task,task_manager):
        """AgentåŒ–çš„ä¸‰è½®æ¼æ´æ£€æµ‹æµç¨‹"""
        import json
        from datetime import datetime
        
        start_time = time.time()
        logs = []
        
        logs.append(f"å¼€å§‹æ—¶é—´: {datetime.utcnow().isoformat()}")
        
        # è·å–è§„åˆ™å’Œä¸šåŠ¡æµä»£ç 
        vulnerability_result = task.result
        business_flow_code = task.business_flow_code
        
        logs.append(f"è§„åˆ™ç±»å‹: {task.rule_key}")
        logs.append(f"ä»£ç é•¿åº¦: {len(business_flow_code)} å­—ç¬¦")
        
        # æ‰§è¡Œä¸‰è½®ç‹¬ç«‹æ£€æµ‹
        round_results = []
        
        for round_num in range(1, 4):  # ä¸‰è½®æ£€æµ‹
            logs.append(f"å¼€å§‹ç¬¬ {round_num} è½®æ£€æµ‹")
            
            try:
                round_result = self._execute_single_detection_round(
                    vulnerability_result, business_flow_code, task, round_num, logs
                )
                round_results.append(round_result)
                logs.append(f"ç¬¬ {round_num} è½®ç»“æœ: {round_result}")
                
                # ğŸ”§ å¦‚æœä»»ä½•ä¸€è½®å¾—åˆ° 'no' ç»“æœï¼Œç›´æ¥è·³å‡ºå¾ªç¯ï¼Œä¸æ‰§è¡Œåç»­è½®æ¬¡
                if round_result == 'no':
                    print(f"ğŸš« [Round {round_num}] æ£€æµ‹åˆ° 'no' ç»“æœï¼Œè·³è¿‡å‰©ä½™è½®æ¬¡")
                    logs.append(f"ç¬¬ {round_num} è½®: æ£€æµ‹åˆ° 'no' ç»“æœï¼Œè·³è¿‡å‰©ä½™è½®æ¬¡")
                    break
                
            except Exception as e:
                logs.append(f"ç¬¬ {round_num} è½®å¤±è´¥: {str(e)}")
                round_results.append("not_sure")
        
        # æ±‡æ€»ä¸‰è½®ç»“æœ
        final_short_result, final_detailed_result = self._aggregate_round_results(round_results, logs)
        
        # è®¡ç®—å¤„ç†æ—¶é—´
        end_time = time.time()
        process_time = round(end_time - start_time, 2)
        
        logs.append(f"æœ€ç»ˆç®€çŸ­ç»“æœ: {final_short_result}")
        logs.append(f"å¤„ç†è€—æ—¶: {process_time}ç§’")
        logs.append(f"ç»“æŸæ—¶é—´: {datetime.utcnow().isoformat()}")
        
        # ğŸ” æ£€æŸ¥æ˜¯å¦æœ‰ä»»æ„è½®æ¬¡å¤±è´¥ï¼Œå†³å®šæ˜¯å¦ä¿å­˜
        not_sure_count = sum(1 for result in round_results if result == 'not_sure')
        valid_results_count = len(round_results) - not_sure_count
        
        # âš ï¸ åªè¦æœ‰ä»»æ„ä¸€ä¸ªè½®æ¬¡å¤±è´¥(not_sure)ï¼Œå°±ä¸ä¿å­˜validationç»“æœ
        if not_sure_count > 0:
            logs.append("âš ï¸ æœ‰è½®æ¬¡å¤±è´¥ï¼Œä¸ä¿å­˜validationç»“æœ")
            
            # åªä¿å­˜å¤±è´¥æ—¥å¿—åˆ°scan_recordï¼Œä¸è®¾ç½®short_result
            scan_data = {
                'logs': logs,
                'round_results': round_results,
                'process_time': process_time,
                'timestamp': datetime.utcnow().isoformat(),
                'rounds_count': 3,
                'validation_failed': True,
                'failed_rounds': not_sure_count,
                'original_reasoning_result': task.result
            }
            task.scan_record = json.dumps(scan_data, ensure_ascii=False)
            
            # æ›´æ–°æ•°æ®åº“ä½†ä¸è®¾ç½®short_result
            task_manager.save_task(task)
            return "validation_failed"
        
        # âœ… æ‰€æœ‰è½®æ¬¡éƒ½æˆåŠŸï¼Œæ­£å¸¸ä¿å­˜
        logs.append(f"âœ… éªŒè¯æˆåŠŸ: æ‰€æœ‰è½®æ¬¡æˆåŠŸ={valid_results_count}/3, ä¿å­˜validationç»“æœ")
        
        # âš ï¸ ä¿æŒreasoningé˜¶æ®µçš„åŸå§‹resultä¸å˜ï¼Œä¸è¦†ç›–task.result
        # åŸå§‹reasoningç»“æœ: task.result (ä¿æŒä¸å˜)
        # åªæ›´æ–°short_resultç”¨äºç­›é€‰
        task.set_short_result(final_short_result)
        
        # ä¿å­˜å®Œæ•´æ—¥å¿—å’ŒéªŒè¯ç»“æœåˆ°scan_record
        scan_data = {
            'logs': logs,
            'round_results': round_results,
            'process_time': process_time,
            'timestamp': datetime.utcnow().isoformat(),
            'rounds_count': 3,
            'validation_detailed_result': final_detailed_result,  # éªŒè¯é˜¶æ®µçš„è¯¦ç»†ç»“æœ
            'validation_short_result': final_short_result,        # éªŒè¯é˜¶æ®µçš„ç®€çŸ­ç»“æœ
            'original_reasoning_result': task.result              # ä¿å­˜åŸå§‹reasoningç»“æœä¾›å‚è€ƒ
        }
        task.scan_record = json.dumps(scan_data, ensure_ascii=False)
        
        # æ›´æ–°æ•°æ®åº“
        task_manager.save_task(task)
        
        return final_short_result
    
    def _execute_single_detection_round(self, vulnerability_result, business_flow_code, task, round_num, logs):
        """æ‰§è¡Œå•è½®æ£€æµ‹æµç¨‹"""
        from openai_api.openai import (perform_initial_vulnerability_scan,
                                       determine_additional_context_needed,
                                       perform_comprehensive_vulnerability_analysis)
        from prompt_factory.vul_check_prompt import VulCheckPrompt
        
        print(f"ğŸ” [Round {round_num}] å¼€å§‹æ‰§è¡Œå•è½®æ£€æµ‹æµç¨‹")
        logs.append(f"ç¬¬ {round_num} è½®: å¼€å§‹åˆæ­¥ç¡®è®¤")
        
        # ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨prompt factoryç”Ÿæˆå®Œæ•´çš„åˆæ­¥åˆ†æprompt
        initial_prompt = VulCheckPrompt.vul_check_prompt_agent_initial_complete(
            vulnerability_result, business_flow_code
        )

        try:
            # ä½¿ç”¨ä¸“é—¨çš„åˆå§‹åˆ†ææ¨¡å‹è·å–è‡ªç„¶è¯­è¨€å“åº”
            natural_response = perform_initial_vulnerability_scan(initial_prompt)
            
            # ğŸ” åˆå§‹åˆ†æè°ƒè¯•ä¿¡æ¯
            logs.append(f"ç¬¬ {round_num} è½®: åˆå§‹åˆ†æå“åº”ç±»å‹={type(natural_response)}")
            logs.append(f"ç¬¬ {round_num} è½®: åˆå§‹åˆ†æå“åº”é•¿åº¦={len(str(natural_response)) if natural_response else 0}")
            logs.append(f"ç¬¬ {round_num} è½®: åˆå§‹åˆ†æå“åº”å‰200å­—ç¬¦={repr(str(natural_response)[:200]) if natural_response else 'None'}")
            
            if not natural_response:
                logs.append(f"ç¬¬ {round_num} è½®: åˆå§‹åˆ†ææ¨¡å‹æ— å“åº”")
                return "not_sure"
            
            logs.append(f"ç¬¬ {round_num} è½®: åˆå§‹åˆ†æè‡ªç„¶è¯­è¨€å“åº”é•¿åº¦={len(natural_response)}")
            
            # ä½¿ç”¨prompt factoryç”ŸæˆJSONæå–prompt
            json_extraction_prompt = VulCheckPrompt.vul_check_prompt_agent_json_extraction(
                natural_response
            )

            initial_response = extract_structured_json(json_extraction_prompt)
            
            # ğŸ” è¯¦ç»†è°ƒè¯•ä¿¡æ¯
            logs.append(f"ç¬¬ {round_num} è½®: JSONæå–åŸå§‹å“åº”ç±»å‹={type(initial_response)}")
            logs.append(f"ç¬¬ {round_num} è½®: JSONæå–åŸå§‹å“åº”é•¿åº¦={len(str(initial_response)) if initial_response else 0}")
            logs.append(f"ç¬¬ {round_num} è½®: JSONæå–åŸå§‹å“åº”å‰200å­—ç¬¦={repr(str(initial_response)[:200]) if initial_response else 'None'}")
            
            if not initial_response:
                logs.append(f"ç¬¬ {round_num} è½®: JSONæå–å¤±è´¥ - å“åº”ä¸ºç©º")
                return "not_sure"
            
            try:
                # ğŸ”§ ask_openai_for_json å·²ç»å¤„ç†äº†JSONæå–ï¼Œç›´æ¥è§£æ
                initial_result = json.loads(initial_response) if isinstance(initial_response, str) else initial_response
                logs.append(f"ç¬¬ {round_num} è½®: JSONè§£ææˆåŠŸï¼Œç»“æœç±»å‹={type(initial_result)}")
            except json.JSONDecodeError as e:
                logs.append(f"ç¬¬ {round_num} è½®: JSONè§£æå¤±è´¥ - {str(e)}")
                logs.append(f"ç¬¬ {round_num} è½®: åŸå§‹å†…å®¹={repr(initial_response)}")
                return "not_sure"
            assessment = initial_result.get('initial_assessment', 'not_sure')
            additional_info = initial_result.get('additional_info_needed', '')
            
            logs.append(f"ç¬¬ {round_num} è½®: åˆæ­¥è¯„ä¼°={assessment}")
            logs.append(f"ç¬¬ {round_num} è½®: è‡ªç„¶è¯­è¨€åˆ†æ={natural_response[:200]}...")
            
            # å¦‚æœæ˜¯æ˜ç¡®çš„yesæˆ–noï¼Œç›´æ¥è¿”å›
            if assessment in ['yes', 'no']:
                print(f"âœ… [Round {round_num}] è·å¾—æ˜ç¡®ç»“æœ: {assessment}")
                logs.append(f"ç¬¬ {round_num} è½®: æ˜ç¡®ç»“æœï¼Œç›´æ¥è¿”å›")
                # ğŸ”§ ç‰¹åˆ«æ˜¯åœ¨é‡åˆ° 'no' æ—¶ï¼Œç›´æ¥é€€å‡ºä¸è¿›è¡Œåç»­ç¡®è®¤
                if assessment == 'no':
                    print(f"ğŸš« [Round {round_num}] æ£€æµ‹åˆ° 'no' ç»“æœï¼Œè·³è¿‡æ‰€æœ‰åç»­ç¡®è®¤æµç¨‹")
                    logs.append(f"ç¬¬ {round_num} è½®: æ£€æµ‹åˆ° 'no' ç»“æœï¼Œæå‰ç»“æŸéªŒè¯")
                return assessment
            
            # å¦‚æœéœ€è¦æ›´å¤šä¿¡æ¯ï¼Œè¿›å…¥è‡ªå¾ªç¯ï¼ˆæœ€å¤š10è½®ï¼‰
            else:
                print(f"ğŸ”„ [Round {round_num}] éœ€è¦æ›´å¤šä¿¡æ¯ï¼Œè¿›å…¥å†…éƒ¨å¾ªç¯")
                logs.append(f"ç¬¬ {round_num} è½®: éœ€è¦æ›´å¤šä¿¡æ¯: {additional_info}")
                
                # è¿›å…¥è‡ªå¾ªç¯ï¼Œæœ€å¤š10è½®
                max_inner_rounds = 10
                current_assessment = assessment
                current_additional_info = additional_info
                accumulated_context = ""
                
                for inner_round in range(1, max_inner_rounds + 1):
                    logs.append(f"ç¬¬ {round_num} è½®-å†…éƒ¨ç¬¬ {inner_round} æ¬¡: å¼€å§‹è·å–é¢å¤–ä¿¡æ¯")
                    
                    try:
                        # è·å–æ‰€æœ‰ç±»å‹çš„RAGä¿¡æ¯
                        all_additional_info = self._get_all_additional_info(
                            current_additional_info, task, logs, round_num
                        )
                        
                        # æ ¼å¼åŒ–ä¸ºå­—ç¬¦ä¸²
                        additional_context = self._format_all_additional_info(all_additional_info)
                        
                        # ç´¯ç§¯ä¸Šä¸‹æ–‡ä¿¡æ¯
                        if accumulated_context:
                            accumulated_context += f"\n\n=== ç¬¬{inner_round}è½®é¢å¤–ä¿¡æ¯ ===\n" + additional_context
                        else:
                            accumulated_context = additional_context
                        
                        logs.append(f"ç¬¬ {round_num} è½®-å†…éƒ¨ç¬¬ {inner_round} æ¬¡: è·å–RAGä¿¡æ¯å®Œæˆ")
                            
                        # ä½¿ç”¨prompt factoryç”Ÿæˆæœ€ç»ˆåˆ†æprompt
                        final_analysis_prompt = VulCheckPrompt.vul_check_prompt_agent_final_analysis(
                            vulnerability_result, business_flow_code, current_assessment, current_additional_info, accumulated_context
                        )
                        
                        # ä½¿ç”¨ä¸“é—¨çš„æœ€ç»ˆåˆ†ææ¨¡å‹è¿›è¡Œæœ€ç»ˆåˆ†æ
                        final_natural_response = perform_comprehensive_vulnerability_analysis(final_analysis_prompt)
                        
                        # ğŸ” æœ€ç»ˆåˆ†æè°ƒè¯•ä¿¡æ¯
                        logs.append(f"ç¬¬ {round_num} è½®-å†…éƒ¨ç¬¬ {inner_round} æ¬¡: æœ€ç»ˆåˆ†æå“åº”ç±»å‹={type(final_natural_response)}")
                        logs.append(f"ç¬¬ {round_num} è½®-å†…éƒ¨ç¬¬ {inner_round} æ¬¡: æœ€ç»ˆåˆ†æå“åº”é•¿åº¦={len(str(final_natural_response)) if final_natural_response else 0}")
                        
                        if not final_natural_response:
                            logs.append(f"ç¬¬ {round_num} è½®-å†…éƒ¨ç¬¬ {inner_round} æ¬¡: æœ€ç»ˆåˆ†ææ¨¡å‹æ— å“åº”")
                            continue
                        

                        
                        # ä½¿ç”¨prompt factoryç”Ÿæˆæœ€ç»ˆç»“æœæå–prompt
                        final_extraction_prompt = VulCheckPrompt.vul_check_prompt_agent_final_extraction(
                            final_natural_response
                        )

                        final_response = extract_structured_json(final_extraction_prompt)
                        
                        # ğŸ” æœ€ç»ˆç»“æœæå–è°ƒè¯•ä¿¡æ¯
                        logs.append(f"ç¬¬ {round_num} è½®-å†…éƒ¨ç¬¬ {inner_round} æ¬¡: æœ€ç»ˆæå–åŸå§‹å“åº”ç±»å‹={type(final_response)}")
                        logs.append(f"ç¬¬ {round_num} è½®-å†…éƒ¨ç¬¬ {inner_round} æ¬¡: æœ€ç»ˆæå–åŸå§‹å“åº”é•¿åº¦={len(str(final_response)) if final_response else 0}")
                        
                        if not final_response:
                            logs.append(f"ç¬¬ {round_num} è½®-å†…éƒ¨ç¬¬ {inner_round} æ¬¡: æœ€ç»ˆæå–å¤±è´¥ - å“åº”ä¸ºç©º")
                            continue
                        
                        try:
                            # ğŸ”§ extract_structured_json å·²ç»å¤„ç†äº†JSONæå–ï¼Œç›´æ¥è§£æ
                            final_result = json.loads(final_response) if isinstance(final_response, str) else final_response
                            logs.append(f"ç¬¬ {round_num} è½®-å†…éƒ¨ç¬¬ {inner_round} æ¬¡: æœ€ç»ˆJSONè§£ææˆåŠŸï¼Œç»“æœç±»å‹={type(final_result)}")
                            
                            final_assessment = final_result.get('final_result', 'not_sure')
                            final_additional_info = final_result.get('additional_info_needed', '')
                            
                            logs.append(f"ç¬¬ {round_num} è½®-å†…éƒ¨ç¬¬ {inner_round} æ¬¡: æœ€ç»ˆç»“æœ={final_assessment}")
                            logs.append(f"ç¬¬ {round_num} è½®-å†…éƒ¨ç¬¬ {inner_round} æ¬¡: æœ€ç»ˆåˆ†æ={final_natural_response[:200]}...")
                            
                            # å¦‚æœå¾—åˆ°æ˜ç¡®çš„yesæˆ–noï¼Œé€€å‡ºå¾ªç¯
                            if final_assessment in ['yes', 'no']:
                                print(f"ğŸ¯ [Round {round_num}-{inner_round}] å†…éƒ¨å¾ªç¯è·å¾—æ˜ç¡®ç»“æœ: {final_assessment}")
                                logs.append(f"ç¬¬ {round_num} è½®-å†…éƒ¨ç¬¬ {inner_round} æ¬¡: å¾—åˆ°æ˜ç¡®ç»“æœï¼Œé€€å‡ºå¾ªç¯")
                                # ğŸ”§ ç‰¹åˆ«æ˜¯åœ¨é‡åˆ° 'no' æ—¶ï¼Œç›´æ¥é€€å‡ºä¸è¿›è¡Œåç»­ç¡®è®¤
                                if final_assessment == 'no':
                                    print(f"ğŸš« [Round {round_num}-{inner_round}] å†…éƒ¨å¾ªç¯æ£€æµ‹åˆ° 'no' ç»“æœï¼Œè·³è¿‡æ‰€æœ‰åç»­ç¡®è®¤æµç¨‹")
                                    logs.append(f"ç¬¬ {round_num} è½®-å†…éƒ¨ç¬¬ {inner_round} æ¬¡: æ£€æµ‹åˆ° 'no' ç»“æœï¼Œæå‰ç»“æŸéªŒè¯")
                                return final_assessment
                            
                            # å¦‚æœä»ç„¶æ˜¯need_more_infoï¼Œç»§ç»­ä¸‹ä¸€è½®
                            else:
                                if inner_round < max_inner_rounds:
                                    logs.append(f"ç¬¬ {round_num} è½®-å†…éƒ¨ç¬¬ {inner_round} æ¬¡: ä»éœ€æ›´å¤šä¿¡æ¯ï¼Œç»§ç»­ä¸‹ä¸€è½®")
                                    current_assessment = final_assessment
                                    current_additional_info = final_additional_info if final_additional_info else current_additional_info
                                    continue
                                else:
                                    logs.append(f"ç¬¬ {round_num} è½®-å†…éƒ¨ç¬¬ {inner_round} æ¬¡: è¾¾åˆ°æœ€å¤§å¾ªç¯æ¬¡æ•°ï¼Œé€€å‡º")
                                    return 'not_sure'
                                
                        except json.JSONDecodeError as e:
                            logs.append(f"ç¬¬ {round_num} è½®-å†…éƒ¨ç¬¬ {inner_round} æ¬¡: æœ€ç»ˆJSONè§£æå¤±è´¥ - {str(e)}")
                            logs.append(f"ç¬¬ {round_num} è½®-å†…éƒ¨ç¬¬ {inner_round} æ¬¡: æœ€ç»ˆåŸå§‹å†…å®¹={repr(final_response)}")
                            continue
                        
                    except Exception as e:
                        logs.append(f"ç¬¬ {round_num} è½®-å†…éƒ¨ç¬¬ {inner_round} æ¬¡: ä¿¡æ¯è·å–é˜¶æ®µå¤±è´¥: {str(e)}")
                        continue
                
                # å¦‚æœæ‰€æœ‰è½®æ¬¡éƒ½æ²¡æœ‰å¾—åˆ°æ˜ç¡®ç»“æœ
                logs.append(f"ç¬¬ {round_num} è½®: æ‰€æœ‰å†…éƒ¨å¾ªç¯å®Œæˆï¼Œæœªå¾—åˆ°æ˜ç¡®ç»“æœ")
                return 'not_sure'
            
            # å¦‚æœä»¥ä¸Šéƒ½å¤±è´¥ï¼Œè¿”å›åˆæ­¥è¯„ä¼°ç»“æœ
            return assessment if assessment in ['yes', 'no'] else 'not_sure'
            
        except Exception as e:
            import traceback
            error_details = traceback.format_exc()
            print(f"âŒ [Round {round_num}] æ£€æµ‹è¿‡ç¨‹å‘ç”Ÿå¼‚å¸¸: {str(e)}")
            logs.append(f"ç¬¬ {round_num} è½®: æ£€æµ‹å¤±è´¥: {str(e)}")
            logs.append(f"ç¬¬ {round_num} è½®: å®Œæ•´é”™è¯¯å †æ ˆ: {error_details}")
            return "not_sure"

   
    
    def _get_all_additional_info(self, specific_query, task, logs, round_num):
        """åŒæ—¶è·å–æ‰€æœ‰ç±»å‹çš„RAGä¿¡æ¯"""
        all_info = {
            'function_info': [],
            'file_info': [],
            'upstream_downstream_info': [],
            'chunk_info': []
        }
        
        # ğŸ” æ·»åŠ è°ƒè¯•ä¿¡æ¯
        
        try:
            # 1. Function RAGæœç´¢ (topk=5) - åŒ…æ‹¬ä¸‰ç§æœç´¢ç±»å‹
            if self.rag_processor:
                
                try:
                    # æŒ‰åç§°æœç´¢
                    name_results = self.rag_processor.search_functions_by_name(specific_query, 2)
                    
                    # æŒ‰å†…å®¹æœç´¢
                    content_results = self.rag_processor.search_functions_by_content(specific_query, 2)
                    
                    # æŒ‰è‡ªç„¶è¯­è¨€æè¿°æœç´¢
                    natural_results = self.rag_processor.search_functions_by_natural_language(specific_query, 2)
                    
                    # åˆå¹¶å’Œå»é‡ï¼Œå–å‰5ä¸ª
                    function_results = self._merge_and_deduplicate_functions(
                        name_results, content_results, natural_results, 5
                    )
                    
                    for result in function_results:
                        func_name = result.get('name', 'Unknown')
                        func_content = result.get('content', '')  # ğŸ”§ ç§»é™¤é•¿åº¦é™åˆ¶ï¼Œä¿ç•™å®Œæ•´å†…å®¹
                        all_info['function_info'].append({
                            'name': func_name,
                            'content': func_content,
                            'type': 'function'
                        })
                    

                    
                except Exception as e:
                    pass
            else:
                print(f"  âŒ ç¬¬ {round_num} è½®: rag_processorä¸ºNoneï¼Œè·³è¿‡Functionæœç´¢")
            
            # 2. File RAGæœç´¢ (topk=2) - å·²æ³¨é‡Š
            # if self.rag_processor:
            #     file_results = self.rag_processor.search_files_by_content(specific_query, 2)
            #     
            #     for result in file_results:
            #         file_path = result.get('file_path', 'Unknown')
            #         file_content = result.get('content', '')[:300]
            #         all_info['file_info'].append({
            #             'path': file_path,
            #             'content': file_content,
            #             'type': 'file'
            #         })
            #     
            #     logs.append(f"ç¬¬ {round_num} è½®: Fileæœç´¢æ‰¾åˆ° {len(file_results)} ä¸ªç»“æœ")
            
            # 3. Upstream/Downstreamæœç´¢ (level=3/4)

            try:
                upstream_downstream_results = self._get_upstream_downstream_with_levels(task, 3, 4, logs, round_num)
                all_info['upstream_downstream_info'] = upstream_downstream_results
            except Exception as e:
                pass
            
            # 4. Chunk RAGæœç´¢ (topk=3) - è¿‡æ»¤è¶…é•¿å†…å®¹
            if self.rag_processor:
                try:
                    chunk_results = self.rag_processor.search_chunks_by_content(specific_query, 3)
                    max_tokens = 150000  # è®¾ç½®150k tokené˜ˆå€¼
                    
                    for result in chunk_results:
                        chunk_text = result.get('chunk_text', '')
                        original_file = result.get('original_file', 'Unknown')
                        
                        # è®¡ç®—tokenæ•°é‡ï¼Œå¦‚æœè¶…è¿‡é˜ˆå€¼åˆ™è·³è¿‡
                        token_count = self._count_tokens(chunk_text)
                        if token_count > max_tokens:
                            print(f"  âš ï¸ ç¬¬ {round_num} è½®: Chunkæœç´¢ç»“æœè¿‡é•¿ ({token_count} tokens > {max_tokens})ï¼Œè·³è¿‡æ–‡ä»¶ {original_file}")
                            continue
                        
                        all_info['chunk_info'].append({
                            'text': chunk_text,
                            'file': original_file,
                            'type': 'chunk',
                            'token_count': token_count  # å¯é€‰ï¼šè®°å½•tokenæ•°é‡
                        })
                    

                except Exception as e:
                    pass
            else:
                print(f"  âŒ ç¬¬ {round_num} è½®: rag_processorä¸ºNoneï¼Œè·³è¿‡Chunkæœç´¢")
            
            # 5. å»é‡é€»è¾‘ï¼šä»upstream/downstreamä¸­å»é™¤ä¸functionç›¸åŒçš„
            all_info = self._remove_function_duplicates_from_upstream_downstream(all_info)
            
            return all_info
            
        except Exception as e:
            return all_info
    
    def _merge_and_deduplicate_functions(self, name_results, content_results, natural_results, max_count):
        """åˆå¹¶å’Œå»é‡å‡½æ•°æœç´¢ç»“æœï¼ˆä¸‰ç§ç±»å‹ï¼‰"""
        seen_names = set()
        merged_results = []
        
        # å…ˆåŠ å…¥æŒ‰åç§°æœç´¢çš„ç»“æœ
        for result in name_results:
            func_name = result.get('name', '')
            if func_name and func_name not in seen_names:
                seen_names.add(func_name)
                merged_results.append(result)
                if len(merged_results) >= max_count:
                    break
        
        # å†åŠ å…¥æŒ‰å†…å®¹æœç´¢çš„ç»“æœï¼ˆå»é‡ï¼‰
        for result in content_results:
            func_name = result.get('name', '')
            if func_name and func_name not in seen_names:
                seen_names.add(func_name)
                merged_results.append(result)
                if len(merged_results) >= max_count:
                    break
        
        # æœ€ååŠ å…¥æŒ‰è‡ªç„¶è¯­è¨€æœç´¢çš„ç»“æœï¼ˆå»é‡ï¼‰
        for result in natural_results:
            func_name = result.get('name', '')
            if func_name and func_name not in seen_names:
                seen_names.add(func_name)
                merged_results.append(result)
                if len(merged_results) >= max_count:
                    break
        
        return merged_results[:max_count]
    
    def _get_upstream_downstream_with_levels(self, task, upstream_level, downstream_level, logs, round_num):
        """è·å–ä¸Šä¸‹æ¸¸ä¿¡æ¯ï¼ˆå¤ç”¨planningä¸­çš„å®ç°ï¼‰"""
        upstream_downstream = []
        
        # è·å–project_auditå®ä¾‹
        project_audit = getattr(self, 'project_audit', None) or self.context_data.get('project_audit')
        if not project_audit:
            return upstream_downstream
        
        # æ£€æŸ¥project_auditçš„call_treeså±æ€§
        has_call_trees = hasattr(project_audit, 'call_trees') and project_audit.call_trees
        # print(f"    ğŸ” ç¬¬ {round_num} è½®: project_audit.call_treeså­˜åœ¨={has_call_trees}")
        if has_call_trees:
            pass
        
        try:
            # å¤ç”¨planningä¸­çš„æ–¹æ³•è·å–downstreamå†…å®¹
            from planning.planning_processor import PlanningProcessor
            planning_processor = PlanningProcessor(project_audit, None)  # project_auditç¬¬ä¸€ä¸ªï¼Œtask_managerç¬¬äºŒä¸ª
            
            # è·å–downstreamå†…å®¹ï¼ˆä½¿ç”¨planningä¸­çš„æ–¹æ³•ï¼‰
            downstream_content = planning_processor.get_downstream_content_with_call_tree(
                task.name, downstream_level
            )
            
            if downstream_content:
                upstream_downstream.append({
                    'content': downstream_content,  # ğŸ”§ ç§»é™¤800å­—ç¬¦æˆªæ–­ï¼Œä¿ç•™å®Œæ•´å†…å®¹
                    'type': 'downstream',
                    'level': downstream_level,
                    'count': downstream_content.count('\n\n') + 1  # ç®€å•ä¼°ç®—å‡½æ•°æ•°é‡
                })
            else:
                print(f"    âŒ ç¬¬ {round_num} è½®: downstreamå†…å®¹ä¸ºç©º")
            
            # è·å–upstreamå†…å®¹ï¼ˆå¤ç”¨planningçš„é€»è¾‘ï¼Œä½†ä¿®æ”¹ä¸ºupstreamï¼‰
            upstream_content = self._get_upstream_content_with_call_tree(
                task.name, upstream_level, planning_processor
            )
            
            if upstream_content:
                upstream_downstream.append({
                    'content': upstream_content,  # ğŸ”§ ç§»é™¤800å­—ç¬¦æˆªæ–­ï¼Œä¿ç•™å®Œæ•´å†…å®¹
                    'type': 'upstream',
                    'level': upstream_level,
                    'count': upstream_content.count('\n\n') + 1  # ç®€å•ä¼°ç®—å‡½æ•°æ•°é‡
                })
            else:
                print(f"    âŒ ç¬¬ {round_num} è½®: upstreamå†…å®¹ä¸ºç©º")
            
        except Exception as e:
            import traceback
            error_details = traceback.format_exc()
        
        return upstream_downstream
    
    def _get_upstream_content_with_call_tree(self, func_name: str, max_depth: int, planning_processor) -> str:
        """è·å–upstreamå†…å®¹ï¼ˆä½¿ç”¨ç»Ÿä¸€çš„æå–é€»è¾‘ï¼‰"""
        try:
            # ä½¿ç”¨planning_processorçš„ç»Ÿä¸€upstreamæ–¹æ³•
            return planning_processor.get_upstream_content_with_call_tree(func_name, max_depth)
        except Exception as e:
            print(f"âš ï¸ è·å–upstreamå†…å®¹å¤±è´¥: {e}")
            return ""
    
    def _remove_function_duplicates_from_upstream_downstream(self, all_info):
        """ä»upstream/downstreamä¸­å»é™¤ä¸functionç›¸åŒçš„ç»“æœ"""
        # è·å–æ‰€æœ‰functionåç§°
        function_names = set()
        for func_info in all_info['function_info']:
            function_names.add(func_info.get('name', ''))
        
        # ä»upstream/downstreamå†…å®¹ä¸­ç§»é™¤åŒ…å«ç›¸åŒfunctionsçš„éƒ¨åˆ†
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œä¸»è¦æ˜¯é¿å…å†…å®¹é‡å¤
        # å®é™…ä¸Šï¼Œupstream/downstreamå’Œfunctionçš„å†…å®¹æ˜¯ä¸åŒçš„è§’åº¦ï¼Œå¯ä»¥ä¿ç•™
        
        return all_info
    
    def _format_all_additional_info(self, all_info):
        """æ ¼å¼åŒ–æ‰€æœ‰é¢å¤–ä¿¡æ¯ä¸ºå­—ç¬¦ä¸²ï¼ˆå®Œæ•´ç‰ˆæœ¬ï¼Œæ— çœç•¥ï¼‰"""
        context_parts = []
        
        # Functionä¿¡æ¯
        if all_info['function_info']:
            context_parts.append("=== ç›¸å…³å‡½æ•° (Top 5) ===")
            for i, func in enumerate(all_info['function_info'], 1):
                context_parts.append(f"{i}. å‡½æ•°: {func.get('name', 'Unknown')}")
                context_parts.append(f"   ä»£ç : {func.get('content', '')}\n")  # ğŸ”§ ç§»é™¤æˆªæ–­å’Œçœç•¥å·
        
        # Fileä¿¡æ¯ - å·²æ³¨é‡Š
        # if all_info['file_info']:
        #     context_parts.append("=== ç›¸å…³æ–‡ä»¶ (Top 2) ===")
        #     for i, file in enumerate(all_info['file_info'], 1):
        #         context_parts.append(f"{i}. æ–‡ä»¶: {file.get('path', 'Unknown')}")
        #         context_parts.append(f"   å†…å®¹: {file.get('content', '')}\n")  # ğŸ”§ ç§»é™¤æˆªæ–­å’Œçœç•¥å·
        
        # Upstream/Downstreamä¿¡æ¯
        if all_info['upstream_downstream_info']:
            context_parts.append("=== ä¸Šä¸‹æ¸¸å…³ç³»ä¿¡æ¯ ===")
            for info in all_info['upstream_downstream_info']:
                level = info.get('level', 0)
                info_type = info.get('type', 'unknown')
                count = info.get('count', 0)
                context_parts.append(f"{info_type.title()}å‡½æ•° (æ·±åº¦{level}, å…±{count}ä¸ª):")
                context_parts.append(f"{info.get('content', '')}\n")  # ğŸ”§ ç§»é™¤æˆªæ–­å’Œçœç•¥å·
        
        # Chunkä¿¡æ¯
        if all_info['chunk_info']:
            context_parts.append("=== ç›¸å…³æ–‡æ¡£å— (Top 3) ===")
            for i, chunk in enumerate(all_info['chunk_info'], 1):
                context_parts.append(f"{i}. æ–‡ä»¶: {chunk.get('file', 'Unknown')}")
                context_parts.append(f"   å†…å®¹: {chunk.get('text', '')}\n")  # ğŸ”§ ç§»é™¤æˆªæ–­å’Œçœç•¥å·
        
        return '\n'.join(context_parts) if context_parts else "æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯"

    def _aggregate_round_results(self, round_results, logs):
        """æ±‡æ€»ä¸‰è½®ç»“æœï¼Œç”Ÿæˆæœ€ç»ˆåˆ¤æ–­"""
        logs.append("å¼€å§‹æ±‡æ€»ä¸‰è½®ç»“æœ")
        
        # ğŸ”§ ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœç¬¬ä¸€è½®å°±æ˜¯ 'no' å¹¶ä¸”åªæœ‰ä¸€è½®ç»“æœï¼Œç›´æ¥è¿”å› 'no'
        if len(round_results) == 1 and round_results[0] == 'no':
            logs.append("ç‰¹æ®Šæƒ…å†µ: ç¬¬ä¸€è½®å³ä¸º 'no' ç»“æœï¼Œæå‰é€€å‡ºéªŒè¯")
            final_short_result = "no"
            decision_reason = "ç¬¬ä¸€è½®æ£€æµ‹ç¡®è®¤ä¸å­˜åœ¨æ¼æ´ï¼Œæå‰ç»“æŸéªŒè¯"
            detailed_result = f"""AgentåŒ–æ£€æµ‹ç»“æœï¼ˆæå‰é€€å‡ºï¼‰:
è½®æ¬¡ç»“æœ: {round_results}
æœ€ç»ˆåˆ¤æ–­: {final_short_result}
å†³ç­–ä¾æ®: {decision_reason}
"""
            logs.append(f"æœ€ç»ˆæ±‡æ€»: {final_short_result} - {decision_reason}")
            return final_short_result, detailed_result
        
        # ç»Ÿè®¡å„ç§ç»“æœ
        yes_count = sum(1 for result in round_results if result == 'yes')
        no_count = sum(1 for result in round_results if result == 'no')
        not_sure_count = sum(1 for result in round_results if result == 'not_sure')
        
        logs.append(f"ç»“æœç»Ÿè®¡: yes={yes_count}, no={no_count}, not_sure={not_sure_count}")
        
        # å†³ç­–é€»è¾‘
        if yes_count >= 2:  # è‡³å°‘2è½®è¯´yes
            final_short_result = "yes"
            decision_reason = f"3è½®æ£€æµ‹ä¸­{yes_count}è½®ç¡®è®¤å­˜åœ¨æ¼æ´"
        elif no_count >= 2:  # è‡³å°‘2è½®è¯´no
            final_short_result = "no"
            decision_reason = f"3è½®æ£€æµ‹ä¸­{no_count}è½®ç¡®è®¤ä¸å­˜åœ¨æ¼æ´"
        elif no_count >= 1:  # ğŸ”§ æ”¹è¿›ï¼šä»»ä½•ä¸€è½®è¯´noï¼Œå°±å€¾å‘äºnoï¼ˆç‰¹åˆ«æ˜¯æå‰é€€å‡ºçš„æƒ…å†µï¼‰
            final_short_result = "no"
            decision_reason = f"æ£€æµ‹ä¸­{no_count}è½®ç¡®è®¤ä¸å­˜åœ¨æ¼æ´"
        else:  # ç»“æœä¸ä¸€è‡´æˆ–éƒ½æ˜¯not_sure
            if yes_count > no_count:
                final_short_result = "yes"
                decision_reason = f"æ£€æµ‹ç»“æœä¸ä¸€è‡´ï¼Œä½†{yes_count}è½®å€¾å‘äºå­˜åœ¨æ¼æ´"
            elif no_count > yes_count:
                final_short_result = "no"
                decision_reason = f"æ£€æµ‹ç»“æœä¸ä¸€è‡´ï¼Œä½†{no_count}è½®å€¾å‘äºä¸å­˜åœ¨æ¼æ´"
            else:
                final_short_result = "not_sure"
                decision_reason = f"æ£€æµ‹ç»“æœæ— æ³•ç¡®å®šï¼Œéœ€äººå·¥å¤æ ¸"
        
        # ç”Ÿæˆè¯¦ç»†ç»“æœ
        detailed_result = f"""AgentåŒ–ä¸‰è½®æ£€æµ‹ç»“æœ:
è½®æ¬¡ç»“æœ: {round_results}
ç»Ÿè®¡: yes={yes_count}, no={no_count}, not_sure={not_sure_count}
æœ€ç»ˆåˆ¤æ–­: {final_short_result}
å†³ç­–ä¾æ®: {decision_reason}
"""
        
        logs.append(f"æœ€ç»ˆæ±‡æ€»: {final_short_result} - {decision_reason}")
        
        return final_short_result, detailed_result

    def _extract_function_names_from_tree(self, tree_data):
        """ä»è°ƒç”¨æ ‘æ•°æ®ä¸­æå–å‡½æ•°ååˆ—è¡¨"""
        function_names = []
        
        try:
            if isinstance(tree_data, dict):
                for key, value in tree_data.items():
                    if isinstance(key, str) and '.' in key:  # å‡è®¾å‡½æ•°åæ ¼å¼ä¸º ContractName.functionName
                        function_names.append(key)
                    elif isinstance(value, dict):
                        # é€’å½’å¤„ç†åµŒå¥—ç»“æ„
                        nested_names = self._extract_function_names_from_tree(value)
                        function_names.extend(nested_names)
            elif isinstance(tree_data, list):
                for item in tree_data:
                    if isinstance(item, str) and '.' in item:
                        function_names.append(item)
                    elif isinstance(item, dict):
                        nested_names = self._extract_function_names_from_tree(item)
                        function_names.extend(nested_names)
        except Exception as e:
            pass
        
        return list(set(function_names))  # å»é‡

    def _extract_function_content_from_tree(self, tree_data):
        """ä»è°ƒç”¨æ ‘æ•°æ®ä¸­æå–å‡½æ•°çš„å®é™…ä»£ç å†…å®¹"""
        function_contents = []
        
        try:
            if isinstance(tree_data, dict):
                for key, value in tree_data.items():
                    if isinstance(key, str) and '.' in key:  # å‡½æ•°åæ ¼å¼ä¸º ContractName.functionName
                        # ä»self.functionsä¸­æŸ¥æ‰¾å¯¹åº”çš„å‡½æ•°å†…å®¹
                        function_content = self._get_function_content_by_name(key)
                        if function_content:
                            function_contents.append(f"// {key}\n{function_content}")
                    
                    # é€’å½’å¤„ç†åµŒå¥—ç»“æ„
                    if isinstance(value, dict):
                        nested_content = self._extract_function_content_from_tree(value)
                        if nested_content:
                            function_contents.append(nested_content)
            elif isinstance(tree_data, list):
                for item in tree_data:
                    if isinstance(item, str) and '.' in item:
                        function_content = self._get_function_content_by_name(item)
                        if function_content:
                            function_contents.append(f"// {item}\n{function_content}")
                    elif isinstance(item, dict):
                        nested_content = self._extract_function_content_from_tree(item)
                        if nested_content:
                            function_contents.append(nested_content)
        except Exception as e:
            pass
        
        return '\n\n'.join(function_contents) if function_contents else ""

    def _get_function_content_by_name(self, function_name):
        """æ ¹æ®å‡½æ•°åä»self.functionsä¸­è·å–å‡½æ•°å†…å®¹"""
        try:
            for func in self.functions:
                if isinstance(func, dict) and func.get('name') == function_name:
                    return func.get('content', '')
            return ""
        except Exception as e:
            return "" 