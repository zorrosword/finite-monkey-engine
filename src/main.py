import argparse
import ast
import os
import sys
import time
from ai_engine import *
from tree_sitter_parsing import TreeSitterProjectAudit as ProjectAudit
from dataset_manager import load_dataset, Project
from planning.planning import Planning
from sqlalchemy import create_engine
from dao import CacheManager, ProjectTaskMgr
import os
import pandas as pd
from openpyxl import Workbook,load_workbook
from openpyxl.utils.dataframe import dataframe_to_rows
from res_processor.res_processor import ResProcessor

import dotenv
dotenv.load_dotenv()

# æ·»åŠ æ—¥å¿—ç³»ç»Ÿ
from logging_config import setup_logging, get_logger, log_section_start, log_section_end, log_step, log_error, log_warning, log_success, log_data_info

def scan_project(project, db_engine):
    logger = get_logger("scan_project")
    scan_start_time = time.time()
    
    log_section_start(logger, "é¡¹ç›®æ‰«æ", f"é¡¹ç›®ID: {project.id}, è·¯å¾„: {project.path}")
    
    # 1. parsing projects  
    log_step(logger, "Tree-sitterè§£æé¡¹ç›®", f"é¡¹ç›®è·¯å¾„: {project.path}")
    parsing_start = time.time()
    
    project_audit = ProjectAudit(project.id, project.path, db_engine)
    project_audit.parse()
    
    parsing_duration = time.time() - parsing_start
    log_success(logger, "é¡¹ç›®è§£æå®Œæˆ", f"è€—æ—¶: {parsing_duration:.2f}ç§’")
    log_data_info(logger, "è§£æçš„å‡½æ•°", len(project_audit.functions_to_check))
    log_data_info(logger, "è°ƒç”¨æ ‘", len(project_audit.call_trees))
    log_data_info(logger, "è°ƒç”¨å›¾", len(project_audit.call_graphs))
    
    # 1.5 åˆå§‹åŒ–RAGå¤„ç†å™¨ï¼ˆå¯é€‰ï¼‰
    log_step(logger, "åˆå§‹åŒ–RAGå¤„ç†å™¨")
    rag_processor = None
    try:
        from context.rag_processor import RAGProcessor
        rag_start = time.time()
        
        # ä¼ é€’project_auditå¯¹è±¡ï¼ŒåŒ…å«functions, functions_to_check, chunks
        rag_processor = RAGProcessor(
            project_audit, 
            "./src/codebaseQA/lancedb", 
            project.id
        )
        
        rag_duration = time.time() - rag_start
        log_success(logger, "RAGå¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ", f"è€—æ—¶: {rag_duration:.2f}ç§’")
        log_data_info(logger, "åŸºäºtree-sitterè§£æçš„å‡½æ•°æ„å»ºRAG", len(project_audit.functions_to_check))
        log_data_info(logger, "åŸºäºæ–‡æ¡£åˆ†å—æ„å»ºRAG", len(project_audit.chunks))
        log_data_info(logger, "ä½¿ç”¨è°ƒç”¨æ ‘æ„å»ºå…³ç³»å‹RAG", len(project_audit.call_trees))
        log_data_info(logger, "é›†æˆè°ƒç”¨å›¾(Call Graph)", len(project_audit.call_graphs))
        
        # æ˜¾ç¤º call graph ç»Ÿè®¡ä¿¡æ¯
        if project_audit.call_graphs:
            call_graph_stats = project_audit.get_call_graph_statistics()
            log_data_info(logger, "Call Graphç»Ÿè®¡", call_graph_stats)
        
    except ImportError as e:
        log_warning(logger, "RAGå¤„ç†å™¨ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ç®€åŒ–åŠŸèƒ½")
        logger.debug(f"ImportErrorè¯¦æƒ…: {e}")
    except Exception as e:
        log_error(logger, "RAGå¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥", e)
        rag_processor = None
    
    # 1.6 æ£€æŸ¥ä¸šåŠ¡æµæ¨¡å¼é…ç½®
    log_step(logger, "æ£€æŸ¥ä¸šåŠ¡æµæ¨¡å¼é…ç½®")
    switch_business_code = eval(os.environ.get('SWITCH_BUSINESS_CODE', 'True'))
    logger.info(f"SWITCH_BUSINESS_CODE: {switch_business_code}")
    
    if switch_business_code:
        log_step(logger, "å¯ç”¨ä¸šåŠ¡ä»£ç æ‰«ææ¨¡å¼")
    else:
        log_step(logger, "ä½¿ç”¨ä¼ ç»Ÿæ‰«ææ¨¡å¼", "SWITCH_BUSINESS_CODE=False")
    
    # 2. planning & scanning - ç›´æ¥ä½¿ç”¨project_audit
    log_step(logger, "åˆ›å»ºä»»åŠ¡ç®¡ç†å™¨")
    project_taskmgr = ProjectTaskMgr(project.id, db_engine) 
    log_success(logger, "ä»»åŠ¡ç®¡ç†å™¨åˆ›å»ºå®Œæˆ")
    
    # åˆ›å»ºè§„åˆ’å¤„ç†å™¨ï¼Œç›´æ¥ä¼ é€’project_audit
    log_step(logger, "åˆ›å»ºè§„åˆ’å¤„ç†å™¨")
    planning = Planning(project_audit, project_taskmgr)
    log_success(logger, "è§„åˆ’å¤„ç†å™¨åˆ›å»ºå®Œæˆ")
    
    # å¦‚æœæœ‰RAGå¤„ç†å™¨ï¼Œåˆå§‹åŒ–planningçš„RAGåŠŸèƒ½
    if rag_processor:
        log_step(logger, "åˆå§‹åŒ–è§„åˆ’å™¨çš„RAGåŠŸèƒ½")
        planning.initialize_rag_processor("./src/codebaseQA/lancedb", project.id)
        log_success(logger, "è§„åˆ’å™¨RAGåŠŸèƒ½åˆå§‹åŒ–å®Œæˆ")
    
    # åˆ›å»ºAIå¼•æ“
    log_step(logger, "åˆ›å»ºAIå¼•æ“")
    lancedb_table = rag_processor.db if rag_processor else None
    lancedb_table_name = rag_processor.table_name if rag_processor else f"lancedb_{project.id}"
    logger.info(f"LanceDBè¡¨å: {lancedb_table_name}")
    
    engine = AiEngine(planning, project_taskmgr, lancedb_table, lancedb_table_name, project_audit)
    log_success(logger, "AIå¼•æ“åˆ›å»ºå®Œæˆ")
    
    # æ‰§è¡Œè§„åˆ’å’Œæ‰«æ
    log_step(logger, "æ‰§è¡Œé¡¹ç›®è§„åˆ’")
    planning_start = time.time()
    engine.do_planning()
    planning_duration = time.time() - planning_start
    log_success(logger, "é¡¹ç›®è§„åˆ’å®Œæˆ", f"è€—æ—¶: {planning_duration:.2f}ç§’")
    
    log_step(logger, "æ‰§è¡Œæ¼æ´æ‰«æ")
    scan_start = time.time()
    engine.do_scan()
    scan_duration = time.time() - scan_start
    log_success(logger, "æ¼æ´æ‰«æå®Œæˆ", f"è€—æ—¶: {scan_duration:.2f}ç§’")
    
    total_scan_duration = time.time() - scan_start_time
    log_section_end(logger, "é¡¹ç›®æ‰«æ", total_scan_duration)

    return lancedb_table, lancedb_table_name, project_audit

def check_function_vul(engine, lancedb, lance_table_name, project_audit):
    """æ‰§è¡Œæ¼æ´æ£€æŸ¥ï¼Œç›´æ¥ä½¿ç”¨project_auditæ•°æ®"""
    logger = get_logger("check_function_vul")
    check_start_time = time.time()
    
    log_section_start(logger, "æ¼æ´éªŒè¯", f"é¡¹ç›®ID: {project_audit.project_id}")
    
    log_step(logger, "åˆ›å»ºé¡¹ç›®ä»»åŠ¡ç®¡ç†å™¨")
    project_taskmgr = ProjectTaskMgr(project_audit.project_id, engine)
    log_success(logger, "é¡¹ç›®ä»»åŠ¡ç®¡ç†å™¨åˆ›å»ºå®Œæˆ")
    
    # ç›´æ¥ä½¿ç”¨project_auditåˆ›å»ºæ¼æ´æ£€æŸ¥å™¨
    log_step(logger, "åˆå§‹åŒ–æ¼æ´æ£€æŸ¥å™¨")
    from validating import VulnerabilityChecker
    checker = VulnerabilityChecker(project_audit, lancedb, lance_table_name)
    log_success(logger, "æ¼æ´æ£€æŸ¥å™¨åˆå§‹åŒ–å®Œæˆ")
    
    # æ‰§è¡Œæ¼æ´æ£€æŸ¥
    log_step(logger, "æ‰§è¡Œæ¼æ´éªŒè¯")
    validation_start = time.time()
    checker.check_function_vul(project_taskmgr)
    validation_duration = time.time() - validation_start
    log_success(logger, "æ¼æ´éªŒè¯å®Œæˆ", f"è€—æ—¶: {validation_duration:.2f}ç§’")
    
    total_check_duration = time.time() - check_start_time
    log_section_end(logger, "æ¼æ´éªŒè¯", total_check_duration)

def generate_excel(output_path, project_id):
    project_taskmgr = ProjectTaskMgr(project_id, engine)
    entities = project_taskmgr.query_task_by_project_id(project.id)
    
    # åˆ›å»ºä¸€ä¸ªç©ºçš„DataFrameæ¥å­˜å‚¨æ‰€æœ‰å®ä½“çš„æ•°æ®
    data = []
    for entity in entities:
        # ä½¿ç”¨resultå­—æ®µå’Œbusiness_flow_codeè¿›è¡Œç­›é€‰
        if entity.result and ("yes" in str(entity.result).lower()) and len(entity.business_flow_code)>0:
            data.append({
                'æ¼æ´ç»“æœ': entity.result,
                'ID': entity.id,
                'é¡¹ç›®åç§°': entity.project_id,
                'åˆåŒç¼–å·': entity.contract_code,
                'UUID': entity.uuid,  # ä½¿ç”¨uuidè€Œä¸æ˜¯key
                'å‡½æ•°åç§°': entity.name,
                'å‡½æ•°ä»£ç ': entity.content,
                'è§„åˆ™ç±»å‹': entity.rule_key,  # æ–°å¢rule_key
                'å¼€å§‹è¡Œ': entity.start_line,
                'ç»“æŸè¡Œ': entity.end_line,
                'ç›¸å¯¹è·¯å¾„': entity.relative_file_path,
                'ç»å¯¹è·¯å¾„': entity.absolute_file_path,
                'ä¸šåŠ¡æµç¨‹ä»£ç ': entity.business_flow_code,
                'æ‰«æè®°å½•': entity.scan_record,  # ä½¿ç”¨æ–°çš„scan_recordå­—æ®µ
                'æ¨è': entity.recommendation
            })
    
    # å°†æ•°æ®è½¬æ¢ä¸ºDataFrame
    if not data:  # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
        print("No data to process")
        return
        
    df = pd.DataFrame(data)
    
    try:
        # å¯¹dfè¿›è¡Œæ¼æ´å½’é›†å¤„ç†
        res_processor = ResProcessor(df,max_group_size=10,iteration_rounds=5,enable_chinese_translation=True)
        processed_df = res_processor.process()
        
        # ç¡®ä¿æ‰€æœ‰å¿…éœ€çš„åˆ—éƒ½å­˜åœ¨
        required_columns = df.columns
        for col in required_columns:
            if col not in processed_df.columns:
                processed_df[col] = ''
                
        # é‡æ–°æ’åˆ—åˆ—é¡ºåºä»¥åŒ¹é…åŸå§‹DataFrame
        processed_df = processed_df[df.columns]
    except Exception as e:
        print(f"Error processing data: {e}")
        processed_df = df  # å¦‚æœå¤„ç†å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹DataFrame
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_dir = os.path.dirname(output_path)
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºæ–°æ–‡ä»¶
    if not os.path.exists(output_path):
        wb = Workbook()
        ws = wb.active
        ws.title = "é¡¹ç›®æ•°æ®"
    else:
        wb = load_workbook(output_path)
        if "é¡¹ç›®æ•°æ®" in wb.sheetnames:
            ws = wb["é¡¹ç›®æ•°æ®"]
        else:
            ws = wb.create_sheet("é¡¹ç›®æ•°æ®")
    
    # å¦‚æœå·¥ä½œè¡¨æ˜¯ç©ºçš„ï¼Œæ·»åŠ è¡¨å¤´
    if ws.max_row == 1:
        for col, header in enumerate(processed_df.columns, start=1):
            ws.cell(row=1, column=col, value=header)
    
    # å°†DataFrameæ•°æ®å†™å…¥å·¥ä½œè¡¨
    for row in dataframe_to_rows(processed_df, index=False, header=False):
        ws.append(row)
    
    # ä¿å­˜Excelæ–‡ä»¶
    wb.save(output_path)
    
    print(f"Excelæ–‡ä»¶å·²ä¿å­˜åˆ°: {output_path}")
if __name__ == '__main__':
    # åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
    log_file_path = setup_logging()
    main_logger = get_logger("main")
    main_start_time = time.time()
    
    main_logger.info("ğŸ¯ ç¨‹åºå¯åŠ¨å‚æ•°:")
    main_logger.info(f"   Pythonç‰ˆæœ¬: {sys.version}")
    main_logger.info(f"   å·¥ä½œç›®å½•: {os.getcwd()}")
    main_logger.info(f"   ç¯å¢ƒå˜é‡å·²åŠ è½½")

    switch_production_or_test = 'test' # prod / test
    main_logger.info(f"è¿è¡Œæ¨¡å¼: {switch_production_or_test}")

    if switch_production_or_test == 'test':
        log_section_start(main_logger, "æµ‹è¯•æ¨¡å¼æ‰§è¡Œ")
        
        start_time=time.time()
        
        # åˆå§‹åŒ–æ•°æ®åº“
        log_step(main_logger, "åˆå§‹åŒ–æ•°æ®åº“è¿æ¥")
        db_url_from = os.environ.get("DATABASE_URL")
        main_logger.info(f"æ•°æ®åº“URL: {db_url_from}")
        engine = create_engine(db_url_from)
        log_success(main_logger, "æ•°æ®åº“è¿æ¥åˆ›å»ºå®Œæˆ")
        
        # åŠ è½½æ•°æ®é›†
        log_step(main_logger, "åŠ è½½æ•°æ®é›†")
        dataset_base = "./src/dataset/agent-v1-c4"
        main_logger.info(f"æ•°æ®é›†è·¯å¾„: {dataset_base}")
        projects = load_dataset(dataset_base)
        log_success(main_logger, "æ•°æ®é›†åŠ è½½å®Œæˆ", f"æ‰¾åˆ° {len(projects)} ä¸ªé¡¹ç›®")
 
        # è®¾ç½®é¡¹ç›®å‚æ•°
        project_id = 'fishcake0803'  # ä½¿ç”¨å­˜åœ¨çš„é¡¹ç›®ID
        project_path = ''
        main_logger.info(f"ç›®æ ‡é¡¹ç›®ID: {project_id}")
        project = Project(project_id, projects[project_id])
        log_success(main_logger, "é¡¹ç›®å¯¹è±¡åˆ›å»ºå®Œæˆ")
        
        # æ£€æŸ¥æ‰«ææ¨¡å¼
        scan_mode = os.getenv("SCAN_MODE","SPECIFIC_PROJECT")
        main_logger.info(f"æ‰«ææ¨¡å¼: {scan_mode}")
        
        cmd = 'detect_vul'
        main_logger.info(f"æ‰§è¡Œå‘½ä»¤: {cmd}")
        
        if cmd == 'detect_vul':
            # æ‰§è¡Œé¡¹ç›®æ‰«æ
            lancedb,lance_table_name,project_audit=scan_project(project, engine) # scan
            
            # æ ¹æ®æ‰«ææ¨¡å¼å†³å®šæ˜¯å¦æ‰§è¡Œæ¼æ´éªŒè¯
            if scan_mode in ["COMMON_PROJECT", "PURE_SCAN", "CHECKLIST", "COMMON_PROJECT_FINE_GRAINED"]:
                main_logger.info(f"æ‰«ææ¨¡å¼ '{scan_mode}' éœ€è¦æ‰§è¡Œæ¼æ´éªŒè¯")
                check_function_vul(engine,lancedb,lance_table_name,project_audit) # confirm
            else:
                main_logger.info(f"æ‰«ææ¨¡å¼ '{scan_mode}' è·³è¿‡æ¼æ´éªŒè¯æ­¥éª¤")

        # ç»Ÿè®¡æ€»æ‰§è¡Œæ—¶é—´
        end_time=time.time()
        total_duration = end_time-start_time
        log_success(main_logger, "æ‰€æœ‰æ‰«æä»»åŠ¡å®Œæˆ", f"æ€»è€—æ—¶: {total_duration:.2f}ç§’")
        
        # ç”ŸæˆExcelæŠ¥å‘Š
        log_step(main_logger, "ç”ŸæˆExcelæŠ¥å‘Š")
        excel_start = time.time()
        generate_excel("./output.xlsx",project_id)
        excel_duration = time.time() - excel_start
        log_success(main_logger, "ExcelæŠ¥å‘Šç”Ÿæˆå®Œæˆ", f"è€—æ—¶: {excel_duration:.2f}ç§’, æ–‡ä»¶: ./output.xlsx")
        
        log_section_end(main_logger, "æµ‹è¯•æ¨¡å¼æ‰§è¡Œ", time.time() - main_start_time)
        
        
    if switch_production_or_test == 'prod':
        # Set up command line argument parsing
        parser = argparse.ArgumentParser(description='Process input parameters for vulnerability scanning.')
        parser.add_argument('-fpath', type=str, required=True, help='Combined base path for the dataset and folder')
        parser.add_argument('-id', type=str, required=True, help='Project ID')
        # parser.add_argument('-cmd', type=str, choices=['detect', 'confirm','all'], required=True, help='Command to execute')
        parser.add_argument('-o', type=str, required=True, help='Output file path')
        # usage:
        # python main.py 
        # --fpath ../../dataset/agent-v1-c4/Archive 
        # --id Archive_aaa 
        # --cmd detect

        # Parse arguments
        args = parser.parse_args()
        print("fpath:",args.fpath)
        print("id:",args.id)
        print("cmd:",args.cmd)
        print("o:",args.o)
        # Split dataset_folder into dataset and folder
        dataset_base, folder_name = os.path.split(args.fpath)
        print("dataset_base:",dataset_base)
        print("folder_name:",folder_name)
        # Start time
        start_time = time.time()

        # Database setup
        db_url_from = os.environ.get("DATABASE_URL")
        engine = create_engine(db_url_from)

        # Load projects
        projects = load_dataset(dataset_base, args.id, folder_name)
        project = Project(args.id, projects[args.id])

        # Execute command
        # if args.cmd == 'detect':
        #     scan_project(project, engine)  # scan            
        # elif args.cmd == 'confirm':
        #     check_function_vul(engine)  # confirm
        # elif args.cmd == 'all':
        lancedb=scan_project(project, engine)  # scan
        check_function_vul(engine,lancedb)  # confirm

        end_time = time.time()
        print("Total time:", end_time -start_time)
        generate_excel(args.o,args.id)